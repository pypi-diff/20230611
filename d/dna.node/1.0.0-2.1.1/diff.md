# Comparing `tmp/dna.node-1.0.0-py3-none-any.whl.zip` & `tmp/dna.node-2.1.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,150 +1,167 @@
-Zip file size: 179940 bytes, number of entries: 148
+Zip file size: 227250 bytes, number of entries: 165
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Aug-15 12:44 conf/__init__.py
--rw-rw-rw-  2.0 fat     1412 b- defN 22-Aug-08 06:19 conf/logger.yaml
--rw-rw-rw-  2.0 fat      409 b- defN 22-Nov-18 04:23 dna/__init__.py
--rw-rw-rw-  2.0 fat      430 b- defN 22-Jun-22 06:26 dna/color.py
--rw-rw-rw-  2.0 fat     6000 b- defN 22-Aug-09 05:02 dna/conf.py
--rw-rw-rw-  2.0 fat     8096 b- defN 22-Nov-10 01:32 dna/execution.py
--rw-rw-rw-  2.0 fat     1857 b- defN 22-Jun-22 06:26 dna/func.py
--rw-rw-rw-  2.0 fat     6886 b- defN 22-Aug-05 06:58 dna/pika_execution.py
--rw-rw-rw-  2.0 fat     4118 b- defN 22-Aug-01 02:27 dna/pika_rpc.py
--rw-rw-rw-  2.0 fat     1557 b- defN 22-Jun-22 06:26 dna/plot_utils.py
--rw-rw-rw-  2.0 fat    11772 b- defN 22-Jul-21 23:58 dna/types.py
--rw-rw-rw-  2.0 fat     4631 b- defN 22-Aug-15 11:51 dna/utils.py
--rw-rw-rw-  2.0 fat      147 b- defN 22-Aug-03 06:00 dna/camera/__init__.py
--rw-rw-rw-  2.0 fat     3030 b- defN 22-Jun-23 02:25 dna/camera/camera.py
--rw-rw-rw-  2.0 fat    10114 b- defN 22-Nov-11 03:25 dna/camera/image_processor.py
--rw-rw-rw-  2.0 fat     9439 b- defN 22-Nov-03 09:36 dna/camera/opencv_camera.py
--rw-rw-rw-  2.0 fat     2640 b- defN 22-Jun-22 06:26 dna/camera/range_camera.py
--rw-rw-rw-  2.0 fat     2279 b- defN 22-Jun-22 06:26 dna/camera/resized_camera.py
--rw-rw-rw-  2.0 fat     4733 b- defN 22-Aug-03 04:35 dna/camera/threaded_camera.py
--rw-rw-rw-  2.0 fat      513 b- defN 22-Aug-02 00:03 dna/camera/utils.py
--rw-rw-rw-  2.0 fat      107 b- defN 22-Aug-03 04:42 dna/detect/__init__.py
--rw-rw-rw-  2.0 fat     3039 b- defN 22-Aug-03 03:17 dna/detect/detecting_processor.py
--rw-rw-rw-  2.0 fat     5205 b- defN 22-Aug-03 04:38 dna/detect/object_detector.py
+-rw-rw-rw-  2.0 fat     2391 b- defN 23-Jun-11 06:09 conf/logger.yaml
+-rw-rw-rw-  2.0 fat      230 b- defN 23-Jun-11 09:47 dna/__init__.py
+-rw-rw-rw-  2.0 fat      853 b- defN 23-Jun-04 14:02 dna/color.py
+-rw-rw-rw-  2.0 fat     2823 b- defN 23-Jun-11 10:21 dna/config.py
+-rw-rw-rw-  2.0 fat    10753 b- defN 23-Jun-11 10:24 dna/execution.py
+-rw-rw-rw-  2.0 fat    23360 b- defN 23-Jun-11 10:24 dna/types.py
+-rw-rw-rw-  2.0 fat     3636 b- defN 23-Jun-11 10:25 dna/utils.py
+-rw-rw-rw-  2.0 fat     2664 b- defN 23-Jun-10 11:59 dna/zone.py
+-rw-rw-rw-  2.0 fat      211 b- defN 23-May-19 00:45 dna/assoc/__init__.py
+-rw-rw-rw-  2.0 fat     9936 b- defN 23-Jun-11 10:25 dna/assoc/association.py
+-rw-rw-rw-  2.0 fat    12736 b- defN 23-Jun-11 10:15 dna/assoc/associator_feature.py
+-rw-rw-rw-  2.0 fat     5837 b- defN 23-Jun-10 12:31 dna/assoc/associator_motion.py
+-rw-rw-rw-  2.0 fat     9563 b- defN 23-Jun-11 10:15 dna/assoc/closure.py
+-rw-rw-rw-  2.0 fat    12026 b- defN 23-Jun-11 10:27 dna/assoc/collection.py
+-rw-rw-rw-  2.0 fat     3064 b- defN 23-Jun-11 10:27 dna/assoc/schema.py
+-rw-rw-rw-  2.0 fat     4616 b- defN 23-Jun-11 09:47 dna/assoc/tracklet_sync.py
+-rw-rw-rw-  2.0 fat      546 b- defN 23-Jun-11 10:09 dna/assoc/types.py
+-rw-rw-rw-  2.0 fat     8085 b- defN 23-Jun-11 10:31 dna/assoc/utils.py
+-rw-rw-rw-  2.0 fat     6528 b- defN 23-Jun-10 12:17 dna/assoc/windows.py
+-rw-rw-rw-  2.0 fat      184 b- defN 23-Apr-17 04:42 dna/camera/__init__.py
+-rw-rw-rw-  2.0 fat     3052 b- defN 23-Jun-10 05:36 dna/camera/camera.py
+-rw-rw-rw-  2.0 fat    11846 b- defN 23-Jun-11 10:31 dna/camera/image_processor.py
+-rw-rw-rw-  2.0 fat    13149 b- defN 23-Jun-11 10:32 dna/camera/opencv_camera.py
+-rw-rw-rw-  2.0 fat     2631 b- defN 23-Jun-04 14:02 dna/camera/resized_camera.py
+-rw-rw-rw-  2.0 fat      324 b- defN 23-Jun-10 05:11 dna/camera/utils.py
+-rw-rw-rw-  2.0 fat     1701 b- defN 23-Jun-04 14:02 dna/camera/video_writer.py
+-rw-rw-rw-  2.0 fat      130 b- defN 23-Mar-09 01:45 dna/detect/__init__.py
+-rw-rw-rw-  2.0 fat     2898 b- defN 23-Jun-04 14:02 dna/detect/detecting_processor.py
+-rw-rw-rw-  2.0 fat     1545 b- defN 23-Jun-07 00:29 dna/detect/detection.py
+-rw-rw-rw-  2.0 fat     4167 b- defN 23-Jun-10 11:49 dna/detect/object_detector.py
 -rw-rw-rw-  2.0 fat      599 b- defN 22-Aug-03 04:43 dna/detect/utils.py
 -rw-rw-rw-  2.0 fat       39 b- defN 22-Jun-22 06:26 dna/detect/rcnn50_fpn/__init__.py
--rw-rw-rw-  2.0 fat     1850 b- defN 22-Jul-21 01:49 dna/detect/rcnn50_fpn/rcnn50_fpn_detector.py
+-rw-rw-rw-  2.0 fat     1834 b- defN 23-Jun-10 12:04 dna/detect/rcnn50_fpn/rcnn50_fpn_detector.py
+-rw-rw-rw-  2.0 fat       42 b- defN 23-Mar-09 01:45 dna/detect/rcnn50_fpn_v2/__init__.py
+-rw-rw-rw-  2.0 fat     2664 b- defN 23-Jun-10 12:03 dna/detect/rcnn50_fpn_v2/rcnn50_fpn_v2_detector.py
+-rw-rw-rw-  2.0 fat       40 b- defN 23-Mar-09 01:45 dna/detect/ultralytics/__init__.py
+-rw-rw-rw-  2.0 fat     3407 b- defN 23-Jun-11 09:49 dna/detect/ultralytics/ultralytics_detector.py
 -rw-rw-rw-  2.0 fat       35 b- defN 22-Jun-22 06:26 dna/detect/yolov4/__init__.py
--rw-rw-rw-  2.0 fat     4379 b- defN 22-Aug-03 06:06 dna/detect/yolov4/yolov4_detector.py
+-rw-rw-rw-  2.0 fat     4482 b- defN 23-Jun-11 10:33 dna/detect/yolov4/yolov4_detector.py
 -rw-rw-rw-  2.0 fat        0 b- defN 22-Jun-22 06:26 dna/detect/yolov4/tool/__init__.py
 -rw-rw-rw-  2.0 fat     2243 b- defN 22-Jun-22 06:26 dna/detect/yolov4/tool/camera.py
 -rw-rw-rw-  2.0 fat     2015 b- defN 22-Jun-22 06:26 dna/detect/yolov4/tool/coco_annotation.py
 -rw-rw-rw-  2.0 fat    11027 b- defN 22-Jun-22 06:26 dna/detect/yolov4/tool/config.py
 -rw-rw-rw-  2.0 fat     2788 b- defN 22-Jun-22 06:26 dna/detect/yolov4/tool/darknet2onnx.py
 -rw-rw-rw-  2.0 fat    21141 b- defN 22-Jun-22 06:26 dna/detect/yolov4/tool/darknet2pytorch.py
 -rw-rw-rw-  2.0 fat     1161 b- defN 22-Jun-22 06:26 dna/detect/yolov4/tool/onnx2tensorflow.py
 -rw-rw-rw-  2.0 fat     9847 b- defN 22-Jun-22 06:26 dna/detect/yolov4/tool/region_loss.py
 -rw-rw-rw-  2.0 fat     2940 b- defN 22-Jun-22 06:26 dna/detect/yolov4/tool/torch_utils.py
 -rw-rw-rw-  2.0 fat     6750 b- defN 22-Sep-16 05:40 dna/detect/yolov4/tool/utils.py
 -rw-rw-rw-  2.0 fat     7053 b- defN 22-Jun-22 06:26 dna/detect/yolov4/tool/utils_iou.py
 -rw-rw-rw-  2.0 fat    12941 b- defN 22-Jun-22 06:26 dna/detect/yolov4/tool/utils_iou_test.py
 -rw-rw-rw-  2.0 fat    12633 b- defN 22-Jun-22 06:26 dna/detect/yolov4/tool/yolo_layer.py
 -rw-rw-rw-  2.0 fat       35 b- defN 22-Jun-22 06:26 dna/detect/yolov5/__init__.py
--rw-rw-rw-  2.0 fat     1510 b- defN 22-Aug-03 04:45 dna/detect/yolov5/yolov5_detector.py
--rw-rw-rw-  2.0 fat      429 b- defN 22-Jul-31 13:42 dna/node/__init__.py
--rw-rw-rw-  2.0 fat     1999 b- defN 22-Aug-03 06:12 dna/node/drop_short_trail.py
--rw-rw-rw-  2.0 fat     1512 b- defN 22-Jul-31 01:22 dna/node/event_processor.py
--rw-rw-rw-  2.0 fat     3068 b- defN 22-Aug-04 06:08 dna/node/generate_local_path.py
--rw-rw-rw-  2.0 fat      237 b- defN 22-Jun-22 06:26 dna/node/kafka_event.py
--rw-rw-rw-  2.0 fat      788 b- defN 22-Aug-22 23:55 dna/node/kafka_event_publisher.py
--rw-rw-rw-  2.0 fat      948 b- defN 22-Jun-22 06:26 dna/node/local_path_event.py
--rw-rw-rw-  2.0 fat     2581 b- defN 22-Aug-09 05:57 dna/node/node_processor.py
--rw-rw-rw-  2.0 fat     3151 b- defN 22-Aug-09 06:42 dna/node/publish_events_execution.py
--rw-rw-rw-  2.0 fat     3959 b- defN 22-Aug-03 04:24 dna/node/refine_track_event.py
--rw-rw-rw-  2.0 fat     5640 b- defN 22-Aug-02 01:46 dna/node/track_event.py
--rw-rw-rw-  2.0 fat     2843 b- defN 22-Aug-09 05:40 dna/node/utils.py
--rw-rw-rw-  2.0 fat     4102 b- defN 22-Aug-03 04:25 dna/node/world_transform.py
--rw-rw-rw-  2.0 fat      115 b- defN 22-Aug-03 05:58 dna/tracker/__init__.py
--rw-rw-rw-  2.0 fat     6677 b- defN 22-Aug-03 06:31 dna/tracker/track_pipeline.py
--rw-rw-rw-  2.0 fat     4900 b- defN 22-Aug-03 04:31 dna/tracker/tracker.py
--rw-rw-rw-  2.0 fat      773 b- defN 22-Jun-23 00:59 dna/tracker/cnu_siammot/__init__.py
--rw-rw-rw-  2.0 fat     3378 b- defN 22-Jun-22 07:19 dna/tracker/cnu_siammot/siammot_tracker.py
--rw-rw-rw-  2.0 fat      750 b- defN 22-May-12 14:00 dna/tracker/cnu_siammot/centernet/__init__.py
--rw-rw-rw-  2.0 fat     3286 b- defN 22-May-12 14:00 dna/tracker/cnu_siammot/centernet/config.py
--rw-rw-rw-  2.0 fat       46 b- defN 22-Jun-11 08:53 dna/tracker/cnu_siammot/siammot/__init__.py
--rw-rw-rw-  2.0 fat     4274 b- defN 22-Jun-12 06:29 dna/tracker/cnu_siammot/siammot/config.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/data/__init__.py
--rw-rw-rw-  2.0 fat     3348 b- defN 22-Jun-11 07:40 dna/tracker/cnu_siammot/siammot/data/build_train_data_loader.py
--rw-rw-rw-  2.0 fat     8025 b- defN 22-Jun-11 07:40 dna/tracker/cnu_siammot/siammot/data/image_dataset.py
--rw-rw-rw-  2.0 fat     8750 b- defN 22-Jun-11 07:40 dna/tracker/cnu_siammot/siammot/data/video_dataset.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/data/adapters/__init__.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/data/adapters/augmentation/__init__.py
--rw-rw-rw-  2.0 fat     2758 b- defN 22-Jun-11 06:17 dna/tracker/cnu_siammot/siammot/data/adapters/augmentation/build_augmentation.py
--rw-rw-rw-  2.0 fat     5765 b- defN 22-Jun-11 07:41 dna/tracker/cnu_siammot/siammot/data/adapters/augmentation/image_augmentation.py
--rw-rw-rw-  2.0 fat    10841 b- defN 22-Jun-11 07:42 dna/tracker/cnu_siammot/siammot/data/adapters/augmentation/video_augmentation.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/data/adapters/handler/__init__.py
--rw-rw-rw-  2.0 fat     5262 b- defN 22-Jun-11 07:42 dna/tracker/cnu_siammot/siammot/data/adapters/handler/data_filtering.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/data/adapters/utils/__init__.py
--rw-rw-rw-  2.0 fat     2506 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/data/adapters/utils/data_utils.py
--rw-rw-rw-  2.0 fat      975 b- defN 22-Jun-11 07:43 dna/tracker/cnu_siammot/siammot/data/adapters/utils/dataset_info.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/engine/__init__.py
--rw-rw-rw-  2.0 fat     2856 b- defN 22-Jun-11 07:38 dna/tracker/cnu_siammot/siammot/engine/custom_trainer.py
--rw-rw-rw-  2.0 fat     1981 b- defN 22-Jun-11 08:56 dna/tracker/cnu_siammot/siammot/engine/predictor.py
--rw-rw-rw-  2.0 fat     2757 b- defN 22-Jun-11 07:38 dna/tracker/cnu_siammot/siammot/engine/vis.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/eval/__init__.py
--rw-rw-rw-  2.0 fat     3086 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/eval/eval_clears_mot.py
--rw-rw-rw-  2.0 fat     5147 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/eval/eval_det_ap.py
--rw-rw-rw-  2.0 fat     3149 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/eval/eval_utils.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/modeling/__init__.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/modeling/box_head/__init__.py
--rw-rw-rw-  2.0 fat    20234 b- defN 22-Aug-03 04:19 dna/tracker/cnu_siammot/siammot/modeling/box_head/siam_fast_rcnn.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/modeling/meta_arch/__init__.py
--rw-rw-rw-  2.0 fat     4910 b- defN 22-Jun-13 05:38 dna/tracker/cnu_siammot/siammot/modeling/meta_arch/rcnn.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/modeling/roi_heads/__init__.py
--rw-rw-rw-  2.0 fat     4848 b- defN 22-Jun-13 05:53 dna/tracker/cnu_siammot/siammot/modeling/roi_heads/track_heads.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/modeling/track_head/__init__.py
--rw-rw-rw-  2.0 fat     4906 b- defN 22-Jun-11 12:07 dna/tracker/cnu_siammot/siammot/modeling/track_head/track_head.py
--rw-rw-rw-  2.0 fat     4747 b- defN 22-Jun-13 05:56 dna/tracker/cnu_siammot/siammot/modeling/track_head/track_solver.py
--rw-rw-rw-  2.0 fat    10653 b- defN 22-Jun-11 10:37 dna/tracker/cnu_siammot/siammot/modeling/track_head/track_utils.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/modeling/track_head/EMM/__init__.py
--rw-rw-rw-  2.0 fat     2874 b- defN 22-Jun-12 06:33 dna/tracker/cnu_siammot/siammot/modeling/track_head/EMM/feature_extractor.py
--rw-rw-rw-  2.0 fat    14224 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/modeling/track_head/EMM/target_sampler.py
--rw-rw-rw-  2.0 fat     8741 b- defN 22-Jun-11 07:37 dna/tracker/cnu_siammot/siammot/modeling/track_head/EMM/track_core.py
--rw-rw-rw-  2.0 fat     6163 b- defN 22-Jun-09 12:36 dna/tracker/cnu_siammot/siammot/modeling/track_head/EMM/track_loss.py
--rw-rw-rw-  2.0 fat     1360 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/modeling/track_head/EMM/xcorr.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/operator_patch/__init__.py
--rw-rw-rw-  2.0 fat     2734 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/operator_patch/fpn_patch.py
--rw-rw-rw-  2.0 fat     3444 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/operator_patch/rpn_patch.py
--rw-rw-rw-  2.0 fat      711 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/operator_patch/run_operator_patch.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/utils/__init__.py
--rw-rw-rw-  2.0 fat     2152 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/utils/boxlists_to_entities.py
--rw-rw-rw-  2.0 fat     1518 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/utils/entity_utils.py
--rw-rw-rw-  2.0 fat     1551 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/utils/get_model_name.py
--rw-rw-rw-  2.0 fat      139 b- defN 22-May-11 12:36 dna/tracker/cnu_siammot/siammot/utils/registry.py
--rw-rw-rw-  2.0 fat      509 b- defN 22-Jul-21 02:15 dna/tracker/dna_deepsort/__init__.py
--rw-rw-rw-  2.0 fat       66 b- defN 22-Jul-21 02:15 dna/tracker/dna_deepsort/__logger.py
--rw-rw-rw-  2.0 fat     6715 b- defN 22-Aug-03 04:20 dna/tracker/dna_deepsort/deepsort_tracker.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-Jun-22 06:26 dna/tracker/dna_deepsort/deepsort/__init__.py
--rw-rw-rw-  2.0 fat     4109 b- defN 22-Aug-03 06:05 dna/tracker/dna_deepsort/deepsort/deepsort.py
--rw-rw-rw-  2.0 fat      531 b- defN 22-Jun-22 06:26 dna/tracker/dna_deepsort/deepsort/detection.py
--rw-rw-rw-  2.0 fat     1473 b- defN 22-Jun-22 06:26 dna/tracker/dna_deepsort/deepsort/iou_matching.py
--rw-rw-rw-  2.0 fat     8176 b- defN 22-Jun-22 06:26 dna/tracker/dna_deepsort/deepsort/kalman_filter.py
--rw-rw-rw-  2.0 fat     7121 b- defN 22-Jun-22 06:26 dna/tracker/dna_deepsort/deepsort/linear_assignment.py
--rw-rw-rw-  2.0 fat    11352 b- defN 22-Aug-03 06:04 dna/tracker/dna_deepsort/deepsort/matcher.py
--rw-rw-rw-  2.0 fat     5192 b- defN 22-Jun-22 06:26 dna/tracker/dna_deepsort/deepsort/nn_matching.py
--rw-rw-rw-  2.0 fat     3664 b- defN 22-Jun-22 06:26 dna/tracker/dna_deepsort/deepsort/siamese_net.py
--rw-rw-rw-  2.0 fat     5814 b- defN 22-Jun-22 06:26 dna/tracker/dna_deepsort/deepsort/track.py
--rw-rw-rw-  2.0 fat    18199 b- defN 22-Aug-03 06:04 dna/tracker/dna_deepsort/deepsort/tracker.py
--rw-rw-rw-  2.0 fat     2275 b- defN 22-Jun-22 06:26 dna/tracker/dna_deepsort/deepsort/utils.py
--rw-rw-rw-  2.0 fat       26 b- defN 22-Jun-22 06:26 dna/tracker/dna_deepsort/deepsort/application_util/__init__.py
--rw-rw-rw-  2.0 fat    11831 b- defN 22-Jun-22 06:26 dna/tracker/dna_deepsort/deepsort/application_util/image_viewer.py
--rw-rw-rw-  2.0 fat     1987 b- defN 22-Jun-22 06:26 dna/tracker/dna_deepsort/deepsort/application_util/preprocessing.py
--rw-rw-rw-  2.0 fat     4317 b- defN 22-Jun-22 06:26 dna/tracker/dna_deepsort/deepsort/application_util/visualization.py
+-rw-rw-rw-  2.0 fat     4157 b- defN 23-Jun-11 10:33 dna/detect/yolov5/yolov5_detector.py
+-rw-rw-rw-  2.0 fat      800 b- defN 23-Jun-10 03:04 dna/event/__init__.py
+-rw-rw-rw-  2.0 fat     1151 b- defN 23-Jun-11 10:33 dna/event/event_processor.py
+-rw-rw-rw-  2.0 fat     5007 b- defN 23-Jun-11 10:34 dna/event/event_processors.py
+-rw-rw-rw-  2.0 fat     1710 b- defN 23-Jun-11 00:34 dna/event/kafka_event_publisher.py
+-rw-rw-rw-  2.0 fat      957 b- defN 23-Jun-07 00:29 dna/event/local_path_event.py
+-rw-rw-rw-  2.0 fat     6612 b- defN 23-Jun-10 12:11 dna/event/track_event.py
+-rw-rw-rw-  2.0 fat     3235 b- defN 23-Jun-11 10:07 dna/event/track_feature.py
+-rw-rw-rw-  2.0 fat     2887 b- defN 23-Jun-11 10:36 dna/event/tracklet_motion.py
+-rw-rw-rw-  2.0 fat    13505 b- defN 23-Jun-11 10:08 dna/event/tracklet_store.py
+-rw-rw-rw-  2.0 fat     1677 b- defN 23-Jun-11 10:35 dna/event/types.py
+-rw-rw-rw-  2.0 fat     3036 b- defN 23-Jun-11 10:35 dna/event/utils.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Jun-07 00:29 dna/event/proto/__init__.py
+-rw-rw-rw-  2.0 fat     2945 b- defN 23-Jun-07 00:29 dna/event/proto/node_processor_pb2.py
+-rw-rw-rw-  2.0 fat     4138 b- defN 23-Jun-07 00:29 dna/event/proto/node_processor_pb2_grpc.py
+-rw-rw-rw-  2.0 fat     1393 b- defN 23-Jun-07 03:55 dna/event/proto/reid_feature_pb2.py
+-rw-rw-rw-  2.0 fat       33 b- defN 23-Jun-10 01:51 dna/node/__init__.py
+-rw-rw-rw-  2.0 fat     2668 b- defN 23-Jun-11 10:15 dna/node/drop_short_trail.py
+-rw-rw-rw-  2.0 fat     3114 b- defN 23-Jun-10 12:09 dna/node/local_path_generator.py
+-rw-rw-rw-  2.0 fat     1284 b- defN 23-Jun-10 02:02 dna/node/node_event.py
+-rw-rw-rw-  2.0 fat     2228 b- defN 23-Jun-11 00:08 dna/node/node_processor.py
+-rw-rw-rw-  2.0 fat     5916 b- defN 23-May-27 23:07 dna/node/node_processor_grpc.py
+-rw-rw-rw-  2.0 fat     3173 b- defN 23-Jun-10 12:08 dna/node/publish_events_execution.py
+-rw-rw-rw-  2.0 fat    10545 b- defN 23-Jun-10 12:11 dna/node/refine_track_event.py
+-rw-rw-rw-  2.0 fat     4689 b- defN 23-Jun-11 10:08 dna/node/reid_features.py
+-rw-rw-rw-  2.0 fat     1898 b- defN 23-Jun-10 11:43 dna/node/running_stabilizer.py
+-rw-rw-rw-  2.0 fat     5866 b- defN 23-Jun-10 12:05 dna/node/stabilizer.py
+-rw-rw-rw-  2.0 fat    13131 b- defN 23-Jun-11 10:35 dna/node/track_event_pipeline.py
+-rw-rw-rw-  2.0 fat     3595 b- defN 23-Jun-11 10:08 dna/node/tracklet.py
+-rw-rw-rw-  2.0 fat     6751 b- defN 23-Jun-11 10:16 dna/node/tracklet_matcher.py
+-rw-rw-rw-  2.0 fat     6500 b- defN 23-Jun-10 00:42 dna/node/trajectory_drawer.py
+-rw-rw-rw-  2.0 fat      696 b- defN 23-Jun-10 12:18 dna/node/utils.py
+-rw-rw-rw-  2.0 fat     1800 b- defN 23-Jun-10 11:43 dna/node/world_coord_attach.py
+-rw-rw-rw-  2.0 fat     9974 b- defN 23-Jun-11 09:49 dna/node/world_coord_localizer.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-16 12:40 dna/node/pika/__init__.py
+-rw-rw-rw-  2.0 fat     3917 b- defN 23-Jun-11 10:36 dna/node/pika/pika_execution.py
+-rw-rw-rw-  2.0 fat     3811 b- defN 23-Jun-11 10:30 dna/node/pika/pika_execution_client.py
+-rw-rw-rw-  2.0 fat     2832 b- defN 23-Jun-11 10:29 dna/node/pika/pika_execution_context.py
+-rw-rw-rw-  2.0 fat     4426 b- defN 23-Jun-11 10:36 dna/node/pika/pika_execution_server.py
+-rw-rw-rw-  2.0 fat     4121 b- defN 23-Apr-15 08:31 dna/node/pika/pika_rpc.py
+-rw-rw-rw-  2.0 fat      218 b- defN 23-Jun-07 00:29 dna/node/zone/__init__.py
+-rw-rw-rw-  2.0 fat     2084 b- defN 23-Jun-10 04:09 dna/node/zone/motion_detector.py
+-rw-rw-rw-  2.0 fat     3273 b- defN 23-Jun-11 10:16 dna/node/zone/resident_changes.py
+-rw-rw-rw-  2.0 fat     1371 b- defN 23-Jun-11 10:19 dna/node/zone/to_line_transform.py
+-rw-rw-rw-  2.0 fat     9188 b- defN 23-Jun-11 10:16 dna/node/zone/types.py
+-rw-rw-rw-  2.0 fat     5307 b- defN 23-Jun-11 10:36 dna/node/zone/zone_event_generator.py
+-rw-rw-rw-  2.0 fat     7950 b- defN 23-Jun-11 10:37 dna/node/zone/zone_event_refiner.py
+-rw-rw-rw-  2.0 fat     3166 b- defN 23-Jun-11 10:37 dna/node/zone/zone_pipeline.py
+-rw-rw-rw-  2.0 fat     2545 b- defN 23-Jun-10 04:02 dna/node/zone/zone_sequence_collector.py
+-rw-rw-rw-  2.0 fat     2523 b- defN 23-Jun-11 10:17 dna/node/zone/zone_sequences_display.py
+-rw-rw-rw-  2.0 fat       89 b- defN 23-Jun-05 07:50 dna/support/__init__.py
+-rw-rw-rw-  2.0 fat     1901 b- defN 23-Jun-11 10:28 dna/support/func.py
+-rw-rw-rw-  2.0 fat     4150 b- defN 23-Jun-11 10:37 dna/support/iterables.py
+-rw-rw-rw-  2.0 fat     2121 b- defN 23-Jun-11 10:09 dna/support/plot_utils.py
+-rw-rw-rw-  2.0 fat     5573 b- defN 23-Jun-11 10:09 dna/support/polygon_drawer.py
+-rw-rw-rw-  2.0 fat     2240 b- defN 23-Jun-11 10:09 dna/support/rectangle_drawer.py
+-rw-rw-rw-  2.0 fat     1476 b- defN 23-Jun-04 14:02 dna/support/sql_utils.py
+-rw-rw-rw-  2.0 fat      980 b- defN 23-Mar-14 13:52 dna/support/text_line_writer.py
+-rw-rw-rw-  2.0 fat       35 b- defN 23-Jun-07 00:29 dna/track/__init__.py
+-rw-rw-rw-  2.0 fat     9069 b- defN 23-Jun-10 12:06 dna/track/dna_track.py
+-rw-rw-rw-  2.0 fat     7923 b- defN 23-Jun-11 10:38 dna/track/dna_track_params.py
+-rw-rw-rw-  2.0 fat     9634 b- defN 23-Jun-11 10:38 dna/track/dna_tracker.py
+-rw-rw-rw-  2.0 fat     4821 b- defN 23-Jun-10 12:06 dna/track/feature_extractor.py
+-rw-rw-rw-  2.0 fat     8016 b- defN 23-Jun-07 00:29 dna/track/kalman_filter.py
+-rw-rw-rw-  2.0 fat     3664 b- defN 23-Jun-07 00:29 dna/track/siamese_net.py
+-rw-rw-rw-  2.0 fat     7481 b- defN 23-Jun-10 11:56 dna/track/track_pipeline.py
+-rw-rw-rw-  2.0 fat      634 b- defN 23-Jun-10 11:46 dna/track/track_state.py
+-rw-rw-rw-  2.0 fat    19290 b- defN 23-Jun-11 10:18 dna/track/tracker.py
+-rw-rw-rw-  2.0 fat     3217 b- defN 23-Jun-10 12:06 dna/track/types.py
+-rw-rw-rw-  2.0 fat     3593 b- defN 23-Jun-10 12:20 dna/track/utils.py
+-rw-rw-rw-  2.0 fat      412 b- defN 23-Jun-07 00:29 dna/track/matcher/__init__.py
+-rw-rw-rw-  2.0 fat     1605 b- defN 23-Jun-11 10:10 dna/track/matcher/base.py
+-rw-rw-rw-  2.0 fat     5428 b- defN 23-Jun-11 10:10 dna/track/matcher/cost_matrices.py
+-rw-rw-rw-  2.0 fat     3400 b- defN 23-Jun-11 10:10 dna/track/matcher/hungarian_matcher.py
+-rw-rw-rw-  2.0 fat     3343 b- defN 23-Jun-11 10:11 dna/track/matcher/iou_dist_cost_matcher.py
+-rw-rw-rw-  2.0 fat     4163 b- defN 23-Jun-11 09:48 dna/track/matcher/matching_session.py
+-rw-rw-rw-  2.0 fat     2594 b- defN 23-Jun-11 10:11 dna/track/matcher/metric_assisted_cost_matcher.py
+-rw-rw-rw-  2.0 fat      886 b- defN 23-Jun-11 10:12 dna/track/matcher/metric_cost_matcher.py
+-rw-rw-rw-  2.0 fat     4806 b- defN 23-Jun-11 10:12 dna/track/matcher/reciprocal_cost_matcher.py
 -rw-rw-rw-  2.0 fat       21 b- defN 22-Jun-22 06:26 pubsub/__init__.py
 -rw-rw-rw-  2.0 fat    17451 b- defN 22-Jun-22 06:26 pubsub/pubsub.py
--rw-rw-rw-  2.0 fat        0 b- defN 22-Aug-08 02:06 scripts/__init__.py
--rw-rw-rw-  2.0 fat     2663 b- defN 22-Nov-16 09:54 scripts/dna_node.py
--rw-rw-rw-  2.0 fat     3021 b- defN 22-Nov-10 02:19 scripts/dna_node_detect.py
--rw-rw-rw-  2.0 fat     2275 b- defN 22-Nov-10 00:46 scripts/dna_node_processor.py
--rw-rw-rw-  2.0 fat     1661 b- defN 22-Sep-27 10:10 scripts/dna_node_processor_client.py
--rw-rw-rw-  2.0 fat     2411 b- defN 22-Nov-18 04:16 scripts/dna_node_show.py
--rw-rw-rw-  2.0 fat     2913 b- defN 22-Nov-10 02:27 scripts/dna_node_track.py
--rw-rw-rw-  2.0 fat     2028 b- defN 22-Aug-09 06:38 scripts/dna_publish_event_server.py
--rw-rw-rw-  2.0 fat     2031 b- defN 22-Nov-09 01:44 scripts/dna_publish_events.py
--rw-rw-rw-  2.0 fat      754 b- defN 22-Nov-18 04:23 dna.node-1.0.0.dist-info/METADATA
--rw-rw-rw-  2.0 fat       92 b- defN 22-Nov-18 04:23 dna.node-1.0.0.dist-info/WHEEL
--rw-rw-rw-  2.0 fat      424 b- defN 22-Nov-18 04:23 dna.node-1.0.0.dist-info/entry_points.txt
--rw-rw-rw-  2.0 fat       24 b- defN 22-Nov-18 04:23 dna.node-1.0.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat    14454 b- defN 22-Nov-18 04:23 dna.node-1.0.0.dist-info/RECORD
-148 files, 553551 bytes uncompressed, 156364 bytes compressed:  71.8%
+-rw-rw-rw-  2.0 fat       66 b- defN 23-Jun-10 01:05 scripts/__init__.py
+-rw-rw-rw-  2.0 fat     4489 b- defN 23-Jun-07 00:29 scripts/dna_assoc_tracklets.py
+-rw-rw-rw-  2.0 fat     2997 b- defN 23-Jun-10 12:20 scripts/dna_backup_topics.py
+-rw-rw-rw-  2.0 fat     3318 b- defN 23-Apr-17 04:59 scripts/dna_detect.py
+-rw-rw-rw-  2.0 fat     2670 b- defN 23-Jun-10 02:27 scripts/dna_download_node_events.py
+-rw-rw-rw-  2.0 fat     4874 b- defN 23-Jun-10 05:05 scripts/dna_draw_trajs.py
+-rw-rw-rw-  2.0 fat     7738 b- defN 23-Jun-07 00:29 scripts/dna_fuse_assoc_tracklets.py
+-rw-rw-rw-  2.0 fat    12048 b- defN 23-Jun-11 10:38 scripts/dna_gen_trainset.py
+-rw-rw-rw-  2.0 fat     6705 b- defN 23-Jun-11 10:38 scripts/dna_gen_trainset2.py
+-rw-rw-rw-  2.0 fat     4993 b- defN 23-Jun-11 10:13 scripts/dna_match_mc_tracklets.py
+-rw-rw-rw-  2.0 fat     3391 b- defN 23-Jun-11 06:05 scripts/dna_node.py
+-rw-rw-rw-  2.0 fat     2107 b- defN 23-Jun-11 06:50 scripts/dna_node_processor.py
+-rw-rw-rw-  2.0 fat     1861 b- defN 23-Apr-18 05:30 scripts/dna_node_processor_client.py
+-rw-rw-rw-  2.0 fat     2991 b- defN 23-Jun-10 12:13 scripts/dna_reduce_trainset.py
+-rw-rw-rw-  2.0 fat     2266 b- defN 23-Jun-11 10:39 scripts/dna_replay_node_events.py
+-rw-rw-rw-  2.0 fat     2086 b- defN 23-Jun-11 10:39 scripts/dna_restore_topics.py
+-rw-rw-rw-  2.0 fat     2278 b- defN 23-Jun-07 00:29 scripts/dna_show.py
+-rw-rw-rw-  2.0 fat     6425 b- defN 23-Jun-11 09:48 scripts/dna_show_mc_locations.py
+-rw-rw-rw-  2.0 fat     4329 b- defN 23-Jun-10 05:37 scripts/dna_show_multiple_videos.py
+-rw-rw-rw-  2.0 fat     3438 b- defN 23-Jun-09 16:34 scripts/dna_store_topics.py
+-rw-rw-rw-  2.0 fat     4501 b- defN 23-Jun-10 12:22 scripts/dna_sync_tracklets.py
+-rw-rw-rw-  2.0 fat    11345 b- defN 23-Jun-10 11:54 scripts/dna_sync_videos.py
+-rw-rw-rw-  2.0 fat     2926 b- defN 23-Jun-07 00:29 scripts/dna_track.py
+-rw-rw-rw-  2.0 fat     5688 b- defN 23-Jun-10 12:10 scripts/dna_tracklet.py
+-rw-rw-rw-  2.0 fat     3175 b- defN 23-Jun-11 10:39 scripts/utils.py
+-rw-rw-rw-  2.0 fat      837 b- defN 23-Jun-11 10:42 dna.node-2.1.1.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 23-Jun-11 10:42 dna.node-2.1.1.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat      378 b- defN 23-Jun-11 10:42 dna.node-2.1.1.dist-info/entry_points.txt
+-rw-rw-rw-  2.0 fat       24 b- defN 23-Jun-11 10:42 dna.node-2.1.1.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat    13987 b- defN 23-Jun-11 10:42 dna.node-2.1.1.dist-info/RECORD
+165 files, 725043 bytes uncompressed, 205342 bytes compressed:  71.7%
```

## zipnote {}

```diff
@@ -6,80 +6,116 @@
 
 Filename: dna/__init__.py
 Comment: 
 
 Filename: dna/color.py
 Comment: 
 
-Filename: dna/conf.py
+Filename: dna/config.py
 Comment: 
 
 Filename: dna/execution.py
 Comment: 
 
-Filename: dna/func.py
+Filename: dna/types.py
 Comment: 
 
-Filename: dna/pika_execution.py
+Filename: dna/utils.py
 Comment: 
 
-Filename: dna/pika_rpc.py
+Filename: dna/zone.py
 Comment: 
 
-Filename: dna/plot_utils.py
+Filename: dna/assoc/__init__.py
 Comment: 
 
-Filename: dna/types.py
+Filename: dna/assoc/association.py
 Comment: 
 
-Filename: dna/utils.py
+Filename: dna/assoc/associator_feature.py
+Comment: 
+
+Filename: dna/assoc/associator_motion.py
+Comment: 
+
+Filename: dna/assoc/closure.py
+Comment: 
+
+Filename: dna/assoc/collection.py
+Comment: 
+
+Filename: dna/assoc/schema.py
+Comment: 
+
+Filename: dna/assoc/tracklet_sync.py
+Comment: 
+
+Filename: dna/assoc/types.py
+Comment: 
+
+Filename: dna/assoc/utils.py
+Comment: 
+
+Filename: dna/assoc/windows.py
 Comment: 
 
 Filename: dna/camera/__init__.py
 Comment: 
 
 Filename: dna/camera/camera.py
 Comment: 
 
 Filename: dna/camera/image_processor.py
 Comment: 
 
 Filename: dna/camera/opencv_camera.py
 Comment: 
 
-Filename: dna/camera/range_camera.py
-Comment: 
-
 Filename: dna/camera/resized_camera.py
 Comment: 
 
-Filename: dna/camera/threaded_camera.py
+Filename: dna/camera/utils.py
 Comment: 
 
-Filename: dna/camera/utils.py
+Filename: dna/camera/video_writer.py
 Comment: 
 
 Filename: dna/detect/__init__.py
 Comment: 
 
 Filename: dna/detect/detecting_processor.py
 Comment: 
 
+Filename: dna/detect/detection.py
+Comment: 
+
 Filename: dna/detect/object_detector.py
 Comment: 
 
 Filename: dna/detect/utils.py
 Comment: 
 
 Filename: dna/detect/rcnn50_fpn/__init__.py
 Comment: 
 
 Filename: dna/detect/rcnn50_fpn/rcnn50_fpn_detector.py
 Comment: 
 
+Filename: dna/detect/rcnn50_fpn_v2/__init__.py
+Comment: 
+
+Filename: dna/detect/rcnn50_fpn_v2/rcnn50_fpn_v2_detector.py
+Comment: 
+
+Filename: dna/detect/ultralytics/__init__.py
+Comment: 
+
+Filename: dna/detect/ultralytics/ultralytics_detector.py
+Comment: 
+
 Filename: dna/detect/yolov4/__init__.py
 Comment: 
 
 Filename: dna/detect/yolov4/yolov4_detector.py
 Comment: 
 
 Filename: dna/detect/yolov4/tool/__init__.py
@@ -123,323 +159,338 @@
 
 Filename: dna/detect/yolov5/__init__.py
 Comment: 
 
 Filename: dna/detect/yolov5/yolov5_detector.py
 Comment: 
 
-Filename: dna/node/__init__.py
+Filename: dna/event/__init__.py
 Comment: 
 
-Filename: dna/node/drop_short_trail.py
+Filename: dna/event/event_processor.py
 Comment: 
 
-Filename: dna/node/event_processor.py
+Filename: dna/event/event_processors.py
 Comment: 
 
-Filename: dna/node/generate_local_path.py
+Filename: dna/event/kafka_event_publisher.py
 Comment: 
 
-Filename: dna/node/kafka_event.py
+Filename: dna/event/local_path_event.py
 Comment: 
 
-Filename: dna/node/kafka_event_publisher.py
+Filename: dna/event/track_event.py
 Comment: 
 
-Filename: dna/node/local_path_event.py
+Filename: dna/event/track_feature.py
 Comment: 
 
-Filename: dna/node/node_processor.py
+Filename: dna/event/tracklet_motion.py
 Comment: 
 
-Filename: dna/node/publish_events_execution.py
+Filename: dna/event/tracklet_store.py
 Comment: 
 
-Filename: dna/node/refine_track_event.py
+Filename: dna/event/types.py
 Comment: 
 
-Filename: dna/node/track_event.py
+Filename: dna/event/utils.py
 Comment: 
 
-Filename: dna/node/utils.py
+Filename: dna/event/proto/__init__.py
 Comment: 
 
-Filename: dna/node/world_transform.py
+Filename: dna/event/proto/node_processor_pb2.py
 Comment: 
 
-Filename: dna/tracker/__init__.py
+Filename: dna/event/proto/node_processor_pb2_grpc.py
 Comment: 
 
-Filename: dna/tracker/track_pipeline.py
+Filename: dna/event/proto/reid_feature_pb2.py
 Comment: 
 
-Filename: dna/tracker/tracker.py
+Filename: dna/node/__init__.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/__init__.py
+Filename: dna/node/drop_short_trail.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot_tracker.py
+Filename: dna/node/local_path_generator.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/centernet/__init__.py
+Filename: dna/node/node_event.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/centernet/config.py
+Filename: dna/node/node_processor.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/__init__.py
+Filename: dna/node/node_processor_grpc.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/config.py
+Filename: dna/node/publish_events_execution.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/data/__init__.py
+Filename: dna/node/refine_track_event.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/data/build_train_data_loader.py
+Filename: dna/node/reid_features.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/data/image_dataset.py
+Filename: dna/node/running_stabilizer.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/data/video_dataset.py
+Filename: dna/node/stabilizer.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/data/adapters/__init__.py
+Filename: dna/node/track_event_pipeline.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/data/adapters/augmentation/__init__.py
+Filename: dna/node/tracklet.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/data/adapters/augmentation/build_augmentation.py
+Filename: dna/node/tracklet_matcher.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/data/adapters/augmentation/image_augmentation.py
+Filename: dna/node/trajectory_drawer.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/data/adapters/augmentation/video_augmentation.py
+Filename: dna/node/utils.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/data/adapters/handler/__init__.py
+Filename: dna/node/world_coord_attach.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/data/adapters/handler/data_filtering.py
+Filename: dna/node/world_coord_localizer.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/data/adapters/utils/__init__.py
+Filename: dna/node/pika/__init__.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/data/adapters/utils/data_utils.py
+Filename: dna/node/pika/pika_execution.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/data/adapters/utils/dataset_info.py
+Filename: dna/node/pika/pika_execution_client.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/engine/__init__.py
+Filename: dna/node/pika/pika_execution_context.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/engine/custom_trainer.py
+Filename: dna/node/pika/pika_execution_server.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/engine/predictor.py
+Filename: dna/node/pika/pika_rpc.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/engine/vis.py
+Filename: dna/node/zone/__init__.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/eval/__init__.py
+Filename: dna/node/zone/motion_detector.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/eval/eval_clears_mot.py
+Filename: dna/node/zone/resident_changes.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/eval/eval_det_ap.py
+Filename: dna/node/zone/to_line_transform.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/eval/eval_utils.py
+Filename: dna/node/zone/types.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/modeling/__init__.py
+Filename: dna/node/zone/zone_event_generator.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/modeling/box_head/__init__.py
+Filename: dna/node/zone/zone_event_refiner.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/modeling/box_head/siam_fast_rcnn.py
+Filename: dna/node/zone/zone_pipeline.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/modeling/meta_arch/__init__.py
+Filename: dna/node/zone/zone_sequence_collector.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/modeling/meta_arch/rcnn.py
+Filename: dna/node/zone/zone_sequences_display.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/modeling/roi_heads/__init__.py
+Filename: dna/support/__init__.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/modeling/roi_heads/track_heads.py
+Filename: dna/support/func.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/modeling/track_head/__init__.py
+Filename: dna/support/iterables.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/modeling/track_head/track_head.py
+Filename: dna/support/plot_utils.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/modeling/track_head/track_solver.py
+Filename: dna/support/polygon_drawer.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/modeling/track_head/track_utils.py
+Filename: dna/support/rectangle_drawer.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/modeling/track_head/EMM/__init__.py
+Filename: dna/support/sql_utils.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/modeling/track_head/EMM/feature_extractor.py
+Filename: dna/support/text_line_writer.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/modeling/track_head/EMM/target_sampler.py
+Filename: dna/track/__init__.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/modeling/track_head/EMM/track_core.py
+Filename: dna/track/dna_track.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/modeling/track_head/EMM/track_loss.py
+Filename: dna/track/dna_track_params.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/modeling/track_head/EMM/xcorr.py
+Filename: dna/track/dna_tracker.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/operator_patch/__init__.py
+Filename: dna/track/feature_extractor.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/operator_patch/fpn_patch.py
+Filename: dna/track/kalman_filter.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/operator_patch/rpn_patch.py
+Filename: dna/track/siamese_net.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/operator_patch/run_operator_patch.py
+Filename: dna/track/track_pipeline.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/utils/__init__.py
+Filename: dna/track/track_state.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/utils/boxlists_to_entities.py
+Filename: dna/track/tracker.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/utils/entity_utils.py
+Filename: dna/track/types.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/utils/get_model_name.py
+Filename: dna/track/utils.py
 Comment: 
 
-Filename: dna/tracker/cnu_siammot/siammot/utils/registry.py
+Filename: dna/track/matcher/__init__.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/__init__.py
+Filename: dna/track/matcher/base.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/__logger.py
+Filename: dna/track/matcher/cost_matrices.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/deepsort_tracker.py
+Filename: dna/track/matcher/hungarian_matcher.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/deepsort/__init__.py
+Filename: dna/track/matcher/iou_dist_cost_matcher.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/deepsort/deepsort.py
+Filename: dna/track/matcher/matching_session.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/deepsort/detection.py
+Filename: dna/track/matcher/metric_assisted_cost_matcher.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/deepsort/iou_matching.py
+Filename: dna/track/matcher/metric_cost_matcher.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/deepsort/kalman_filter.py
+Filename: dna/track/matcher/reciprocal_cost_matcher.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/deepsort/linear_assignment.py
+Filename: pubsub/__init__.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/deepsort/matcher.py
+Filename: pubsub/pubsub.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/deepsort/nn_matching.py
+Filename: scripts/__init__.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/deepsort/siamese_net.py
+Filename: scripts/dna_assoc_tracklets.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/deepsort/track.py
+Filename: scripts/dna_backup_topics.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/deepsort/tracker.py
+Filename: scripts/dna_detect.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/deepsort/utils.py
+Filename: scripts/dna_download_node_events.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/deepsort/application_util/__init__.py
+Filename: scripts/dna_draw_trajs.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/deepsort/application_util/image_viewer.py
+Filename: scripts/dna_fuse_assoc_tracklets.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/deepsort/application_util/preprocessing.py
+Filename: scripts/dna_gen_trainset.py
 Comment: 
 
-Filename: dna/tracker/dna_deepsort/deepsort/application_util/visualization.py
+Filename: scripts/dna_gen_trainset2.py
 Comment: 
 
-Filename: pubsub/__init__.py
+Filename: scripts/dna_match_mc_tracklets.py
 Comment: 
 
-Filename: pubsub/pubsub.py
+Filename: scripts/dna_node.py
 Comment: 
 
-Filename: scripts/__init__.py
+Filename: scripts/dna_node_processor.py
 Comment: 
 
-Filename: scripts/dna_node.py
+Filename: scripts/dna_node_processor_client.py
 Comment: 
 
-Filename: scripts/dna_node_detect.py
+Filename: scripts/dna_reduce_trainset.py
 Comment: 
 
-Filename: scripts/dna_node_processor.py
+Filename: scripts/dna_replay_node_events.py
 Comment: 
 
-Filename: scripts/dna_node_processor_client.py
+Filename: scripts/dna_restore_topics.py
+Comment: 
+
+Filename: scripts/dna_show.py
+Comment: 
+
+Filename: scripts/dna_show_mc_locations.py
+Comment: 
+
+Filename: scripts/dna_show_multiple_videos.py
+Comment: 
+
+Filename: scripts/dna_store_topics.py
+Comment: 
+
+Filename: scripts/dna_sync_tracklets.py
 Comment: 
 
-Filename: scripts/dna_node_show.py
+Filename: scripts/dna_sync_videos.py
 Comment: 
 
-Filename: scripts/dna_node_track.py
+Filename: scripts/dna_track.py
 Comment: 
 
-Filename: scripts/dna_publish_event_server.py
+Filename: scripts/dna_tracklet.py
 Comment: 
 
-Filename: scripts/dna_publish_events.py
+Filename: scripts/utils.py
 Comment: 
 
-Filename: dna.node-1.0.0.dist-info/METADATA
+Filename: dna.node-2.1.1.dist-info/METADATA
 Comment: 
 
-Filename: dna.node-1.0.0.dist-info/WHEEL
+Filename: dna.node-2.1.1.dist-info/WHEEL
 Comment: 
 
-Filename: dna.node-1.0.0.dist-info/entry_points.txt
+Filename: dna.node-2.1.1.dist-info/entry_points.txt
 Comment: 
 
-Filename: dna.node-1.0.0.dist-info/top_level.txt
+Filename: dna.node-2.1.1.dist-info/top_level.txt
 Comment: 
 
-Filename: dna.node-1.0.0.dist-info/RECORD
+Filename: dna.node-2.1.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## conf/logger.yaml

```diff
@@ -1,54 +1,95 @@
-version: 1
-
-formatters:
-    standard:
-        format: "%(asctime)s %(levelname).5s [%(name)s] %(message)s (%(filename)s:%(lineno)d)"
-        datefmt: "%H:%M:%S"
-    error:
-        format: "%(levelname)s <PID %(process)d:%(processName)s> %(name)s.%(funcName)s(): %(message)s"
-        datefmt: "%Y-%m-%d %H:%M:%S"
-
-handlers:
-    console:
-        class: logging.StreamHandler
-        level: INFO
-        formatter: standard
-        stream: ext://sys.stdout
-
-    # info_file_handler:
-    #     class: logging.handlers.RotatingFileHandler
-    #     level: INFO
-    #     formatter: standard
-    #     filename: /tmp/info.log
-    #     maxBytes: 10485760 # 10MB
-    #     backupCount: 20
-    #     encoding: utf8
-
-    # error_file_handler:
-    #     class: logging.handlers.RotatingFileHandler
-    #     level: ERROR
-    #     formatter: error
-    #     filename: /tmp/errors.log
-    #     maxBytes: 10485760 # 10MB
-    #     backupCount: 20
-    #     encoding: utf8
-
-# root:
-#     level: NOTSET
-#     handlers: [console]
-#     propogate: yes
-
-loggers:
-    dna:
-        level: INFO
-        handlers: [console]
-        propagate: no
-    dna.image_processor:
-        level: INFO
-        handlers: [console]
-        propagate: no
-
-    # <module.x>:
-    #     level: DEBUG
-    #     handlers: [info_file_handler, error_file_handler, critical_file_handler, debug_file_handler, warn_file_handler]
+version: 1
+
+formatters:
+    standard:
+        format: "%(asctime)s %(levelname).4s [%(name)s] %(message)s (%(filename)s:%(lineno)d)"
+        datefmt: "%H:%M:%S"
+    error:
+        format: "%(levelname)s <PID %(process)d:%(processName)s> %(name)s.%(funcName)s(): %(message)s"
+        datefmt: "%Y-%m-%d %H:%M:%S"
+
+handlers:
+    console:
+        class: logging.StreamHandler
+        level: DEBUG
+        formatter: standard
+        stream: ext://sys.stdout
+
+    # info_file_handler:
+    #     class: logging.handlers.RotatingFileHandler
+    #     level: INFO
+    #     formatter: standard
+    #     filename: /tmp/info.log
+    #     maxBytes: 10485760 # 10MB
+    #     backupCount: 20
+    #     encoding: utf8
+
+    # error_file_handler:
+    #     class: logging.handlers.RotatingFileHandler
+    #     level: ERROR
+    #     formatter: error
+    #     filename: /tmp/errors.log
+    #     maxBytes: 10485760 # 10MB
+    #     backupCount: 20
+    #     encoding: utf8
+
+# root:
+#     level: NOTSET
+#     handlers: [console]
+#     propogate: yes
+
+loggers:
+    dna:
+        level: INFO
+        handlers: [console]
+        propagate: no
+    dna.envs:
+        level: INFO
+        handlers: [console]
+        propagate: no
+    dna.image_processor:
+        level: INFO
+        handlers: [console]
+        propagate: no
+    dna.tracker:
+        level: INFO
+        handlers: [console]
+        propagate: no
+    dna.node:
+        level: INFO
+        handlers: [console]
+        propagate: no
+    dna.node.event:
+        level: INFO
+        handlers: [console]
+        propagate: no
+    dna.node.zone:
+        level: INFO
+        handlers: [console]
+        propagate: no
+    dna.node.zone.zone:
+        level: INFO
+        handlers: [console]
+        propagate: no
+    dna.node.zone.motion:
+        level: INFO
+        handlers: [console]
+        propagate: no
+    dna.assoc:
+        level: DEBUG
+        handlers: [console]
+        propagate: no
+    dna.assoc.motion:
+        level: WARN
+        handlers: [console]
+        propagate: no
+
+    kafka:
+        level: WARN
+        handlers: [console]
+        propagate: no
+
+    # <module.x>:
+    #     level: DEBUG
+    #     handlers: [info_file_handler, error_file_handler, critical_file_handler, debug_file_handler, warn_file_handler]
     #     propogate: yes
```

## dna/__init__.py

```diff
@@ -1,13 +1,9 @@
-from .color import BGR, WHITE, RED
-from .types import Box, Size2d, Point, Image, Frame
-from .utils import gdown_file, initialize_logger
-from .pika_execution import PikaConnectionParameters, PikaExecutionServer
-from .conf import *
+from .types import Box, Size2d, Point, Image, Frame, ByteString
+from .color import BGR
+from .utils import initialize_logger
 
-__version__ = '1.0.0'
+__version__ = '2.1.1'
 
-# DEBUG_FRAME_IDX = -1
-# DEBUG_SHOW_IMAGE = False
-# DEBUG_PRINT_COST = DEBUG_SHOW_IMAGE
-# DEBUG_START_FRAME = 32
-# DEBUG_TARGET_TRACKS = None
+DEBUG_FRAME_INDEX = -1
+DEBUG_SHOW_IMAGE = False
+DEBUG_PRINT_COST = False
```

## dna/color.py

```diff
@@ -5,13 +5,28 @@
 WHITE = BGR(255,255,255)
 YELLOW = BGR(0,255,255)
 RED = BGR(0, 0, 255)
 PURPLE = BGR(128,0,128)
 MAGENTA = BGR(255,0,255)
 GREEN = BGR(0,255,0)
 BLUE = BGR(255,0,0)
+LAVENDER = BGR(250,230,230)
+SKYBLUE = BGR(235,206,135)
+INDIGO = BGR(130,0,75)
 LIGHT_GREY = BGR(211, 211, 211)
+ORANGE = BGR(0, 165, 255)
+OLIVE = BGR(0, 128, 128)
+DARK_OLIVE_GREEN = BGR(47, 107, 85)
+GOLD = BGR(0, 215, 255)
+SILVER = BGR(192, 192, 192)
+KHAKI = BGR(140, 230, 240)
+DARK_KHAKI = BGR(107, 183, 189)
+INDIAN_RED = BGR(92, 92, 205)
+TEAL = BGR(128, 0, 0)
+CYAN = BGR(255, 255, 0)
+GREY = BGR(128, 128, 128)
+DIM_GREY = BGR(105, 105, 105)
 
 import sys
 def name_to_color(name: str):
     current_module = sys.modules[__name__]
     return current_module.__dict__[name]
```

## dna/execution.py

```diff
@@ -1,236 +1,315 @@
-
-from datetime import time, timedelta
-from typing import Optional
-from abc import ABCMeta, abstractmethod
-
-from enum import Enum
-from logging import Logger
-
-class ExecutionState(Enum):
-    NOT_STARTED = 0
-    STARTING = 1
-    RUNNING = 2
-    STOPPING = 3
-    STOPPED = 4
-    FAILED = 5
-    COMPLETED = 6
-
-class Execution(metaclass=ABCMeta):
-    @abstractmethod
-    def run(self) -> object: pass
-
-class ExecutionContext(metaclass=ABCMeta):
-    @abstractmethod
-    def started(self) -> None: pass
-    
-    @abstractmethod
-    def report_progress(self, progress:object) -> None: pass
-
-    @abstractmethod
-    def completed(self, result:object) -> None: pass
-
-    @abstractmethod
-    def stopped(self, details:str) -> None: pass
-
-    @abstractmethod
-    def failed(self, cause:str) -> None: pass
-
-class NoOpExecutionContext(ExecutionContext):
-    def started(self) -> None: pass
-    def report_progress(self, progress:object) -> None: pass
-    def completed(self, result:object) -> None: pass
-    def stopped(self, details:str) -> None: pass
-    def failed(self, cause:str) -> None: pass
-
-class LoggingExecutionContext(ExecutionContext):
-    def __init__(self, logger:Logger=None) -> None:
-        super().__init__()
-        self.logger = logger
-
-    def started(self) -> None:
-        if self.logger is not None:
-            self.logger.info(f'started')
-
-    def report_progress(self, progress:object) -> None: 
-        if self.logger is not None:
-            self.logger.info(f'progress reported: progress={progress}')
-
-    def completed(self, result:object) -> None:
-        if self.logger is not None:
-            self.logger.info(f'completed: result={result}')
-
-    def stopped(self, details:str) -> None:
-        if self.logger is not None:
-            self.logger.info(f'stopped: details={details}')
-
-    def failed(self, cause:str) -> None:
-        if self.logger is not None:
-            self.logger.info(f'failed: cause={cause}')
-
-class ExecutionFactory(metaclass=ABCMeta):
-    @abstractmethod
-    def create(self, context:ExecutionContext) -> Execution: pass
-
-
-
-class CancellationError(Exception):
-    def __init__(self, message:str) -> None:
-        self.message = message
-        super().__init__(message)
-    
-class UserInterruptException(Exception):
-    def __init__(self) -> None:
-        super().__init__()
-
-
-import threading
-class AbstractExecution(Execution):
-    def __init__(self, report_interval=60*60, context:ExecutionContext= NoOpExecutionContext()):
-        self.ctx = context
-        
-        self.lock = threading.Lock()
-        self.cond = threading.Condition(self.lock)
-        self.state = ExecutionState.NOT_STARTED
-        self.stop_details = None
-
-        self.report_interval = report_interval
-        
-    def context(self) -> ExecutionContext:
-        return self.ctx
-        
-    @abstractmethod
-    def run_work(self) -> object: pass
-
-    @abstractmethod
-    def finalize(self) -> None: pass
-    
-    def check_stopped(self) -> None:
-        with self.lock:
-            if self.state == ExecutionState.STOPPING:
-                raise CancellationError(self.stop_details)
-
-    def run(self) -> object:
-        with self.lock:
-            if self.state != ExecutionState.NOT_STARTED:
-                raise AssertionError(f'invalid execution state: {self.state.name}, expected={ExecutionState.NOT_STARTED.name}')
-            self.state = ExecutionState.RUNNING
-            self.cond.notify_all()
-        self.ctx.started()
-        
-        try:
-            result = self.run_work()
-            with self.lock:
-                if self.state != ExecutionState.RUNNING and self.state != ExecutionState.STOPPING:
-                    raise AssertionError(f'invalid execution state: {self.state.name}, expected={ExecutionState.RUNNING.name}')
-                self.state = ExecutionState.COMPLETED
-                self.cond.notify_all()
-            self.ctx.completed(result)
-            
-            return result
-        except CancellationError as e:
-            with self.lock:
-                if self.state != ExecutionState.RUNNING and self.state != ExecutionState.STOPPING:
-                    raise AssertionError(f'invalid execution state: {self.state.name}, expected={ExecutionState.RUNNING.name}')
-                self.state = ExecutionState.STOPPED
-                self.cond.notify_all()
-            self.ctx.stopped(str(e))
-        except Exception as e:
-            with self.lock:
-                self.state = ExecutionState.FAILED
-                self.cond.notify_all()
-            self.ctx.failed(str(e))
-        finally:
-            self.finalize()
-        
-    def stop(self, details: str='user requested', nowait=False) -> None:
-        with self.lock:
-            if self.state == ExecutionState.RUNNING:
-                self.stop_details = details
-                self.state = ExecutionState.STOPPING
-                if not nowait:
-                    while self.state == ExecutionState.STOPPING:
-                        self.cond.wait()
-
-
-class InvocationError(Exception):
-    def __init__(self, message:str) -> None:
-        self.message = message
-        super().__init__(message)
-
-class TimeoutError(Exception):
-    def __init__(self, message:str) -> None:
-        self.message = message
-        super().__init__(message)
-
-class AsyncExecution(Execution):
-    def __init__(self) -> None:
-        self.lock = threading.Lock()
-        self.cond = threading.Condition(self.lock)
-        self.state = ExecutionState.NOT_STARTED
-        self.result = None
-        self.message = None
-
-    def is_started(self) -> bool:
-        with self.lock: return self.state >= ExecutionState.RUNNING
-
-    def is_running(self) -> bool:
-        with self.lock: return self.state == ExecutionState.RUNNING
-
-    def is_completed(self) -> bool:
-        with self.lock: return self.state == ExecutionState.COMPLETED
-
-    def is_failed(self) -> bool:
-        with self.lock: return self.state == ExecutionState.FAILED
-
-    def is_stopped(self) -> bool:
-        with self.lock: return self.state == ExecutionState.STOPPED
-
-    def wait_for_finished(self, timeout:float=timedelta.max.total_seconds()) -> ExecutionState:
-        due = time.time() + timeout
-        with self.lock:
-            while True:
-                timeout = due - time.time()
-                if self.cond.wait_for(lambda: self.state >= ExecutionState.STOPPED, timeout):
-                    return self.state
-                else:
-                    raise TimeoutError(f"timeout={timedelta(seconds=timeout)}")
-
-    def get(self, timeout:float=timedelta.max.total_seconds()) -> object:
-        due = time.time() + timeout
-        with self.lock:
-            while True:
-                timeout = due - time.time()
-                if self.cond.wait_for(lambda: self.state >= ExecutionState.STOPPED, timeout):
-                    if self.state == ExecutionState.COMPLETED:
-                        return self.result
-                    elif self.state == ExecutionState.STOPPED:
-                        raise CancellationError(self.message)
-                    elif self.state == ExecutionState.FAILED:
-                        raise InvocationError(self.message)
-                    else:
-                        raise AssertionError(f"unexpected state: {self.state}")
-                else:
-                    raise TimeoutError(f"timeout={timedelta(seconds=timeout)}")
-
-    def notify_started(self) -> None:
-        with self.lock:
-            self.state = ExecutionState.RUNNING
-            self.cond.notify_all()
-
-    def notify_completed(self, result: object) -> None:
-        with self.lock:
-            self.result = result
-            self.state = ExecutionState.COMPLETED
-            self.cond.notify_all()
-
-    def notify_stopped(self, message: str) -> None:
-        with self.lock:
-            self.message = message
-            self.state = ExecutionState.STOPPED
-            self.cond.notify_all()
-
-    def notify_failed(self, message: str) -> None:
-        with self.lock:
-            self.message = message
-            self.state = ExecutionState.FAILED
+
+from datetime import time, timedelta
+from typing import Optional
+from abc import ABCMeta, abstractmethod
+
+from enum import Enum
+from logging import Logger
+
+class ExecutionState(Enum):
+    NOT_STARTED = 0
+    '''Execution is not started.'''
+    STARTING = 1
+    '''Execution is preparing for start.'''
+    RUNNING = 2
+    '''Execution is running.'''
+    STOPPING = 3
+    '''Execution is stopping.'''
+    STOPPED = 4
+    '''Execution has been stopped by something.'''
+    FAILED = 5
+    '''Execution has been finished because of a failure'''
+    COMPLETED = 6
+    '''Execution has been done sucessfully.'''
+
+class Execution(metaclass=ABCMeta):
+    @abstractmethod
+    def run(self) -> object:
+        """본 실행을 수행시킨다.
+
+        Returns:
+            object: 실행 완료로 생성된 결과.
+        """
+        pass
+
+
+class ExecutionContext(metaclass=ABCMeta):
+    @abstractmethod
+    def started(self) -> None:
+        """실행이 시작됨을 알린다.
+        """
+        pass
+    
+    @abstractmethod
+    def report_progress(self, progress:object) -> None:
+        """실행 진행 상황을 알린다.
+
+        Args:
+            progress (object): 진행 상황 정보.
+        """
+        pass
+
+    @abstractmethod
+    def completed(self, result:object) -> None:
+        """실행이 완료됨을 알린다.
+        '실행 완료'는 실행이 그 목적을 모두 달성하고 종료되는 것을 믜미한다.
+
+        Args:
+            result (object): 실행 완료로 생성된 결과 객체.
+        """
+        pass
+
+    @abstractmethod
+    def stopped(self, details:str) -> None:
+        """사용자에 의해 실행이 중단됨을 알린다.
+
+        Args:
+            details (str): 실행 중단 원인.
+        """
+        pass
+
+    @abstractmethod
+    def failed(self, cause:str) -> None:
+        """실행 도중 오류가 발생하여 종료됨을 알린다.
+
+        Args:
+            cause (str): 오류 원인.
+        """
+        pass
+
+
+class NoOpExecutionContext(ExecutionContext):
+    def started(self) -> None: pass
+    def report_progress(self, progress:object) -> None: pass
+    def completed(self, result:object) -> None: pass
+    def stopped(self, details:str) -> None: pass
+    def failed(self, cause:str) -> None: pass
+
+
+class LoggingExecutionContext(ExecutionContext):
+    def __init__(self, logger:Logger=None) -> None:
+        super().__init__()
+        self.logger = logger
+
+    def started(self) -> None:
+        if self.logger is not None:
+            self.logger.info(f'started')
+
+    def report_progress(self, progress:object) -> None: 
+        if self.logger is not None:
+            self.logger.info(f'progress reported: progress={progress}')
+
+    def completed(self, result:object) -> None:
+        if self.logger is not None:
+            self.logger.info(f'completed: result={result}')
+
+    def stopped(self, details:str) -> None:
+        if self.logger is not None:
+            self.logger.info(f'stopped: details={details}')
+
+    def failed(self, cause:str) -> None:
+        if self.logger is not None:
+            self.logger.info(f'failed: cause={cause}')
+
+class ExecutionFactory(metaclass=ABCMeta):
+    @abstractmethod
+    def create(self, context:ExecutionContext) -> Execution:
+        """새로운 실행 객체를 생성한다.
+        본 메소드를 통해 실행 객체가 생성만되지, 그 실행이 시작되지는 않는다.
+
+        Args:
+            context (ExecutionContext): 실행 과정에서 사용될 문맥 정보 객체.
+
+        Returns:
+            Execution: 생성된 실행 객체.
+        """
+        pass
+
+
+
+class CancellationError(Exception):
+    def __init__(self, message:str) -> None:
+        self.message = message
+        super().__init__(message)
+
+
+import threading
+class AbstractExecution(Execution):
+    def __init__(self, context:Optional[ExecutionContext]=None):
+        self._ctx = context if context else NoOpExecutionContext()
+        
+        self.lock = threading.Lock()
+        self.cond = threading.Condition(self.lock)
+        self.state = ExecutionState.NOT_STARTED
+        self.stop_details = None
+        
+    @property
+    def context(self) -> ExecutionContext:
+        return self._ctx
+        
+    @abstractmethod
+    def run_work(self) -> object:
+        """본 실행이 수행해야 하는 작업을 수행한다.
+        본 메소드는 ``run()`` 메소드가 호출되는 경우, 자동적으로 수행된다.
+
+        Returns:
+            object: 실행 결과.
+        """
+        pass
+
+    @abstractmethod
+    def finalize(self) -> None:
+        """본 실행이 종료될 때, 종료화 작업을 수행한다.
+        """
+        pass
+    
+    def check_stopped(self) -> None:
+        with self.lock:
+            if self.state == ExecutionState.STOPPING:
+                raise CancellationError(self.stop_details)
+
+    def run(self) -> object:
+        with self.lock:
+            if self.state != ExecutionState.NOT_STARTED:
+                raise AssertionError(f'invalid execution state: {self.state.name}, ',
+                                     f'expected={ExecutionState.NOT_STARTED.name}')
+            self.state = ExecutionState.RUNNING
+            self.cond.notify_all()
+        self._ctx.started()
+        
+        try:
+            result = self.run_work()
+            
+            state = None
+            with self.lock:
+                if self.state == ExecutionState.RUNNING:
+                    state = self.state = ExecutionState.COMPLETED
+                elif self.state == ExecutionState.STOPPING:
+                    state = self.state = ExecutionState.STOPPED
+                else:
+                    raise AssertionError(f'invalid execution state: {self.state.name}, '
+                                            f'expected={ExecutionState.RUNNING.name}')
+                self.cond.notify_all()
+            if state == ExecutionState.COMPLETED:
+                self._ctx.completed(result)
+            elif state == ExecutionState.STOPPED:
+                self._ctx.stopped('user requested')
+            return result
+        except CancellationError as e:
+            with self.lock:
+                if self.state != ExecutionState.RUNNING and self.state != ExecutionState.STOPPING:
+                    raise AssertionError(f'invalid execution state: {self.state.name}, expected={ExecutionState.RUNNING.name}')
+                self.state = ExecutionState.STOPPED
+                self.cond.notify_all()
+            self._ctx.stopped(str(e))
+        except Exception as e:
+            with self.lock:
+                self.state = ExecutionState.FAILED
+                self.cond.notify_all()
+            self._ctx.failed(str(e))
+            raise e
+        finally:
+            self.finalize()
+        
+    def stop(self, details: str='user requested', nowait=False) -> None:
+        with self.lock:
+            if self.state == ExecutionState.RUNNING:
+                self.stop_details = details
+                self.state = ExecutionState.STOPPING
+            else:
+                return
+                
+        self.stop_work()        
+        if not nowait:
+            with self.lock:
+                while self.state == ExecutionState.STOPPING:
+                    self.cond.wait()
+                    
+    @abstractmethod
+    def stop_work(self) -> None: pass
+
+
+class InvocationError(Exception):
+    def __init__(self, message:str) -> None:
+        self.message = message
+        super().__init__(message)
+
+
+class TimeoutError(Exception):
+    def __init__(self, message:str) -> None:
+        self.message = message
+        super().__init__(message)
+
+
+class AsyncExecution(Execution):
+    def __init__(self) -> None:
+        self.lock = threading.Lock()
+        self.cond = threading.Condition(self.lock)
+        self.state = ExecutionState.NOT_STARTED
+        self.result = None
+        self.message = None
+
+    def is_started(self) -> bool:
+        with self.lock: return self.state >= ExecutionState.RUNNING
+
+    def is_running(self) -> bool:
+        with self.lock: return self.state == ExecutionState.RUNNING
+
+    def is_completed(self) -> bool:
+        with self.lock: return self.state == ExecutionState.COMPLETED
+
+    def is_failed(self) -> bool:
+        with self.lock: return self.state == ExecutionState.FAILED
+
+    def is_stopped(self) -> bool:
+        with self.lock: return self.state == ExecutionState.STOPPED
+
+    def wait_for_finished(self, timeout:float=timedelta.max.total_seconds()) -> ExecutionState:
+        due = time.time() + timeout
+        with self.lock:
+            while True:
+                timeout = due - time.time()
+                if self.cond.wait_for(lambda: self.state >= ExecutionState.STOPPED, timeout):
+                    return self.state
+                else:
+                    raise TimeoutError(f"timeout={timedelta(seconds=timeout)}")
+
+    def get(self, timeout:float=timedelta.max.total_seconds()) -> object:
+        due = time.time() + timeout
+        with self.lock:
+            while True:
+                timeout = due - time.time()
+                if self.cond.wait_for(lambda: self.state >= ExecutionState.STOPPED, timeout):
+                    if self.state == ExecutionState.COMPLETED:
+                        return self.result
+                    elif self.state == ExecutionState.STOPPED:
+                        raise CancellationError(self.message)
+                    elif self.state == ExecutionState.FAILED:
+                        raise InvocationError(self.message)
+                    else:
+                        raise AssertionError(f"unexpected state: {self.state}")
+                else:
+                    raise TimeoutError(f"timeout={timedelta(seconds=timeout)}")
+
+    def notify_started(self) -> None:
+        with self.lock:
+            self.state = ExecutionState.RUNNING
+            self.cond.notify_all()
+
+    def notify_completed(self, result: object) -> None:
+        with self.lock:
+            self.result = result
+            self.state = ExecutionState.COMPLETED
+            self.cond.notify_all()
+
+    def notify_stopped(self, message: str) -> None:
+        with self.lock:
+            self.message = message
+            self.state = ExecutionState.STOPPED
+            self.cond.notify_all()
+
+    def notify_failed(self, message: str) -> None:
+        with self.lock:
+            self.message = message
+            self.state = ExecutionState.FAILED
             self.cond.notify_all()
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## dna/types.py

```diff
@@ -1,362 +1,692 @@
 from __future__ import annotations
+from typing import TypeAlias, NewType, Optional, Union
+from collections.abc import Iterable, Sequence, Callable
 
+import numbers
 from dataclasses import dataclass, field
-from typing import List, NewType, Tuple, Optional, Union
 import math
 
 import numpy as np
-import cv2
+import numpy.typing as npt
 
 from .color import BGR
 
+Image = NewType('Image', np.ndarray)
+
+ByteString: TypeAlias = Union[bytes, bytearray, memoryview]
+
 
 class Point:
-    __slots__ = ('__xy', )
+    """A point coordinate in 2d plane.
 
-    def __init__(self, x: Union[int, float], y: Union[int, float]) -> None:
-        self.__xy = np.array([x, y])
+    Attributes:
+        xy (numpy.ndarray): (x,y) coordinate as a numpy array.
+    """
+    __slots__ = ('xy', )
 
-    @property
-    def x(self) -> Union[int, float]:
-        return self.__xy[0]
+    def __init__(self, xy:npt.ArrayLike) -> None:
+        """(x,y) 좌표를 갖는 Point 객체를 반환한다.
 
-    @property
-    def y(self) -> Union[int, float]:
-        return self.__xy[1]
+        Args:
+            xy (npt.ArrayLike): (x,y) 좌표
+        """
+        self.xy:np.ndarray = np.array(xy)
 
     @property
-    def xy(self):
-        return self.__xy
+    def x(self) -> Union[int,float]:
+        """Point 객체 좌표의 x축 값.
 
-    def to_tuple(self) -> Tuple[Union[int, float], Union[int, float]]:
-        return tuple(self.__xy)
+        Returns:
+            Union[int,float]: 좌표의 x축 값.
+        """
+        return self.xy[0]
 
-    @classmethod
-    def from_np(cls, xy: np.ndarray) -> Point:
-        return Point(xy[0], xy[1])
+    @property
+    def y(self) -> Union[int,float]:
+        """Point 객체 좌표의 y축 값.
+
+        Returns:
+            Union[int,float]: 좌표의 y축 값.
+        """
+        return self.xy[1]
+        
+    def __array__(self, dtype=None):
+        if not dtype or dtype == self.xy.dtype:
+            return self.xy
+        else:
+            return self.xy.astype(dtype)
 
     def distance_to(self, pt:Point) -> float:
+        """Returns an Euclidean distance to the point pt.
+
+        Args:
+            pt (Point): target Point object to calculate distance to.
+
+        Returns:
+            float: distance.
+        """
         return np.linalg.norm(self.xy - pt.xy)
 
-    def angle_with(self, pt:Point) -> float:
-        delta = pt - self
-        return math.atan2(delta.height, delta.width)
+    def angle_between(self, pt:Point) -> float:
+        """본 Point 객체 벡터와 인자 Point 객체 벡터 사이의 각(radian)을 반환한다.
 
-    @staticmethod
-    def line_function(pt1:Point, pt2:Point):
-        delta = pt1.xy - pt2.xy
+        Args:
+            pt (Point): 각을 계산할 대상 Point 객체.
+
+        Returns:
+            float: 두 벡터 사이의 각 (단위: radian)
+        """
+        return np.arctan2(np.cross(self.xy, pt.xy), np.dot(self.xy, pt.xy))
+
+    def line_function_to(self, pt2:Point) -> Callable[[numbers.Number],numbers.Number]:
+        """본 Point 객체와 인자로 주어진 Point까지를 잇는 1차원 함수를 반환한다.
+
+        Args:
+            pt2 (Point): 목표 Point 객체.
+
+        Raises:
+            ValueError: 목표 Point 객체의 위치를 잇는 1차원 함수를 구할 수 없는 경우.
+                        예를들어 두 Point의 x좌표가 동일한 경우.
+
+        Returns:
+            Callable[[numbers.Number],numbers.Number]: 1차원 함수.
+        """
+        delta = self.xy - pt2.xy
         if delta[0] == 0:
-            raise ValueError(f"Cannot find a line function: {pt1} - {pt2}")
+            raise ValueError(f"Cannot find a line function: {self} - {pt2}")
         slope = delta[1] / delta[0]
         y_int = pt2.y - (slope * pt2.x)
 
         def func(x):
             return (slope * x) + y_int
         return func
 
-    @staticmethod
-    def split_points(pt1:Point, pt2:Point, npoints:int) -> List[Point]:
-        func = Point.line_function(pt1, pt2)
-        step_x = (pt2.x - pt1.x) / (npoints+1)
-        xs = [pt1.x + (idx * step_x) for idx in range(1, npoints+1)]
-        return [Point.from_np(np.array([x, func(x)])) for x in xs]
+    def split_points_to(self, pt2:Point, npoints:int) -> list[Point]:
+        func = self.line_function_to(pt2)
+        step_x = (pt2.x - self.x) / (npoints+1)
+        xs = [self.x + (idx * step_x) for idx in range(1, npoints+1)]
+        return [Point([x, func(x)]) for x in xs]
+
+    def to_rint(self) -> Point:
+        """본 Point 객체의 좌표값을 int형식으로 반올림한 좌표를 갖는 Point 객체를 반환한다.
+
+        Returns:
+            Point: int형식으로 반올림한 좌표를 갖는 Point 객체.
+        """
+        return Point(np.rint(self.xy).astype(int))
 
     def __add__(self, rhs) -> Point:
         if isinstance(rhs, Point):
-            return Point.from_np(self.xy + rhs.xy)
+            return Point(self.xy + rhs.xy)
         elif isinstance(rhs, Size2d):
-            return Point.from_np(self.xy + rhs.wh)
+            return Point(self.xy + rhs.wh)
         elif (isinstance(rhs, np.ndarray) or isinstance(rhs, tuple) or isinstance(rhs, list)) and len(rhs) >= 2:
-            return Point(self.x + rhs[0], self.y + rhs[1])
+            return Point(self.xy + np.array(rhs))
         elif isinstance(rhs, int) or isinstance(rhs, float):
-            return Point(self.x + rhs, self.y + rhs)
+            return Point(self.xy + rhs)
         else:
             raise ValueError(f"invalid rhs: rhs={rhs}")
 
     def __sub__(self, rhs) -> Union[Point,Size2d]:
         if isinstance(rhs, Point):
-            return Size2d.from_np(self.xy - rhs.xy)
+            return Size2d(self.xy - rhs.xy)
         elif isinstance(rhs, Size2d):
-            return Point.from_np(self.xy - rhs.wh)
-        elif isinstance(rhs, tuple) and len(rhs) >= 2:
-            return Point(self.x - rhs[0], self.y - rhs[1])
+            return Point(self.xy - rhs.wh)
+        elif (isinstance(rhs, np.ndarray) or isinstance(rhs, tuple) or isinstance(rhs, list)) and len(rhs) >= 2:
+            return Point(self.xy - np.array(rhs))
         elif isinstance(rhs, int) or isinstance(rhs, float):
-            return Point(self.x - rhs, self.y - rhs)
+            return Point(self.xy - rhs)
         else:
             raise ValueError(f"invalid rhs: rhs={rhs}")
 
     def __mul__(self, rhs) -> Point:
         if isinstance(rhs, int) or isinstance(rhs, float):
-            return Point(self.x * rhs, self.y * rhs)
+            return Point(self.xy * rhs)
         elif isinstance(rhs, Size2d):
-            return Point.from_np(self.xy * rhs.wh)
-        elif isinstance(rhs, tuple) and len(rhs) >= 2:
-            return Point(self.x * rhs[0], self.y * rhs[1])
+            return Point(self.xy * rhs.wh)
+        elif (isinstance(rhs, np.ndarray) or isinstance(rhs, tuple) or isinstance(rhs, list)) and len(rhs) >= 2:
+            return Point(self.xy * np.array(rhs))
         else:
             raise ValueError(f"invalid rhs: rhs={rhs}")
 
     def __truediv__(self, rhs) -> Point:
         if isinstance(rhs, Size2d):
-            return Point(self.x / rhs.width, self.y / rhs.height)
+            return Point(self.xy / rhs.wh)
         elif isinstance(rhs, int) or isinstance(rhs, float):
-            return Point(self.x / rhs, self.y / rhs)
+            return Point(self.xy / rhs)
         else:
             raise ValueError('invalid right-hand-side:', rhs)
     
     def __repr__(self) -> str:
         if isinstance(self.xy[0], np.int32):
             return '({},{})'.format(*self.xy)
         else:
             return '({:.1f},{:.1f})'.format(*self.xy)
 
+
 class Size2d:
-    __slots__ = ('__wh',)
+    """A size object in 2d plane.
+
+    Attributes:
+        wh (numpy.ndarray): (width, height) as a numpy array.
+    """
+    __slots__ = ('wh',)
+
+    def __init__(self, wh:npt.ArrayLike) -> None:
+        """width와 height를 구성된 Size2d 객체를 반환한다.
+
+        Args:
+            wh (npt.ArrayLike): 2차원 크기의 넓이(w)와 높이(h) 값의 배열
+        """
+        self.wh = np.array(wh)
+
+    @staticmethod
+    def from_expr(expr:object) -> Size2d:
+        """인자 값을 'Size2d' 객체로 형 변화시킨다.
+        - 인자가 None인 경우는 None을 반환한다.
+        - 인자가 Size2d인 경우는 별도의 변환없이 인자를 복사하여 반환한다.
+        - 인자가 문자열인 경우에는 '<width> x <height>' 형식으로 파싱하여 Size2d를 생성함.
+        - 그렇지 않은 경우는 numpy.array() 함수를 통해 numpy array로 변환하고 이를 다시 Size2d로 생성함.
+
+        Args:
+            expr (object): 형 변환시킬 대상 객체.
+
+        Returns:
+            Size2d: 형 변환된 Size2d 객체.
+        """
+        if expr is None:
+            return None
+        elif isinstance(expr, Size2d):
+            return Size2d(expr.wh)
+        elif isinstance(expr, str):
+            return Size2d.parse_string(expr)
+        else:
+            return Size2d(expr)
+
+    @staticmethod
+    def parse_string(expr:str) -> Size2d:
+        """'<width> x <height>' 형식으로 표기된 문자열을 파싱하여 Size2d 객체를 생성한다.
+
+        Args:
+            expr (str): '<width> x <height>' 형식의 문자열.
 
-    def __init__(self, width: Union[int, float], height: Union[int, float]) -> None:
-        self.__wh = np.array([width, height])
+        Raises:
+            ValueError: '<width> x <height>' 형식의 문자열이 아닌 경우.
 
-    @classmethod
-    def from_np(cls, wh:np.ndarray) -> Size2d:
-        return Size2d(wh[0], wh[1])
-
-    @classmethod
-    def parse_string(cls, expr:str) -> Size2d:
-        parts: List[int] = [int(p) for p in expr.split("x")]
+        Returns:
+            Size2d: Size2d 객체.
+        """
+        parts: list[float] = [float(p) for p in expr.split("x")]
         if len(parts) == 2:
-            return Size2d(parts[0], parts[1])
+            return Size2d(parts)
         raise ValueError(f"invalid Size2d string: {expr}")
 
+    def is_valid(self) -> bool:
+        """Size2d 객체의 유효성 여부를 반환한다.
+
+        Returns:
+            bool: 유효성 여부. 넓이와 높이가 모두 0보다 크거나 같은지 여부.
+        """
+        return self.wh[0] >= 0 and self.wh[1] >= 0
+    
     @staticmethod
-    def from_conf(expr:object) -> Size2d:
-        if isinstance(expr, str):
-            return Size2d.parse_string(expr)
-        elif isinstance(expr, Size2d):
-            return expr
-        elif hasattr(expr, "__getitem__"):
-            return Size2d(expr[0], expr[1])
-        else:
-            raise ValueError(f'invalid Size2d expression: {expr}')
-
-    def to_tuple(self) -> Tuple[Union[int, float],Union[int, float]]:
-        return tuple(np.rint(self.wh).astype(int))
-        # return tuple(self.__wh)
+    def from_image(img:np.ndarray) -> Size2d:
+        """주어진 OpenCV 이미지의 크기를 반환한다.
 
-    def is_valid(self) -> bool:
-        return self.__wh[0] >= 0 and self.__wh[1] >= 0
+        Args:
+            img (np.ndarray): OpenCV 이미지 객체.
 
-    @property
-    def wh(self) -> np.ndarray:
-        return self.__wh
+        Returns:
+            Size2d: 이미지 크기 (width, height)
+        """
+        h, w, _ = img.shape
+        return Size2d([w, h])
 
     @property
-    def width(self) -> Union[int, float]:
-        return self.__wh[0]
+    def width(self) -> Union[int,float]:
+        """본 Size2d의 넓이 값.
+
+        Returns:
+            Union[int,float]: 본 Size2d의 넓이 값.
+        """
+        return self.wh[0]
     
     @property
-    def height(self) -> Union[int, float]:
-        return self.__wh[1]
+    def height(self) -> Union[int,float]:
+        """본 Size2d의 높이 값.
 
-    def aspect_ratio(self) -> float:
-        return self.__wh[0] / self.__wh[1]
+        Returns:
+            Union[int,float]: 본 Size2d의 높이 값.
+        """
+        return self.wh[1]
+    
+    def __iter__(self):
+        return (c for c in self.wh)
+        
+    def __array__(self, dtype=None):
+        if not dtype or dtype == self.wh.dtype:
+            return self.wh
+        else:
+            return self.wh.astype(dtype)
 
-    def area(self) -> float:
-        return self.__wh[0] * self.__wh[1]
+    def aspect_ratio(self) -> float:
+        """본 Size2d의 aspect ratio (=w/h)를 반환한다.
 
-    def abs(self) -> Size2d:
-        return Size2d.from_np(np.abs(self.__wh))
+        Returns:
+            float: aspect ratio
+        """
+        return self.wh[0] / self.wh[1]
 
-    def to_int(self) -> Size2d:
-        return Size2d.from_np(np.rint(self.wh).astype(int))
+    def area(self) -> float:
+        """본 Size2d에 해당하는 영역을 반환한다.
 
-    def norm(self):
-        return np.linalg.norm(self.wh)
+        Returns:
+            float: 영역.
+        """
+        return self.wh[0] * self.wh[1]
+
+    def to_rint(self) -> Size2d:
+        """본 Size2d 크기 값을 int형식으로 반올림한 값을 갖는 Size2d 객체를 반환한다.
+
+        Returns:
+            Size2d: int형식으로 반올림한 크기를 갖는 Size2d 객체.
+        """
+        return Size2d(np.rint(self.wh).astype(int))
+    
+    def __hash__(self):
+        return hash(tuple(self))
 
     def __add__(self, rhs) -> Size2d:
         if isinstance(rhs, Size2d):
-            return Size2d.from_np(self.wh + rhs.wh)
+            return Size2d(self.wh + rhs.wh)
         elif isinstance(rhs, int) or isinstance(rhs, float):
-            return Size2d.from_np(self.wh - np.array([rhs, rhs]))
+            return Size2d(self.wh + rhs)
         else:
-            raise ValueError('invalid right-hand-side:', rhs)
+            return Size2d(self.wh + np.array(rhs))
 
     def __sub__(self, rhs) -> Size2d:
         if isinstance(rhs, Size2d):
-            return Size2d.from_np(self.wh - rhs.wh)
+            return Size2d(self.wh - rhs.wh)
         elif isinstance(rhs, int) or isinstance(rhs, float):
-            return Size2d.from_np(self.wh - np.array([rhs, rhs]))
+            return Size2d(self.wh - rhs)
         else:
-            raise ValueError('invalid right-hand-side:', rhs)
+            return Size2d(self.wh - np.array(rhs))
 
     def __mul__(self, rhs) -> Size2d:
         if isinstance(rhs, Size2d):
-            return Size2d.from_np(self.wh * rhs.wh)
+            return Size2d(self.wh * rhs.wh)
         elif isinstance(rhs, int) or isinstance(rhs, float):
-            return Size2d.from_np(self.wh * np.array([rhs, rhs]))
+            return Size2d(self.wh * rhs)
         else:
-            raise ValueError('invalid right-hand-side:', rhs)
+            return Size2d(self.wh * np.array(rhs))
 
     def __truediv__(self, rhs) -> Size2d:
         if isinstance(rhs, Size2d):
-            return Size2d.from_np(self.wh / rhs.wh)
+            return Size2d(self.wh / rhs.wh)
         elif isinstance(rhs, int) or isinstance(rhs, float):
-            return Size2d.from_np(self.wh / np.array([rhs, rhs]))
+            return Size2d(self.wh / rhs)
         else:
-            raise ValueError('invalid right-hand-side:', rhs)
+            return Size2d(self.wh / np.array(rhs))
 
     def __eq__(self, other):
         if isinstance(other, Size2d):
-            return np.array_equal(self.__wh, other.__wh)
+            return np.array_equal(self.wh, other.wh)
         else:
             return False
+
+    def __gt__(self, other:Size2d):
+        if isinstance(other, Size2d):
+            return self.wh[0] > other.wh[0] and self.wh[1] > other.wh[1]
+        else:
+            raise ValueError(f'invalid Size2d object: {self}')
+
+    def __ge__(self, other:Size2d):
+        if isinstance(other, Size2d):
+            return self.wh[0] >= other.wh[0] and self.wh[1] >= other.wh[1]
+        else:
+            raise ValueError(f'invalid Size2d object: {self}')
+
+    def __lt__(self, other:Size2d):
+        if isinstance(other, Size2d):
+            return self.wh[0] < other.wh[0] and self.wh[1] < other.wh[1]
+        else:
+            raise ValueError(f'invalid Size2d object: {self}')
+
+    def __le__(self, other:Size2d):
+        if isinstance(other, Size2d):
+            return self.wh[0] <= other.wh[0] and self.wh[1] <= other.wh[1]
+        else:
+            raise ValueError(f'invalid Size2d object: {self}')
     
     def __repr__(self) -> str:
         if isinstance(self.wh[0], np.int32):
-            return '{}x{}'.format(*self.__wh)
+            return '{}x{}'.format(*self.wh)
         else:
-            return '{:.1f}x{:.1f}'.format(*self.__wh)
-EMPTY_SIZE2D: Size2d = Size2d(-1, -1)
+            return '{:.1f}x{:.1f}'.format(*self.wh)
+INVALID_SIZE2D: Size2d = Size2d([-1, -1])
 
 
 class Box:
-    __slots__ = ('__tlbr', )
+    """A box object in 2d plane.
+
+    Attributes:
+        tlbr (numpy.ndarray): (x1, y1, x2, y2), where (x1, y1) is the coordinate of the top-left corner
+                                and (x2, y2) is the coordinate of the bottom-right corner as a numpy arrays.
+    """
+    __slots__ = ('tlbr', )
+
+    def __init__(self, tlbr:npt.ArrayLike) -> None:
+        """두 개의 좌표 (x1,y2), (x2, y2) 로 구성된 Box 객체를 반환한다.
+
+        Args:
+            tlbr (npt.ArrayLike): (l,t), (r, b) 좌표
+        """
+        tlbr = np.array(tlbr)
+        if tlbr.shape == (2,2):
+            tlbr = tlbr.flatten()
+        self.tlbr = tlbr
 
-    def __init__(self, tlbr: np.ndarray) -> None:
-        self.__tlbr = np.array(tlbr)
+    @staticmethod
+    def from_points(tl:Point, br:Point) -> Box:
+        """두 개의 Point tl, br로 구성된 Box 객체를 반환한다.
 
-    @classmethod
-    def from_points(self, tl: Point, br: Point) -> Box:
+        Args:
+            tl (Point): 왼쪽 위 꼭지점 좌표.
+            br (Point): 오른쪽 아래 꼭지점 좌표.
+
+        Returns:
+            Box: Box 객체
+        """
         return Box(np.hstack([tl.xy, br.xy]))
 
-    @classmethod
-    def from_tlbr(cls, tlbr: np.ndarray) -> Box:
-        return Box(tlbr)
+    @staticmethod
+    def  from_tlwh(tlwh:npt.ArrayLike) -> Box:
+        """Box의 좌상단 꼭지점의 좌표와 box의 넓이와 높이 정보를 이용하여 Box 객체를 생성한다.
 
-    @classmethod
-    def from_tlwh(cls, tlwh: np.ndarray) -> Box:
+        Args:
+            tlwh (npt.ArrayLike): 좌상단 꼭지점의 좌표 (tl)와 넓이(w)와 높이(h)
+
+        Returns:
+            Box: Box 객체
+        """
+        tlwh = np.array(tlwh)
         tlbr = tlwh.copy()
         tlbr[2:] = tlwh[:2] + tlwh[2:]
         return Box(tlbr)
 
     @staticmethod
-    def from_size(size:Size2d) -> Box:
-        return Box.from_tlbr(np.array([0, 0, size.width, size.height]))
+    def from_size(size:Union[Size2d,npt.ArrayLike]) -> Box:
+        """
+        Create a box object of the given size.
+        The top-left corner of the create box will be (0, 0).
+
+        Args:
+            size (Union[Size2d,npt.ArrayLike]): the size of the created box.
+
+        Returns:
+            Box: a Box object.
+        """
+        w, h = tuple(size.wh) if isinstance(size, Size2d) else tuple(np.array(size))
+        return Box([0, 0, w, h])
+    
+    @staticmethod
+    def from_image(img:np.ndarray) -> Box:
+        h, w, _ = img.shape
+        return Box([0, 0, w, h])
+
+    def translate(self, delta:Union[Size2d,npt.ArrayLike]) -> Box:
+        """본 Box 객체를 주어진 거리만큼 평행 이동시킨다.
+
+        Args:
+            delta (Union[Size2d,npt.ArrayLike]): 평행 이동 거리.
+
+        Returns:
+            Box: 평행 이동된 Box 객체.
+        """
+        w, h = tuple(delta.wh) if isinstance(delta, Size2d) else tuple(np.array(delta))
+        delta = np.array([w, h, w, h])
+        return Box(self.tlbr + delta)
 
     def is_valid(self) -> bool:
-        wh = self.wh
-        return wh[0] >= 0 and wh[1] >= 0
+        """본 Box의 유효성 여부를 반환한다.
 
-    def to_tlbr(self) -> np.ndarray:
-        return self.__tlbr
+        Returns:
+            bool: 유효성 여부.  l <= r and t <= b
+        """
+        return self.tlbr[0] <= self.tlbr[2] and self.tlbr[1] <= self.tlbr[3]
+        
+    def __array__(self, dtype=None):
+        if not dtype or dtype == self.xy.dtype:
+            return self.tlbr
+        else:
+            return self.tlbr.astype(dtype)
 
-    def to_tlwh(self) -> np.ndarray:
-        tlwh = self.__tlbr.copy()
+    @property
+    def tlwh(self) -> np.ndarray:
+        """``tlwh`` (top-left corner coordinates, width, and height) of this box object.
+
+        Returns:
+            np.ndarray: ``tlwh`` (top-left corner coordinates, width, and height)
+        """
+        tlwh = self.tlbr.copy()
         tlwh[2:] = self.br - self.tl
         return tlwh
 
-    def to_xyah(self) -> np.ndarray:
-        ret = self.to_tlwh()
+    @property
+    def xyah(self) -> np.ndarray:
+        """``xyah`` (x/y coordinate for the top-left corner, aspect ratio, and height) of this box object.
+
+        Returns:
+            np.ndarray: ``xyah`` (x/y coordinate for the top-left corner, aspect ratio, and height)
+        """
+        ret = self.tlwh
         ret[:2] += ret[2:] / 2
         ret[2] /= ret[3]
         return ret
 
     def to_rint(self) -> Box:
-        return Box(np.rint(self.__tlbr).astype(int))
+        """Returns a box object whose coordindates are round to integers.
+
+        Returns:
+            Box: ``Box`` object of integer coordinates.
+        """
+        return Box(np.rint(self.tlbr).astype(int))
 
     @property
     def tl(self) -> np.ndarray:
-        return self.__tlbr[:2]
+        '''Returns the coordinate of top-left corner of this box object.'''
+        return self.tlbr[:2]
 
     @property
     def br(self) -> np.ndarray:
-        return self.__tlbr[2:]
+        '''Returns the coordinate of bottom-right corner of this box object.'''
+        return self.tlbr[2:]
 
     @property
     def wh(self) -> np.ndarray:
+        '''Returns width and height pair of this box object.'''
         return self.br - self.tl
 
     @property
     def width(self) -> Union[float,int]:
+        '''Returns width of this box object.'''
         return self.wh[0]
 
     @property
     def height(self) -> Union[float,int]:
+        '''Returns height of this box object.'''
         return self.wh[1]
+    
+    @property
+    def coords(self) -> List:
+        """Returns a list of four corners of this box object.
+        The order of corners are top-left, top-right, bottom-right, bottom-left.
+
+        Returns:
+            List: a list of corner coordinates.
+        """
+        return [[self.tlbr[0], self.tlbr[1]],
+                [self.tlbr[2], self.tlbr[1]],
+                [self.tlbr[2], self.tlbr[3]],
+                [self.tlbr[0], self.tlbr[3]]]
 
     def top_left(self) -> Point:
-        return Point.from_np(self.tl)
+        '''Returns the ``Point`` object of top-left corner of this box object.'''
+        return Point(self.tl)
 
     def bottom_right(self) -> Point:
-        return Point.from_np(self.br)
+        '''Returns the ``Point`` object of bottom-right corner of this box object.'''
+        return Point(self.br)
 
     def center(self) -> Point:
-        return Point.from_np(self.tl + (self.wh / 2.))
+        '''Returns the ``Point`` object of the center of this box object.'''
+        return Point(self.tl + (self.wh / 2.))
 
     def size(self) -> Size2d:
-        return Size2d.from_np(self.wh) if self.is_valid() else EMPTY_SIZE2D
-
-    def aspect_ratio(self) -> float:
-        return self.wh[0] / self.wh[1]
+        return Size2d(self.wh) if self.is_valid() else INVALID_SIZE2D
 
     def area(self) -> float:
-        return self.size().area() if self.is_valid() else 0
+        """Returns the area of this box.
+        If the box is invalid, zero will be returned.
 
-    def area_int(self) -> int:
-        if self.is_valid():
-            wh = self.wh + 1
-            return wh[0] * wh[1]
-        else:
-            return 0
+        Returns:
+            float: area
+        """
+        return self.size().area() if self.is_valid() else 0
 
     def distance_to(self, box:Box) -> float:
-        tlbr1 = self.__tlbr
-        tlbr2 = box.__tlbr
+        """Returns the distance to the given box.
+
+        Args:
+            box (Box): target box which the distance is calculated.
+
+        Returns:
+            float: distance.
+        """
+        tlbr1 = self.tlbr
+        tlbr2 = box.tlbr
 
         delta1 = tlbr1[[0,3]] - tlbr2[[2,1]]
         delta2 = tlbr2[[0,3]] - tlbr2[[2,1]]
         u = np.max(np.array([np.zeros(len(delta1)), delta1]), axis=0)
         v = np.max(np.array([np.zeros(len(delta2)), delta2]), axis=0)
         dist = np.linalg.norm(np.concatenate([u, v]))
         return dist
 
-    def contains(self,box:Box) -> bool:
-        return self.__tlbr[0] <= box.__tlbr[0] and self.__tlbr[1] <= box.__tlbr[1] \
-                and self.__tlbr[2] >= box.__tlbr[2] and self.__tlbr[3] >= box.__tlbr[3]
-
-    def intersection(self, bbox:Box) -> Optional[Box]:
-        x1 = max(self.__tlbr[0], bbox.__tlbr[0])
-        y1 = max(self.__tlbr[1], bbox.__tlbr[1])
-        x2 = min(self.__tlbr[2], bbox.__tlbr[2])
-        y2 = min(self.__tlbr[3], bbox.__tlbr[3])
+    def contains_point(self, pt:Point) -> bool:
+        """Returns whether this box contains the given point or not.
+
+        Args:
+            pt (Point): a Point object for containment test.
+
+        Returns:
+            bool: True if this box contains the point object, otherwise False.
+        """
+        x, y = tuple(pt.xy)
+        return x >= self.tlbr[0] and y >= self.tlbr[1] and x < self.tlbr[2] and y < self.tlbr[3]
+
+    def contains(self, box:Box) -> bool:
+        return self.tlbr[0] <= box.tlbr[0] and self.tlbr[1] <= box.tlbr[1] \
+                and self.tlbr[2] >= box.tlbr[2] and self.tlbr[3] >= box.tlbr[3]
+
+    def intersection(self, bbox:Box) -> Box:
+        """Returns the intersection box of this box and the box given by the argument.
+
+        Args:
+            bbox (Box): a box object to take intersection with.
+
+        Returns:
+            Box: intersection box
+        """
+        x1 = max(self.tlbr[0], bbox.tlbr[0])
+        y1 = max(self.tlbr[1], bbox.tlbr[1])
+        x2 = min(self.tlbr[2], bbox.tlbr[2])
+        y2 = min(self.tlbr[3], bbox.tlbr[3])
         
-        if x1 >= x2 or y1 >= y2:
-            return EMPTY_BOX
-        else:
-            return Box.from_tlbr(np.array([x1, y1, x2, y2]))
+        return Box([x1, y1, x2, y2])
 
-    def iou(self,box:Box) -> float:
+    def iou(self, box:Box) -> float:
         inter_area = self.intersection(box).area()
-        area1, area2 = self.area(), self.area()
+        area1, area2 = self.area(), box.area()
         return inter_area / (area1 + area2 - inter_area)
 
-    def iou_int(self,box:Box) -> float:
-        inter_area = self.intersection(box).area_int()
-        area1, area2 = self.area_int(), self.area_int()
-        return inter_area / (area1 + area2 - inter_area)
-
-    def draw(self, convas:Image, color:BGR, line_thickness=2):
-        tlbr_int = self.__tlbr.astype(int)
-        return cv2.rectangle(convas, tlbr_int[0:2], tlbr_int[2:4], color,
+    def overlap_ratios(self, other:Box) -> tuple[float,float,float]:
+        if self.is_valid() and other.is_valid():
+            inter_area = self.intersection(other).area()
+            r1 = inter_area / self.area()
+            r2 = inter_area / other.area()
+            return (r1, r2, self.iou(other))
+        elif not self.is_valid():
+            raise ValueError(f'invalid "Box" object: {self}')
+        else:
+            raise ValueError(f'invalid "Box" object: {other}')
+
+    def draw(self, convas:Image, color:BGR, line_thickness=2) -> Image:
+        """Draw this box on the given convas.
+
+        Args:
+            convas (Image): the convas image on which this box is drawn.
+            color (BGR): the color to draw the box with.
+            line_thickness (int, optional): line thickness. Defaults to 2.
+
+        Returns:
+            Image: the image the box is drawn on.
+        """
+        import cv2
+        
+        box_int = self.to_rint()
+        return cv2.rectangle(convas, box_int.tl, box_int.br, color,
                             thickness=line_thickness, lineType=cv2.LINE_AA)
+
+    def crop(self, image:Image) -> Image:
+        """Crops the image of the box is located out of the given image.
+
+        Args:
+            img (Image): the source image from which the crop is taken.
+
+        Returns:
+            Image: cropped image.
+        """
+        x1, y1, x2, y2 = tuple(self.tlbr)
+        return image[y1:y2, x1:x2]
+    
+    def expand(self, margin:Union[numbers.Number,npt.ArrayLike]) -> Box:
+        """Expand this box with the amount of the given margin.
+
+        Args:
+            margin (Union[numbers.Number,npt.ArrayLike]): the margin
+
+        Returns:
+            Box: the expanded box object.
+        """
+        if isinstance(margin, numbers.Number):
+            tlbr = self.tlbr + [-margin, -margin, margin, margin]
+            return Box(tlbr)
+        else:
+            w, h = tuple(np.array(margin))
+            return Box(self.tlbr + [-w, -h, w, h])
+        
+    def update_roi(self, to_image:Image, from_image:Image) -> None:
+        """Read data from ``from_image`` and write it onto ``to_image`` of this box is located.
+
+        Args:
+            to_image (Image): the target convas where the image is written to
+            from_image (Image): the source image which data is from.
+        """
+        x1, y1, x2, y2 = tuple(self.tlbr)
+        to_image[y1:y2, x1:x2] = from_image
     
     def __repr__(self):
-        return '{}:{}'.format(self.top_left(), self.size())
+        return '{}:{}'.format(Point(self.tl), self.size())
 
-EMPTY_BOX:Box = Box(np.array([-1,-1,0,0]))
+EMPTY_BOX:Box = Box(np.array([0,0,-1,-1]))
 
 
-Image = NewType('Image', np.ndarray)
 @dataclass(frozen=True, eq=True)    # slots=True
 class Frame:
-    image: Image = field(repr=False)
+    """Frame captured by ImageCapture.
+    a Frame object consists of image (OpenCv format), frame index, and timestamp.
+    """
+    image: Image = field(repr=False, compare=False, hash=False)
     index: int
     ts: float
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## dna/utils.py

```diff
@@ -1,82 +1,79 @@
-import sys
-from typing import Tuple, Union, Dict, Any, Optional
+from __future__ import annotations
+from typing import Optional, TypeVar
+from collections.abc import Sequence, Callable
+
 from datetime import datetime, timezone
-from time import time
 from pathlib import Path
 
-from .types import Box
+from dna import Point
 from .color import BGR
 
+T = TypeVar("T")
+
 
 def datetime2utc(dt: datetime) -> int:
-    return int(dt.replace(tzinfo=timezone.utc).timestamp())
+    secs = dt.replace(tzinfo=timezone.utc).timestamp()
+    return int(secs * 1000)
 
 def utc2datetime(ts: int) -> datetime:
     return datetime.fromtimestamp(ts / 1000)
 
 def datetime2str(dt: datetime) -> str:
     return dt.strftime("%Y-%m-%d %H:%M:%S.%f")
 
-def utc_now() -> int:
-    return round(time() * 1000)
+def utc_now_datetime() -> datetime:
+    return datetime.now(timezone.utc)
+
+def utc_now_seconds() -> float:
+    return datetime.now(timezone.utc).timestamp()
+
+def utc_now_millis() -> int:
+    return round(utc_now_seconds() * 1000)
+
 
-def _parse_keyvalue(kv) -> Tuple[str,str]:
+def _parse_keyvalue(kv) -> tuple[str,str]:
     pair = kv.split('=')
     if len(pair) == 2:
         return tuple(pair)
     else:
         return pair, None
 
-def parse_query(query: str) -> Dict[str,str]:
+def parse_query(query: str) -> dict[str,str]:
     if not query or len(query) == 0:
         return dict()
     return dict([_parse_keyvalue(kv) for kv in query.split('&')])
 
-def get_first_param(args: Dict[str,Any], key: str, def_value=None):
+def get_first_param(args: dict[str,object], key: str, def_value=None) -> object:
     value = args.get(key)
     return value[0] if value else def_value
 
+def split_list(list:list[T], cond) -> tuple[list[T],list[T]]:
+    trues = []
+    falses = []
+    for v in list:
+        if cond(v):
+            trues.append(v)
+        else:
+            falses.append(v)
+    return trues, falses
+    
+def remove_cond_from_list(list:list[T], cond:Callable[[T],bool]) -> list[T]:
+    length = len(list)
+    removeds = []
+    for idx in range(length-1, -1, -1):
+        if cond(list[idx]):
+            removeds.append(list.pop(idx))
+    return removeds
 
-from dna import color, plot_utils
-import cv2
-import numpy as np
-
-def _draw_ds_track(convas, track, box_color:BGR, label_color:BGR, line_thickness:int):
-    box = Box.from_tlbr(track.to_tlbr())
-    box.draw(convas, box_color)
-    if label_color:
-        msg = f"{track.track_id}[{track.state}]"
-        mat = plot_utils.draw_label(convas, msg, box.br.astype(int), label_color, box_color, 2)
-    return convas
-
-def draw_ds_tracks(convas, tracks, box_color, label_color=None, line_thickness=2, track_indices=None):
-    if track_indices:
-        tracks = [tracks[i] for i in track_indices]
-    tracks = sorted(tracks, key=lambda t: t.track_id, reverse=True)
-
-    for track in tracks:
-        if track.is_tentative():
-            convas = _draw_ds_track(convas, track, box_color, label_color, line_thickness)
-    for track in tracks:
-        if not track.is_tentative():
-            convas = _draw_ds_track(convas, track, box_color, label_color, line_thickness)
-    return convas
-
-def draw_ds_detections(convas, dets, box_color, label_color=None, line_thickness=2):
-    for idx, det in enumerate(dets):
-        box = det.bbox
-        box.draw(convas, box_color, line_thickness=line_thickness)
-        if label_color:
-            msg = f"{idx:02d}"
-            mat = plot_utils.draw_label(convas, msg, box.br.astype(int), label_color, box_color, 2)
-    return convas
+def rindex(lst, value):
+    return len(lst) - lst[::-1].index(value) - 1
 
 def find_track_index(track_id, tracks):
-    return next((idx for idx, track in enumerate(tracks) if track[idx].track_id == track_id), None)
+    return next((idx for idx, track in enumerate(tracks) if track[idx].id == track_id), None)
 
 
 def gdown_file(url:str, file: Path, force: bool=False):
     if isinstance(file, str):
         file = Path(file)
         
     if force:
@@ -85,52 +82,41 @@
     if not file.exists():
         # create an empty 'weights' folder if not exists
         file.parent.mkdir(parents=True, exist_ok=True)
 
         import gdown
         gdown.download(url, str(file.resolve().absolute()), quiet=False)
 
-class RectangleDrawer:
-    def __init__(self, image: np.ndarray) -> None:
-        self.image = image
-        self.drawing = False
-        self.bx, self.by, self.ex, self.ey = 0, 0, 0, 0
-
-    def run(self) -> Tuple[np.ndarray, Box]:
-        cv2.namedWindow('image')
-        cv2.setMouseCallback('image', self.draw)
-
-        self.convas = self.image.copy()
-        while ( True ):
-            cv2.imshow('image', self.convas)
-            key = cv2.waitKey(1) & 0xFF
-            if key == ord('q'):
-                break
-        cv2.destroyWindow('image')
-
-        return self.convas, Box([self.bx, self.by, self.ex, self.ey])
-
-    def draw(self, event, x, y, flags, param):
-        if event == cv2.EVENT_LBUTTONDOWN:
-            self.drawing = True
-            self.bx, self.by = x, y
-        elif event == cv2.EVENT_MOUSEMOVE:
-            print(f'({x}),({y})')
-            if self.drawing == True:
-                self.convas = self.image.copy()
-                cv2.rectangle(self.convas, (self.bx, self.by), (x,y), (0,255,0), 1)
-        elif event == cv2.EVENT_LBUTTONUP:
-            self.drawing = False
-            self.ex, self.ey = x, y
-            cv2.rectangle(self.convas, (self.bx, self.by), (x,y), (0,255,0), 2)
-
-def initialize_logger(conf_file_path: Optional[str]=None):
-    if conf_file_path is None:
-        import pkg_resources
-        conf_file_path = pkg_resources.resource_filename('conf', 'logger.yaml')
+def initialize_logger(logger_conf_file: Optional[str]=None):
+    import yaml
+    import logging.config
+    
+    if logger_conf_file is None:
+        import pkgutil
+        logger_conf_text = pkgutil.get_data('conf', 'logger.yaml')
+    else:
+        with open(logger_conf_file, 'rt') as f:
+            logger_conf_text = f.read()
+    logger_conf = yaml.safe_load(logger_conf_text)
+    logging.config.dictConfig(logger_conf)
+        
         
-    with open(conf_file_path, 'rt') as f:
-        import yaml
-        import logging.config
+def has_method(obj, name:str) -> bool:
+    method = getattr(obj, name, None)
+    return callable(method) if method else False
+
+
 
-        config = yaml.safe_load(f.read())
-        logging.config.dictConfig(config)
+def detect_outliers(values:list[T], weight:float=1.5, *,
+                    key:Optional[Callable[[T],float]]=None) -> tuple[list[T],list[T]]:
+    import numpy as np
+    
+    keys = [key(v) for v in values] if key else values
+    
+    v25, v75 = np.percentile(keys, [25, 75])
+    iqr = v75 - v25
+    step = weight * iqr
+    lowest, highest = v25 - step, v75 + step
+    
+    low_outlier_idxes = [i for i, k in enumerate(keys) if k < lowest]
+    high_outlier_idxes = [i for i, k in enumerate(keys) if k > highest]
+    return [values[i] for i in low_outlier_idxes], [values[i] for i in high_outlier_idxes]
```

## dna/camera/__init__.py

```diff
@@ -1,4 +1,4 @@
 
 from .camera import Camera, ImageCapture
-from .utils import create_camera_from_conf
-from .image_processor import ImageProcessor, FrameProcessor
+from .image_processor import ImageProcessor, FrameProcessor
+from .opencv_camera import create_opencv_camera, create_opencv_camera_from_conf
```

## dna/camera/camera.py

```diff
@@ -1,68 +1,57 @@
 from __future__ import annotations
 
-from typing import Optional, NewType, Union
-from dataclasses import dataclass, field
+from typing import Optional
 from abc import ABCMeta, abstractmethod
 
-from omegaconf import OmegaConf
-import numpy as np
-
-import dna
 from dna import Size2d, Frame
 
 
-@dataclass(frozen=True, eq=True)    # slots=True
-class Parameters:
-    uri: Union[str,int] = field(default=None)
-    size: Optional[Size2d] = field(default=None)
-    sync: bool = field(default=False)
-    begin_frame: int = field(default=1)
-    end_frame: Optional[int] = field(default=None)
-    threaded: bool = field(default=False)
-
-    @classmethod
-    def from_conf(cls, conf:OmegaConf):
-        uri = conf.uri
-        size = conf.get('size', None)
-        size = Size2d.from_conf(size) if size is not None else size
-        sync = conf.get("sync", False)
-        begin_frame = conf.get("begin_frame", 1)
-        end_frame = conf.get("end_frame", None)
-        threaded = conf.get("threaded", False)
-        
-        return cls(uri=uri, size=size, sync=sync, begin_frame=begin_frame, end_frame=end_frame,
-                    threaded=threaded)
-
 class Camera(metaclass=ABCMeta):
     @abstractmethod
     def open(self) -> ImageCapture:
-        """Opens a camera
+        """Open this camera.
+
+        Returns:
+            ImageCapture: an ImageCapture object that captures images from this camera.
         """
         pass
 
     @property
     @abstractmethod
     def uri(self) -> str:
         """Returns the URI of this Camera.
 
         Returns:
-            Parameters: camera URI
+            str: URI of this camera.
         """
         pass
 
+    @property
     @abstractmethod
     def size(self) -> Size2d:
-        """Returns the image size captured from this Camera.
+        """The image size captured from this Camera.
 
         Returns:
-            Parameters: the image size captured from this Camera
+            Size2d: the image size captured from this Camera
         """
         pass
 
+    def resize(self, size:Size2d) -> Camera:
+        """Returns a Camera that captures the resized images.
+
+        Args:
+            size (Size2d): target image size.
+
+        Returns:
+            Camera: Camera
+        """
+        from .resized_camera import ResizingCamera
+        return ResizingCamera(self, size)
+
 
 class ImageCapture(metaclass=ABCMeta):
     @abstractmethod
     def close(self) -> None:
         """Closes this ImageCapture.
         """
         pass
@@ -75,22 +64,33 @@
             bool: True if this is opened, False otherwise.
         """
         pass
 
     @abstractmethod
     def __call__(self) -> Optional[Frame]:
         """Captures an OpenCV image frame.
+        If it fails to capture an image, this method returns None.
 
         Returns:
             Frame: captured image frame.
         """
         pass
 
     @property
     @abstractmethod
+    def camera(self) -> Camera:
+        """Returns source camera object that this capture is from.
+
+        Returns:
+            Camera: a camera object.
+        """
+        pass
+
+    @property
+    @abstractmethod
     def size(self) -> Size2d:
         """Returns the size of the images that this ImageCapture captures.
 
         Returns:
             Size2d: (width, height)
         """
         pass
@@ -104,18 +104,28 @@
             int: frames per second.
         """
         pass
 
     @property
     @abstractmethod
     def frame_index(self) -> int:
-        """Returns the total count of images this ImageCapture captures so far.
+        """Returns the total count of images this ImageCapture has captured so far.
 
         Returns:
             int: The number of frames
         """
         pass
 
     @property
     @abstractmethod
+    def sync(self) -> bool:
+        """Returns whether frames are captured on its fps or immediately as they are captured from the camera.
+
+        Returns:
+            bool: synchronized capture or not
+        """
+        pass
+
+    @property
+    @abstractmethod
     def repr_str(self) -> str:
         pass
```

## dna/camera/image_processor.py

```diff
@@ -1,30 +1,27 @@
 from __future__ import annotations
-from typing import Optional, Tuple, List
+
+from typing import Union, Optional
 from abc import ABCMeta, abstractmethod
-from collections import namedtuple
 from contextlib import suppress
 
 import logging
 from pathlib import Path
 import time
 from datetime import timedelta
 
 import numpy as np
-
 from omegaconf import OmegaConf
 from tqdm import tqdm
 import cv2
 
-from dna import color, Frame
-from dna.types import Size2d
+from dna import color, Frame, utils, Size2d
 from .camera import ImageCapture
-from dna.execution import AbstractExecution, ExecutionContext, NoOpExecutionContext, UserInterruptException
+from dna.execution import AbstractExecution, ExecutionContext, CancellationError
 
-import logging
 
 class FrameProcessor(metaclass=ABCMeta):
     @abstractmethod
     def on_started(self, proc:ImageProcessor) -> None:
         pass
 
     @abstractmethod
@@ -34,232 +31,261 @@
     @abstractmethod
     def process_frame(self, frame:Frame) -> Optional[Frame]:
         pass
 
     def set_control(self, key:int) -> int:
         return key
 
+
 class ImageProcessor(AbstractExecution):
     __ALPHA = 0.2
-    __slots__ = ('capture', 'conf', 'frame_processors', 'suffix_processors', '_is_drawing', 'fps_measured')
+    __slots__ = ('capture', 'frame_processors', 'suffix_processors', 'show_processor',
+                 'is_drawing', 'fps_measured', 'logger')
 
     from dataclasses import dataclass
     @dataclass(frozen=True)    # slots=True
     class Result:
         elapsed: float
         frame_count: int
         fps_measured: float
         failure_cause: Exception
 
         def __repr__(self):
             return (f"elapsed={timedelta(seconds=self.elapsed)}, "
-                    f"frame_count={self.frame_count}, "
-                    f"fps={self.fps_measured:.1f}")
+                    f"frame_count={self.frame_count}, fps={self.fps_measured:.1f}")
 
-    def __init__(self, cap: ImageCapture, conf: OmegaConf, context: ExecutionContext=NoOpExecutionContext()):
+    def __init__(self, cap:ImageCapture, *,
+                 show:Optional[Union[str,Size2d,bool]]=False,
+                 output_video:Optional[str]=None,
+                 show_progress:bool=False,
+                 context:Optional[ExecutionContext]=None):
         super().__init__(context=context)
         
         self.capture = cap
-        self.conf = conf
-        self.frame_processors: List[FrameProcessor] = []
-        self.suffix_processors: List[FrameProcessor] = []
+        self.frame_processors: list[FrameProcessor] = []
+        self.suffix_processors: list[FrameProcessor] = []
+        self.logger = logging.getLogger('dna.image_processor')
 
-        output_video:str = conf.get("output_video", None)
+        self.show_processor:ShowFrame = None
         
-        show_str:str = conf.get("show", None)
-        show:Optional[Size2d] = Size2d.parse_string(show_str) if show_str is not None else None
-
-        self._is_drawing:bool = show or output_video is not None
-        if self._is_drawing:
-            self.suffix_processors.append(DrawText())
+        def parse_show(show) -> Size2d:
+            if isinstance(show, bool):
+                return cap.size if show else None
+            else:
+                return Size2d.from_expr(show).to_rint() if show else None
+        show = parse_show(show)
 
-        if output_video is not None:
-            self.suffix_processors.append(VideoWriter(Path(output_video)))
+        self.is_drawing:bool = show is not None or output_video is not None
+        if self.is_drawing:
+            self.suffix_processors.append(DrawFrameTitle())
+        if output_video:
+            self.suffix_processors.append(ImageWriteProcessor(Path(output_video),
+                                                              logger=self.logger.getChild('image_writer')))
 
         if show:
-            window_name = f'camera={conf.camera.uri}'
-            self.suffix_processors.append(ShowFrame(window_name, show.to_tuple() if show else None))
+            window_name = f'camera={cap.camera.uri}'
+            self.show_processor = ShowFrame(window_name, tuple(show.wh) if show else None,
+                                            logger=self.logger.getChild('show_frame'))
+            self.suffix_processors.append(self.show_processor)
 
-        if not isinstance(context, NoOpExecutionContext):
-            import dna
-            interval = int(dna.conf.get_config(context.request, "progress_report.interval_seconds", 60))
-            self.suffix_processors.append(ExecutionProgressReporter(context, interval_secs=interval))
-
-        show_progress:bool = conf.get("show_progress", False)
         if show_progress:
-            self.suffix_processors.append(ShowProgress(self.capture.total_frame_count))
+            # 카메라 객체에 'begin_frame' 속성과 'end_frame' 속성이 존재하는 경우에만 ShowProgress processor를 추가한다.
+            camera = self.capture.camera
+            if ( hasattr(camera, 'begin_frame')
+                and hasattr(camera, 'end_frame')
+                and hasattr(self.capture, 'total_frame_count') ):
+                self.suffix_processors.append(ShowProgress())
 
-        self.logger = logging.getLogger('dna.image_processor')
+        self.fps_measured = 0.
         
     def close(self) -> None:
         self.stop("close requested", nowait=True)
 
-    def is_drawing(self) -> None:
-        return self._is_drawing
-
     def add_frame_processor(self, frame_proc: FrameProcessor) -> None:
         self.frame_processors.append(frame_proc)
+        if self.show_processor:
+            self.show_processor.add_processor(frame_proc)
         
     def run_work(self) -> Result:
         started = time.time()
 
+        # 등록된 모든 frame processor들의 'on_started()' 메소드를 호출하여 ImageProcessor가 시작됨을 알린다.
         processors = self.frame_processors + self.suffix_processors
         for fproc in processors:
             fproc.on_started(self)
 
         capture_count = 0
         self.fps_measured = 0.
         failure_cause = None
         try:
-            self.logger.info(f'start: ImageProcess[cap={self.capture}]')
+            if self.logger.isEnabledFor(logging.INFO):
+                self.logger.info(f'start: ImageProcess[cap={self.capture}]')
             while self.capture.is_open():
                 # 사용자에 의해 동작 멈춤이 요청된 경우 CallationError 예외를 발생시킴
                 self.check_stopped()
                 
                 # ImageCapture에서 처리할 이미지를 읽어 옴.
                 frame: Frame = self.capture()
                 if frame is None: break
                 capture_count += 1
 
+                # 등록된 모든 frame-processor를 capture된 image를 이용해 'process_frame' 메소드를 차례대로 호출한다.
+                # process_frame() 호출시 첫번째 processor는 capture된 image를 입력받지만,
+                # 이후 processor들은 자신 바로 전에 호출된 process_frame()의 반환값을 입력으로 받는다.
+                # 만일 어느 한 frame-processor의 process_frame() 호출 결과가 None인 경우는 이후 frame-processor 호출은 중단되고
+                # 전체 image-processor의 수행이 중단된다.
                 for fproc in processors:
                     frame = fproc.process_frame(frame)
-                    if frame is None: break
+                    if frame is None:
+                        self.stop(nowait=True)
+                        break
                 if frame is None: break
 
                 elapsed = time.time() - started
                 fps = 1 / (elapsed / capture_count)
-                weight = ImageProcessor.__ALPHA if capture_count > 10 else 0.5
+                weight = ImageProcessor.__ALPHA if capture_count > 100 else 0.9
                 self.fps_measured = weight*fps + (1-weight)*self.fps_measured
+        except CancellationError as e:
+            failure_cause = e
         except Exception as e:
             failure_cause = e
             self.logger.error(e, exc_info=True)
         finally:
+            # 등록된 순서의 역순으로 'on_stopped()' 메소드를 호출함
             for fproc in reversed(processors):
                 try:
                     fproc.on_stopped()
                 except Exception as e:
                     self.logger.error(e, exc_info=True)
 
         return ImageProcessor.Result(time.time()-started, capture_count, self.fps_measured, failure_cause)
+                
+    def stop_work(self) -> None: pass
 
     def finalize(self) -> None:
         self.capture.close()
 
-class ExecutionProgressReporter(FrameProcessor):
-    def __init__(self, context: ExecutionContext, interval_secs: int) -> None:
-        super().__init__()
-        self.ctx = context
-        self.report_interval = interval_secs
-
-    def on_started(self, proc:ImageProcessor) -> None:
-        self.next_report_time = time.time() + self.report_interval
-
-    def on_stopped(self) -> None: pass
-
-    def process_frame(self, frame:Frame) -> Optional[Frame]:
-        now = time.time()
-        if now >= self.next_report_time:
-            progress = {
-                'frame_index': frame.index
-            }
-            self.ctx.report_progress(progress)
-            self.next_report_time += self.report_interval
-        return frame
 
-class DrawText(FrameProcessor):
+class DrawFrameTitle(FrameProcessor):
     def on_started(self, proc:ImageProcessor) -> None:
         self.proc = proc
     def on_stopped(self) -> None: pass
 
     def process_frame(self, frame:Frame) -> Optional[Frame]:
         convas = cv2.putText(frame.image, f'frames={frame.index}, fps={self.proc.fps_measured:.2f}',
                             (10, 20), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, color.RED, 2)
         return Frame(image=convas, index=frame.index, ts=frame.ts)
 
+
 class ShowFrame(FrameProcessor):
     _PAUSE_MILLIS = int(timedelta(hours=1).total_seconds() * 1000)
 
-    def __init__(self, window_name: str, window_size: Optional[Tuple[int,int]]) -> None:
+    def __init__(self, window_name:str, window_size:Optional[tuple[int,int]],
+                 *, logger:Optional[logging.Logger]=None) -> None:
         super().__init__()
         self.window_name = window_name
-        self.window_size:Optional[Tuple[int,int]] = window_size if window_size != (0,0) else None
-        self.logger = logging.getLogger('dna.node.frame_processor.show_frame')
+        self.window_size:Optional[tuple[int,int]] = window_size if window_size != (0,0) else None
+        self.processors: list[FrameProcessor] = []
+        self.logger = logger
+        
+    def add_processor(self, proc:FrameProcessor) -> None:
+        self.processors.append(proc)
 
     def on_started(self, proc:ImageProcessor) -> None:
-        win_size = self.window_size if self.window_size else proc.capture.size.to_tuple()
+        win_size = self.window_size if self.window_size else tuple(proc.capture.size.wh)
         
-        self.logger.info(f'create window: {self.window_name}, size=({win_size[0]}x{win_size[1]})')
+        if self.logger and self.logger.isEnabledFor(logging.INFO):
+            self.logger.info(f'create window: {self.window_name}, size=({win_size[0]}x{win_size[1]})')
         cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)
         cv2.resizeWindow(self.window_name, win_size[0], win_size[1])
 
     def on_stopped(self) -> None:
-        self.logger.info(f'destroy window: {self.window_name}')
+        if self.logger and self.logger.isEnabledFor(logging.INFO):
+            self.logger.info(f'destroy window: {self.window_name}')
         with suppress(Exception): cv2.destroyWindow(self.window_name)
 
     def process_frame(self, frame:Frame) -> Optional[Frame]:
         img = cv2.resize(frame.image, self.window_size, cv2.INTER_AREA) if self.window_size else frame.image
         cv2.imshow(self.window_name, img)
 
         key = cv2.waitKey(int(1)) & 0xFF
         while True:
             if key == ord('q'):
-                self.logger.info(f'interrupted by a key-stroke')
-                raise UserInterruptException()
+                if self.logger and self.logger.isEnabledFor(logging.DEBUG):
+                    self.logger.debug(f'interrupted by a key-stroke')
+                return None
             elif key == ord(' '):
-                self.logger.info(f'paused by a key-stroke')
+                if self.logger and self.logger.isEnabledFor(logging.DEBUG):
+                    self.logger.debug(f'paused by a key-stroke')
                 while True:
                     key = cv2.waitKey(ShowFrame._PAUSE_MILLIS) & 0xFF
                     if key == ord(' '):
-                        self.logger.info(f'resumed by a key-stroke')
+                        if self.logger and self.logger.isEnabledFor(logging.DEBUG):
+                            self.logger.debug(f'resumed by a key-stroke')
                         key = 1
                         break
                     elif key == ord('q'):
-                        raise UserInterruptException()
-            else:
+                        return None
+            elif key != 0xFF:
+                for proc in self.processors:
+                    key = proc.set_control(key)
+                return frame
+            else: 
                 return frame
 
+
 class ShowProgress(FrameProcessor):
-    def __init__(self, total_frame_count: int) -> None:
+    __slots__ = ( 'begin_frame_index', 'last_frame_index', 'tqdm' )
+    
+    def __init__(self) -> None:
         super().__init__()
-        self.total_frame_count = total_frame_count
+        
+        self.begin_frame_index = -1
+        self.last_frame_index = -1
+        self.tqdm = None
 
     def on_started(self, proc:ImageProcessor) -> None:
-        self.last_frame_index = 0
-        self.tqdm = tqdm(total=self.total_frame_count)
+        camera = proc.capture.camera
+        self.begin_frame_index = camera.begin_frame
+        end_frame_index = camera.end_frame if camera.end_frame is not None else proc.capture.total_frame_count+1
+        self.tqdm = tqdm(total=end_frame_index-1)
 
     def on_stopped(self) -> None:
-        with suppress(Exception): self.tqdm.close()
+        with suppress(Exception):
+            self.tqdm.close()
+            self.tqdm = None
 
     def process_frame(self, frame:Frame) -> Optional[Frame]:
+        if self.last_frame_index < 0:
+            self.last_frame_index = 0
+        
         self.tqdm.update(frame.index - self.last_frame_index)
         self.tqdm.refresh()
         self.last_frame_index = frame.index
         return frame
-
-class VideoWriter(FrameProcessor):
-    def __init__(self, path: Path) -> None:
+    
+    
+class ImageWriteProcessor(FrameProcessor):
+    __slots__ = ( 'path', 'writer', 'logger' )
+    
+    def __init__(self, path: Path, *, logger:Optional[logging.Logger]=None) -> None:
         super().__init__()
-
-        self.fourcc = None
-        ext = path.suffix.lower()
-        if ext == '.mp4':
-            self.fourcc = cv2.VideoWriter_fourcc(*'mp4v')
-        elif ext == '.avi':
-            self.fourcc = cv2.VideoWriter_fourcc(*'DIVX')
-        else:
-            raise IOError("unknown output video file extension: 'f{ext}'")
+        
         self.path = path.resolve()
-        self.logger = logging.getLogger('dna.node.frame_processor.video_writer')
+        self.logger = logger
 
     def on_started(self, proc:ImageProcessor) -> None:
-        self.logger.info(f'opening video file: {self.path}')
-
-        self.path.parent.mkdir(exist_ok=True)
-        self.video_writer = cv2.VideoWriter(str(self.path), self.fourcc, proc.capture.fps, proc.capture.size.to_tuple())
+        if self.logger and self.logger.isEnabledFor(logging.INFO):
+            self.logger.info(f'opening video file: {self.path}')
+        
+        from .video_writer import VideoWriter
+        self.writer = VideoWriter(self.path.resolve(), proc.capture.fps, proc.capture.size)
+        self.writer.open()
 
     def on_stopped(self) -> None:
-        self.logger.info(f'closing video file: {self.path}')
-        with suppress(Exception): self.video_writer.release()
+        if self.logger and self.logger.isEnabledFor(logging.INFO):
+            self.logger.info(f'closing video file: {self.path}')
+        with suppress(Exception): self.writer.close()
 
     def process_frame(self, frame:Frame) -> Optional[Frame]:
-        self.video_writer.write(frame.image)
+        self.writer.write(frame.image)
         return frame
```

## dna/camera/opencv_camera.py

```diff
@@ -1,267 +1,376 @@
 from __future__ import annotations
 
-from typing import Optional, Tuple
+from typing import Union, Optional
 import dataclasses
 import time
 import uuid
-from subprocess import CompletedProcess, Popen, STDOUT, DEVNULL
+from subprocess import CompletedProcess, Popen, DEVNULL
 
 import numpy as np
 import cv2
 from omegaconf import OmegaConf
 
 import dna
 from dna import Size2d, Image, Frame
+from dna.utils import utc_now_seconds
 from .camera import Camera, ImageCapture
 
+
+def create_opencv_camera(uri:str, **options) -> OpenCvCamera:
+    """Create an OpenCvCamera object of the given URI.
+    The additional options will be given by dictionary ``options``.
+    The options contain the followings:
+    - size: the size of the image that the created camera will capture (optional)
+
+    Args:
+        uri (str): id of the camera.
+
+    Returns:
+        OpenCvCamera: an OpenCvCamera object.
+        If URI points to a video file, ``OpenCvVideFile`` object is returned. Otherwise,
+        ``OpenCvCamera`` is returned.
+    """
+    if OpenCvCamera.is_video_file(uri):
+        if 'open_ts' in options:
+            return TestingVideoFile(uri, **options)
+        else:
+            return OpenCvVideFile(uri, **options)
+    elif OpenCvCamera.is_local_camera(uri):
+        return OpenCvCamera(uri, **options)
+    elif OpenCvCamera.is_rtsp_camera(uri):
+        return RTSPOpenCvCamera(uri, **options)
+    else:
+        raise ValueError(f'invalid OpenCvCamera URI: {uri}')
+
+
+def create_opencv_camera_from_conf(conf:OmegaConf) -> OpenCvCamera:
+    """Create a camera from OmegaConf configuration.
+
+    Args:
+        conf (OmegaConf): OmegaConf configuration.
+
+    Returns:
+        OpenCvCamera: an OpenCvCamera object.
+    """
+    options = {k:v for k, v in dict(conf).items() if k != 'uri'}
+    return create_opencv_camera(conf.uri, **options)
+
+
 class OpenCvCamera(Camera):
-    def __init__(self, uri:str, target_size:Optional[Size2d]=None):
+    def __init__(self, uri:str, **options:object):
         Camera.__init__(self)
 
-        self.__uri = uri
-        self.__target_size = target_size
-        self.__size = target_size
-
-    @classmethod
-    def from_conf(cls, conf:OmegaConf):
-        uri = conf.uri
-        size_conf = conf.get('size', None)
-        size = Size2d.from_conf(size_conf) if size_conf is not None else None
-
-        return cls(uri, size)
+        self._uri = uri
+        self._size = Size2d.from_expr(options.get('size'))
+        self._target_size = self._size
+        self.open_ts = options.get('open_ts', 0)
 
     @staticmethod
-    def is_local_camera(uri: str):
+    def is_local_camera(uri:str):
+        '''Determines that the give URI is for the local camera or not.
+        'Local camera' means the one is directly connected to this computer through USB or any other media.'''
         return uri.isnumeric()
 
     @staticmethod
-    def is_rtsp_camera(uri: str):
+    def is_rtsp_camera(uri:str):
+        '''Determines whether the camera of the give URI is a remote one accessed by the RTSP protocol.'''
         return uri.startswith('rtsp://')
 
     @staticmethod
-    def is_video_file(uri: str):
+    def is_video_file(uri:str):
+        '''Determines whether the images captured from a video file or not.'''
         return uri.endswith('.mp4') or uri.endswith('.avi')
 
     def open(self) -> ImageCapture:
-        vid, proc = OpenCvCamera.__open_video_capture(self.uri)
-        from_video = self.is_video_file(self.uri)
+        """Open this camera and set ready for captures.
 
-        if self.__target_size is not None:
-            vid.set(cv2.CAP_PROP_FRAME_WIDTH, self.__target_size.width)
-            vid.set(cv2.CAP_PROP_FRAME_HEIGHT, self.__target_size.height)
+        Returns:
+            ImageCapture: a image capturing session from this camera.
+        """
+        uri = int(self.uri) if OpenCvCamera.is_local_camera(self.uri) else self.uri
+        vid = self._open_video_capture(uri)
 
-        return VideoFileCapture(self, vid) if from_video else OpenCvImageCapture(self, vid, proc)
+        from_video = self.is_video_file(self.uri)
+        # return VideoFileCapture(self, vid) if from_video else OpenCvImageCapture(self, vid, proc)
+        return TestingVideoFileCapture(self, vid, self.open_ts) if from_video else OpenCvImageCapture(self, vid)
 
     @property
     def uri(self) -> str:
-        return self.__uri
+        return self._uri
 
+    @property
     def size(self) -> Size2d:
-        if self.__target_size is not None:
-            return self.__target_size
+        if self._target_size is not None:
+            return self._target_size
         
-        if self.__size is None:
-            vid = self.__open_video_capture(self.uri)
-            width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))
-            height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))
-            self.__size = Size2d(width, height)
+        if self._size is None:
+            # if the image size has not been set yet, open this camera and find out the image size.
+            vid = self._open_video_capture(self._uri)
+            try:
+                width = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))
+                height = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))
+                self._size = Size2d([width, height])
+            finally:
+                vid.release()
             
-        return self.__size
-
-    @staticmethod
-    def __open_video_capture(uri: str) -> Tuple[cv2.VideoCapture, CompletedProcess]:
-        if uri.isnumeric():
-            return (cv2.VideoCapture(int(uri)), None)
-        elif uri.startswith('rtsp://'):
-            # 만일 OpenCv에서 지원하지 않는 RTSP Url을 사용한다면 replay하는 방법을 해결함.
-            if uri.find("&end=") >= 0 or uri.find("start=") >= 0:
-                new_uri = f"rtsp://localhost:8554/{uuid.uuid1()}"
-                cmd = ["C:\\local\\ffmpeg\\bin\\ffmpeg", "-re", "-rtsp_transport", "tcp", "-i", uri,
-                        "-rtsp_transport", "tcp", "-c:v", "copy", "-f", "rtsp", new_uri]
-                proc = Popen(cmd, stdout=DEVNULL, stderr=DEVNULL)
-                cv2.waitKey(4000)
-
-                vcap = cv2.VideoCapture(new_uri)
-                while (1):
-                    ret, frame = vcap.read()
-                    if ret: return (vcap, proc)
-                    else:
-                        cv2.waitKey(1000)
-                        vcap = cv2.VideoCapture(new_uri)
-            else:
-                return (cv2.VideoCapture(uri), None)
-        elif uri.endswith('.mp4') or uri.endswith('.avi'):  # from video-file
-            import os
-            if not os.path.exists(uri):
-                raise IOError(f"invalid video file path: {uri}")
-            return (cv2.VideoCapture(uri), None)
-        else:
-            raise ValueError(f"invalid camera uri: {uri}")
+        return self._size
+    
+    def _open_video_capture(self, uri:Union[str,int]) -> cv2.VideoCapture:
+        vid = cv2.VideoCapture(uri)
+        if self._target_size is not None:
+            vid.set(cv2.CAP_PROP_FRAME_WIDTH, self._target_size.width)
+            vid.set(cv2.CAP_PROP_FRAME_HEIGHT, self._target_size.height)
+            
+        return vid
 
     def __repr__(self) -> str:
-        size_str = f', size={self.__size}' if self.__size is not None else ''
+        size_str = f', size={self._size}' if self._size is not None else ''
         return f"{__class__.__name__}(uri={self.uri}{size_str})"
 
 
 class OpenCvVideFile(OpenCvCamera):
-    def __init__(self, uri:str, size:Optional[Size2d]=None, sync:bool=True,
-                begin_frame:int=1, end_frame:Optional[int]=None):
-        OpenCvCamera.__init__(self, uri, size)
-
-        self.sync = sync
-        self.begin_frame = begin_frame
-        self.end_frame = end_frame
-
-    @classmethod
-    def from_conf(cls, conf:OmegaConf):
-        uri = conf.uri
-        size_conf = conf.get('size', None)
-        size = Size2d.from_conf(size_conf) if size_conf is not None else None
-
-        sync = conf.get('sync', True)
-        begin_frame = conf.get('begin_frame', 1)
-        end_frame = conf.get('end_frame', None)
+    def __init__(self, uri:str, **options):
+        super().__init__(uri, **options)
 
-        return cls(uri, size, sync, begin_frame, end_frame)
+        self.sync = options.get('sync', True)
+        self.begin_frame = options.get('begin_frame', 1)
+        self.end_frame = options.get('end_frame')
+
+    def open(self) -> VideoFileCapture:
+        import os
+        if not os.path.exists(self.uri):
+            raise IOError(f"invalid video file path: {self.uri}")
+        
+        vid = self._open_video_capture(self.uri)
+        return VideoFileCapture(self, vid)
+        # return TestingVideoFileCapture(self, vid, self.open_ts)
 
     def __repr__(self) -> str:
-        size_str = f', size={self.__size}' if self.__size is not None else ''
+        size_str = f', size={self._size}' if self._size is not None else ''
         return f"{__class__.__name__}(uri={self.uri}{size_str}, sync={self.sync})"
 
+
 class OpenCvImageCapture(ImageCapture):
-    __slots__ = '__camera', '__vid', '__proc', '__size', '__fps', '__frame_index'
+    __slots__ = '_camera', '_vid', '_size', '_fps', '_frame_index'
 
-    def __init__(self, camera: OpenCvCamera, vid: cv2.VideoCapture, proc: CompletedProcess) -> None:
+    def __init__(self, camera:OpenCvCamera, vid:cv2.VideoCapture) -> None:
         """Create a OpenCvImageCapture object.
 
         Args:
             uri (str): Resource identifier.
         """
-        self.__camera = camera
+        self._camera = camera
         if vid is None:
             raise ValueError(f'cv2.VideoCapture is invalid')
-        self.__vid:cv2.VideoCapture = vid            # None if closed
-        self.__proc:CompletedProcess = proc
+        self._vid:cv2.VideoCapture = vid            # None if closed
 
-        width = int(self.__vid.get(cv2.CAP_PROP_FRAME_WIDTH))
-        height = int(self.__vid.get(cv2.CAP_PROP_FRAME_HEIGHT))
-        self.__size = Size2d(width, height)
-        self.__fps = self.__vid.get(cv2.CAP_PROP_FPS)
-        self.__frame_index = 0
+        width = int(self._vid.get(cv2.CAP_PROP_FRAME_WIDTH))
+        height = int(self._vid.get(cv2.CAP_PROP_FRAME_HEIGHT))
+        self._size = Size2d([width, height])
+        self._fps = self._vid.get(cv2.CAP_PROP_FPS)
+        self._frame_index = 0
 
     def close(self) -> None:
-        if self.__vid:
-            self.__vid.release()
-            self.__vid = None
-            if self.__proc is not None:
-                self.__proc.kill()
+        if self._vid:
+            self._vid.release()
+            self._vid = None
 
     def __call__(self) -> Optional[Frame]:
         if not self.is_open():
             raise IOError(f"{self.__class__.__name__}: not opened")
 
-        ret, mat = self.__vid.read()
+        ret, mat = self._vid.read()
         if not ret:
             return None
 
-        self.__frame_index += 1
-        return Frame(image=Image(mat), index=self.frame_index, ts=time.time())
+        self._frame_index += 1
+        return Frame(image=Image(mat), index=self.frame_index, ts=utc_now_seconds())
 
     def is_open(self) -> bool:
-        return self.__vid is not None
+        return self._vid is not None
 
     @property
     def camera(self) -> OpenCvCamera:
-        return self.__camera
+        return self._camera
 
     @property
     def cv2_video_capture(self) -> cv2.VideoCapture:
-        return self.__vid
+        return self._vid
 
     @property
     def size(self) -> Size2d:
-        return self.__size
+        return self._size
 
     @property
     def fps(self) -> int:
-        return self.__fps
+        return self._fps
 
     @property
     def frame_index(self) -> int:
-        return self.__frame_index
+        return self._frame_index
 
-    def set_frame_index(self, index:int) -> None:
-        self.__vid.set(cv2.CAP_PROP_POS_FRAMES, index-1)
-        self.__frame_index = index
+    @property
+    def sync(self) -> bool:
+        return False
 
     @property
     def repr_str(self) -> str:
         state = 'opened' if self.is_open() else 'closed'
-        return f'{state}, size={self.size}, frames={self.frame_index}, fps={self.fps:.0f}/s'
+        return f'{state}, size={self.size}, fps={self.fps:.0f}/s'
 
     def __repr__(self) -> str:
-        return f'OpenCvCamera({self.repr_str})'
-
+        return f'{self.__class__.__name__}({self.repr_str})'
+    
 
 class VideoFileCapture(OpenCvImageCapture):
-    __ALPHA = 0.5
-    __OVERHEAD = 0.02
-    __slots__ = '__interval', '__sync', '__last_img', '__overhead'
+    __ALPHA = 0.3
+    __slots__ = '_interval', 'sync', '_last_captured_ts', '_end_frame_index', '_overhead'
 
-    def __init__(self, camera: OpenCvVideFile, vid: cv2.VideoCapture) -> None:
-        """Create a VideoFileCapture object.
+    def __init__(self, camera:OpenCvVideFile, vid:cv2.VideoCapture) -> None:
+        super().__init__(camera, vid)
 
-        Args:
-            camera (OpenCvCamera): Resource identifier.
-        """
-        super().__init__(camera, vid, None)
-
-        self.__interval = 1.0 / self.fps
-        self.__sync = self.camera.sync
-        self.__last_frame = Frame(image=None, index=-1, ts=time.time())
-        self.__overhead = 0.0
+        self._interval = 1.0 / self.fps
+        self.sync = self.camera.sync
+        self._last_captured_ts = utc_now_seconds()
+        self._overhead = 0.0
 
-        if self.camera.begin_frame > 1:
-            self.set_frame_index(self.camera.begin_frame)
+        if self._camera.begin_frame > 1:
+            self.frame_index = self._camera.begin_frame - 1
             
-        import sys
-        self.__last_frame_index = sys.maxsize if self.camera.end_frame is None else self.camera.end_frame
+        if self._camera.end_frame:
+            self._end_frame_index = self._camera.end_frame
+        else:
+            self._end_frame_index = int(self.cv2_video_capture.get(cv2.CAP_PROP_FRAME_COUNT)) + 100
 
     @property
     def total_frame_count(self) -> int:
         return int(self.cv2_video_capture.get(cv2.CAP_PROP_FRAME_COUNT))
 
+    @property
+    def frame_index(self) -> int:
+        return self._frame_index
+
+    @frame_index.setter
+    def frame_index(self, index:int) -> None:
+        if index <= 0 and index > self.total_frame_count:
+            raise ValueError(f'index({index}) should be between 1 and {self.total_frame_count}')
+        
+        self._vid.set(cv2.CAP_PROP_POS_FRAMES, index)
+        self._frame_index = index
+
     def __call__(self) -> Optional[Frame]:
-        started = self.__last_frame.ts
+        started_ts = self._last_captured_ts
 
         frame: Frame = super().__call__()
         if frame is None:
             return frame
         
         # 지정된 마지막 프레임 번호보다 큰 경우는 image capture를 종료시킨다.
-        if frame.index > self.__last_frame_index:
+        if frame.index >= self._end_frame_index:
             return None
 
-        if self.__sync:
-            remains = self.__interval - (frame.ts - started) - self.__overhead
-            # print(f'elapsed={(img.ts - started)*1000:.0f}, overhead={self.__overhead*1000:.0f}, remains={remains*1000:.0f}')
-            if remains > 0.005:
+        if self.sync:
+            remains = self._interval - (frame.ts - started_ts) - self._overhead - 0.008
+            if remains > 0:
                 time.sleep(remains)
 
                 # System상 정확히 remains 초 만큼 대기하지 않기 때문에 그 차이를 계산해서
                 # 다음번 대기 시간에 반영시킴.
-                ts = time.time()
-                overhead = (ts - started) - self.__interval
-                if self.__overhead == 0: # for the initial frame
-                    self.__overhead = overhead
+                now = utc_now_seconds()
+                overhead = (now - started_ts) - self._interval
+                if self._overhead == 0: # for the initial frame
+                    self._overhead = overhead
                 else:
-                    self.__overhead == (VideoFileCapture.__ALPHA * overhead) + ((1-VideoFileCapture.__ALPHA)*self.__overhead)
+                    self._overhead = (VideoFileCapture.__ALPHA * overhead) + ((1-VideoFileCapture.__ALPHA)*self._overhead)
                 
-                frame = dataclasses.replace(frame, ts=ts)
+                frame = dataclasses.replace(frame, ts=now)
 
-        self.__last_frame = frame
+        self._last_captured_ts = frame.ts
         return frame
 
     @property
     def repr_str(self) -> str:
-        return f'{super().repr_str}, sync={self.__sync}'
+        return f'{super().repr_str}, sync={self.sync}'
+    
+    
+class RTSPOpenCvCamera(OpenCvCamera):
+    def __init__(self, uri:str, **options):
+        super().__init__(uri, **options)
+        
+        self.ffmpeg_cmd = None
+        if uri.find("&end=") >= 0 or uri.find("start=") >= 0:
+            ffmpeg_path = options.get('ffmpeg_path')
+            if not ffmpeg_path:
+                raise ValueError(f'FFMPEG command is not specified')
+            
+            self.ffmpeg_cmd = [ffmpeg_path, "-re", "-rtsp_transport", "tcp", "-i", uri,
+                               "-rtsp_transport", "tcp", "-c:v", "copy", "-f", "rtsp"]
+            
+    def open(self) -> OpenCvImageCapture:
+        if self.ffmpeg_cmd:
+            ffmpeg_cmd = self.ffmpeg_cmd.copy()
+            
+            new_uri = f"rtsp://localhost:8554/{uuid.uuid1()}"
+            # new_uri = f"rtsp://localhost:8554/visual"
+            ffmpeg_cmd.append(new_uri)
+            proc = Popen(ffmpeg_cmd, stdout=DEVNULL, stderr=DEVNULL)
+            cv2.waitKey(5000)
+
+            while True:
+                vcap = self._open_video_capture(new_uri)
+                ret, _ = vcap.read()
+                if ret:
+                    return RTSPOpenCvImageCapture(self, vcap, proc)
+                else:
+                    cv2.waitKey(1000)
+        else:
+            return super().open()
+
+    def __repr__(self) -> str:
+        size_str = f', size={self._size}' if self._size is not None else ''
+        ffmpeg_str = f', ffmpeg={self.ffmpeg_path}' if self.ffmpeg_path else ""
+        return f"{__class__.__name__}(uri={self.uri}{size_str}, sync={self.sync}{ffmpeg_str})"
+
+class RTSPOpenCvImageCapture(OpenCvImageCapture):
+    __slots__ = ( '_proc', )
+
+    def __init__(self, camera:RTSPOpenCvCamera, vid:cv2.VideoCapture, proc:CompletedProcess) -> None:
+        super().__init__(camera, vid)
+        
+        self._proc:CompletedProcess = proc
+        
+    def close(self) -> None:
+        if self._proc is not None:
+            self._proc.kill()
+        super().close()
+
+    def __repr__(self) -> str:
+        return f'RTSPCapture({self.repr_str})'
+
+    
+class TestingVideoFile(OpenCvVideFile):
+    def __init__(self, uri:str, **options):
+        super().__init__(uri, **options)
+        
+        self.open_ts = float(options.get('open_ts', 0))
+
+    def open(self) -> TestingVideoFileCapture:
+        vfc = super().open()
+        return TestingVideoFileCapture(camera=self, vid=vfc._vid, open_ts=self.open_ts)
+        
+
+class TestingVideoFileCapture(VideoFileCapture):
+    def __init__(self, camera: OpenCvVideFile, vid: cv2.VideoCapture, open_ts:float) -> None:
+        super().__init__(camera, vid)
+        
+        self.last_ts:float = open_ts
+        self.inc_secs:float =  1 / self.fps
+
+    def __call__(self) -> Optional[Frame]:
+        frame: Frame = super().__call__()
+        if frame is None:
+            return frame
+        
+        self.last_ts += self.inc_secs
+        frame = dataclasses.replace(frame, ts=self.last_ts)
+        return frame
```

## dna/camera/resized_camera.py

```diff
@@ -1,36 +1,40 @@
 from __future__ import annotations
 from typing import Optional
 
 import cv2
 
-from dna import Size2d
-from .camera import Camera, ImageCapture, Image
+from dna import Size2d, Image, Frame
+from .camera import Camera, ImageCapture
 
 
 class ResizingCamera(Camera):
     def __init__(self, camera: Camera, target_size: Size2d):
         self.base_camera = camera
         self.__size = target_size
 
+    @property
+    def uri(self) -> str:
+        return self.base_camera.uri
+
     def open(self) -> ImageCapture:
         src_capture = self.base_camera.open()
         return ResizingImageCapture(self, src_capture) if src_capture.size != self.__size else src_capture
 
     @property
     def size(self) -> Size2d:
         return self.__size
 
     def __repr__(self) -> str:
         end_frame = self.end_frame if self.end_frame else ""
         return f"Range({self.base_camera}, {self.begin_frame}:{end_frame})"
 
 
 class ResizingImageCapture(ImageCapture):
-    def __init__(self, camera: ResizingCamera, capture: ImageCapture) -> None:
+    def __init__(self, camera:ResizingCamera, capture:ImageCapture) -> None:
         self.__cap = capture
         self.__size = camera.size
 
         src_size = capture.size
         if self.__size == src_size:
             raise ValueError(f"target size({self.__size}) is equal to the source size({src_size})")
         elif self.__size.area() < src_size.area():
@@ -43,31 +47,43 @@
     def close(self) -> None:
         self.__cap.close()
 
     def is_open(self) -> bool:
         return self.__cap.is_open()
 
     def __call__(self) -> Optional[Image]:
-        img = self.__cap()
-        if img:
-            mat = cv2.resize(img.mat, dsize=self.__size.to_tuple(), interpolation=self.interpolation)
-            img = Image(mat=mat, frame_index=img.frame_index, ts=img.ts)
-        return img
+        frame:Frame = self.__cap()
+        if frame:
+            mat = cv2.resize(frame.image, dsize=tuple(self.__size.wh), interpolation=self.interpolation)
+            frame = Frame(image=mat, index=frame.index, ts=frame.ts)
+        return frame
+
+    @property
+    def camera(self) -> Camera:
+        return self.__cap.camera
 
     @property
     def size(self) -> Size2d:
         return self.__size
 
     @property
     def fps(self) -> int:
         return self.__cap.fps
 
     @property
     def frame_index(self) -> int:
         return self.__cap.frame_index
 
     @property
+    def sync(self) -> bool:
+        return self.__cap.sync
+
+    @sync.setter
+    def sync(self, flag) -> None:
+        return self.__cap.sync(flag)
+
+    @property
     def repr_str(self) -> str:
         return f'{self.__cap.repr_str}, target_size={self.__size}'
 
     def __repr__(self) -> str:
         return f'{self.__camera}({self.repr_str})'
```

## dna/camera/utils.py

```diff
@@ -1,17 +1,10 @@
+from __future__ import annotations
+from typing import Optional, NamedTuple
 
-from typing import Optional
+from contextlib import ExitStack, closing, contextmanager
+        
 
-from omegaconf import OmegaConf
-
-import dna
-from .opencv_camera import OpenCvCamera, OpenCvVideFile
-from .threaded_camera import ThreadedCamera
-
-
-def create_camera_from_conf(conf: OmegaConf):
-    camera = OpenCvVideFile.from_conf(conf) if OpenCvCamera.is_video_file(conf.uri) \
-                                            else OpenCvCamera.from_conf(conf)
-    if dna.conf.get_config(conf, 'threaded', False):
-        camera = ThreadedCamera(camera)
-
-    return camera
+@contextmanager
+def multi_camera_context(camera_list):
+    with ExitStack() as stack:
+        yield [stack.enter_context(closing(camera.open())) for camera in camera_list]
```

## dna/detect/__init__.py

```diff
@@ -1,2 +1,3 @@
-from .object_detector import Detection, ObjectDetector
+from .detection import Detection
+from .object_detector import ObjectDetector
 from .detecting_processor import DetectingProcessor
```

## dna/detect/detecting_processor.py

```diff
@@ -1,36 +1,33 @@
 from __future__ import annotations
-from dataclasses import dataclass, field
+from typing import Optional
 
-from typing import Optional, List
-from abc import ABCMeta, abstractmethod
 from pathlib import Path
 
 from dna import color, Frame
 from dna.camera import ImageProcessor, FrameProcessor
-from .object_detector import ObjectDetector, Detection
+from . import ObjectDetector, Detection
 
 
 class DetectingProcessor(FrameProcessor):
-    __slots__ = 'detector', 'draw_detections', 'box_color', 'label_color', 'show_score', 'output', 'out_handle'
+    __slots__ = 'detector', 'draw_detections', 'box_color', 'label_color', 'show_score', 'output', 'out_fp'
     
-    def __init__(self,
-                detector:ObjectDetector,
+    def __init__(self, detector:ObjectDetector, *,
                 output: Optional[str]=None,
                 draw_detections: bool=False):
         self.detector = detector
         self.draw_detections = draw_detections
         self.box_color = color.RED
         self.label_color = color.WHITE
         self.show_score = True
         self.output = output
         self.out_fp = None
 
-    @classmethod
-    def load(cls, detector_uri:str, output: Optional[Path]=None, draw_detections: bool=False) -> DetectingProcessor:
+    @staticmethod
+    def load(detector_uri:str, *, output: Optional[Path]=None, draw_detections: bool=False) -> DetectingProcessor:
         if not detector_uri:
             raise ValueError(f"detector id is None")
 
         parts = detector_uri.split(':', 1)
         id, query = tuple(parts) if len(parts) > 1 else (detector_uri, "")
         if id == 'file':
             from pathlib import Path
@@ -38,15 +35,15 @@
             det_file = Path(query)
             detector = LogReadingDetector(det_file)
         else:
             import importlib
             loader_module = importlib.import_module(id)
             detector = loader_module.load(query)
 
-        return cls(detector=detector, output=output, draw_detections=draw_detections)
+        return DetectingProcessor(detector=detector, output=output, draw_detections=draw_detections)
 
     def on_started(self, proc: ImageProcessor) -> None:
         if self.output:
             Path(self.output).parent.mkdir(exist_ok=True)
             self.out_fp = open(self.output, "w")
         return self
 
@@ -59,22 +56,22 @@
         img = frame.image
         frame_idx = frame.index
 
         for det in self.detector.detect(frame):
             if self.out_fp:
                 self.out_fp.write(self._to_string(frame_idx, det) + '\n')
             if self.draw_detections:
-                img = det.draw(img, color=self.box_color, label_color=self.label_color, show_score=self.show_score)
+                img = det.draw(img, color=self.box_color, label_color=self.label_color)
 
         return Frame(image=img, index=frame_idx, ts=frame.ts)
 
     def set_control(self, key: int) -> int:
         if key == ord('l'):
             self.label_color = None if self.label_color else color.WHITE
         elif key == ord('c'):
             self.show_score = not self.show_score
         return key
 
     def _to_string(self, frame_idx: int, det: Detection) -> str:
-        tlbr = det.bbox.to_tlbr()
+        tlbr = det.bbox.tlbr
         return (f"{frame_idx},-1,{tlbr[0]:.3f},{tlbr[1]:.3f},{tlbr[2]:.3f},{tlbr[3]:.3f},"
                 f"{det.score:.3f},-1,-1,-1,{det.label}")
```

## dna/detect/object_detector.py

```diff
@@ -1,110 +1,89 @@
 from __future__ import annotations
-from typing import List, Optional
+from typing import Optional
 from pathlib import Path
 from abc import ABCMeta, abstractmethod
-from dataclasses import dataclass, field
 
 import numpy as np
 
-from dna import BGR, Box, Size2d, Image, Frame
-from dna.utils import plot_utils
-
-
-@dataclass(frozen=True, eq=True)    # slots=True
-class Detection:
-    bbox: Box
-    label: Optional[str] = field(default=None)
-    score: float = -1
-
-    def draw(self, convas: Image, color:BGR, label_color: Optional[BGR]=None, show_score: bool=True,
-            line_thickness: int=2) -> Image:
-        loc = self.bbox
-        convas = loc.draw(convas, color=color, line_thickness=line_thickness)
-        if label_color:
-            msg = f"{self.label}({self.score:.3f})" if show_score else self.label
-            convas = plot_utils.draw_label(convas=convas, label=msg, tl=loc.tl.astype(int),
-                                            color=label_color, fill_color=color, thickness=2)
-
-        return convas
-
-    def __truediv__(self, rhs) -> Detection:
-        if isinstance(rhs, Size2d):
-            return Detection(bbox=self.bbox/rhs, label=self.label, score=self.score)
-        else:
-            raise ValueError('invalid right-hand-side:', rhs)
-    
-    def __repr__(self) -> str:
-        return f'{self.label}:{self.bbox},{self.score:.3f}'
+from dna import Box, Frame
+from .detection import Detection
 
 
 class ObjectDetector(metaclass=ABCMeta):
     @abstractmethod
-    def detect(self, frame: Frame) -> List[Detection]:
+    def detect(self, frame: Frame) -> list[Detection]:
         """Detect objects from the image and returns their locations
 
         Args:
             image Image: an image from OpenCV
             frame_index (int, optional): frame index. Defaults to None.
 
         Returns:
-            List[Detection]: a list of Detection objects
+            list[Detection]: a list of Detection objects
         """
         pass
+    
+    def detect_images(self, frames:list[Frame]) -> list[list[Detection]]:
+        return [self.detect(frame) for frame in frames]
+
 
 class ScoreFilteredObjectDetector(ObjectDetector):
     def __init__(self, detector: ObjectDetector, min_score: float) -> None:
         super().__init__()
 
         self.detector = detector
         if min_score < 0:
             raise ValueError(f'invalid score threshold: {min_score}')
         self.min_score = min_score
 
-    def detect(self, frame: Frame) -> List[Detection]:
+    def detect(self, frame: Frame) -> list[Detection]:
         return [det for det in self.detector.detect(frame)
                         if det.score < 0 or det.score >= self.min_score]
 
+
 class LabelFilteredObjectDetector(ObjectDetector):
-    def __init__(self, detector: ObjectDetector, accept_labels: List[str]) -> None:
+    def __init__(self, detector: ObjectDetector, accept_labels: list[str]) -> None:
         super().__init__()
 
         self.detector = detector
         self.labels = accept_labels
 
-    def detect(self, frame: Frame) -> List[Detection]:
+    def detect(self, frame: Frame) -> list[Detection]:
         return [det for det in self.detector.detect(frame)
                         if det.label in self.labels]
 
+
 class BlindZoneObjectDetector(ObjectDetector):
-    def __init__(self, detector: ObjectDetector, blind_zones: List[Box]) -> None:
+    def __init__(self, detector: ObjectDetector, blind_zones: list[Box]) -> None:
         super().__init__()
 
         self.detector = detector
         self.blind_zones = blind_zones
 
-    def detect(self, frame: Frame) -> List[Detection]:
+    def detect(self, frame: Frame) -> list[Detection]:
         return [det for det in self.detector.detect(frame)
                         if not any(zone.contains(det.bbox) for zone in self.blind_zones)]
 
+
 class LogReadingDetector(ObjectDetector):
     def __init__(self, det_file: Path) -> None:
         """Create an ObjectDetector object that issues detections from a detection file.
 
         Args:
             det_file (Path): Path to the detection file.
         """
         self.__file = open(det_file, 'r')
         self.look_ahead = self._look_ahead()
 
     @property
     def file(self) -> Path:
         return self.__file
 
-    def detect(self, frame: Frame) -> List[Detection]:
+    def detect(self, frame: Frame) -> list[Detection]:
         if not frame.index:
             return []
 
         if not self.look_ahead:
             return []
 
         idx = int(self.look_ahead[0])
@@ -125,25 +104,24 @@
             if self.look_ahead:
                 idx = int(self.look_ahead[0])
             else:
                 idx += 1
 
         return detections
 
-    def _look_ahead(self) -> Optional[List[str]]:
+    def _look_ahead(self) -> Optional[list[str]]:
         line = self.__file.readline().rstrip()
         if line:
             return line.split(',')
         else:
             self.__file.close()
             return None
 
-    def _parse_line(self, parts: List[str]) -> Detection:
-        tlbr = np.array(parts[2:6]).astype(float)
-        bbox = Box.from_tlbr(tlbr)
+    def _parse_line(self, parts: list[str]) -> Detection:
+        bbox = Box([float(v) for v in parts[2:6]])
         label: Optional[str] = parts[10] if len(parts) >= 11 else None
         score: float = float(parts[6])
         
         return Detection(bbox=bbox, label=label, score=score)
 
     def __repr__(self) -> str:
         current_idx = int(self.look_ahead[0]) if self.look_ahead else -1
```

## dna/detect/rcnn50_fpn/rcnn50_fpn_detector.py

```diff
@@ -1,8 +1,8 @@
-from typing import List, Optional
+from typing import Optional
 
 import torch
 from detectron2 import model_zoo
 
 from dna import get_logger, Box, Frame
 from dna.detect import ObjectDetector, Detection
 from dna.utils import parse_query
@@ -32,22 +32,22 @@
         self.cfg.merge_from_file(model_zoo.get_config_file(MODEL_FILE))
         self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5
         self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(MODEL_FILE)
         self.predictor = DefaultPredictor(self.cfg)
 
         self.class_names = self.predictor.metadata.get("thing_classes")
 
-    def detect(self, frame: Frame) -> List[Detection]:
+    def detect(self, frame: Frame) -> list[Detection]:
         outputs = self.predictor(frame.image)
         insts = outputs["instances"].to("cpu")
 
         pred_classes = insts.pred_classes.numpy()
         pred_boxes = insts.pred_boxes.tensor.numpy()
         pred_scores = insts.scores.numpy()
         return [self._to_detection(cls, box, score)
                 for cls, box, score in zip(pred_classes, pred_boxes, pred_scores)]
 
     def _to_detection(self, cls, bbox, score):
-        return Detection(bbox=Box.from_tlbr(bbox),
+        return Detection(bbox=Box(bbox),
                         label=self.class_names[cls],
                         score=score)
```

## dna/detect/yolov4/yolov4_detector.py

```diff
@@ -1,26 +1,28 @@
+from __future__ import annotations
+
 from dataclasses import dataclass
 from re import L
-from typing import List, Optional, Any
+from typing import Optional
 from pathlib import Path
 from urllib.parse import parse_qs
 
 import yaml
 import numpy as np
 import cv2
 import gdown
 
 # import sys
 # FILE = Path(__file__).absolute()
 # _YOLOV4_DIR = str(Path(FILE.parents[3], 'dna-plugins/dna-yoloqv4-torch'))
 # if not _YOLOV4_DIR in sys.path:
 #     sys.path.append(_YOLOV4_DIR)
 
-from dna import Box, gdown_file, Frame
-from dna.utils import parse_query, get_first_param
+from dna import Box, Frame
+from dna.utils import gdown_file, parse_query, get_first_param
 from dna.detect import Detection, ObjectDetector
 
 from .tool.utils import load_class_names
 from .tool.torch_utils import do_detect
 from .tool.darknet2pytorch import Darknet
 
 import logging
@@ -33,17 +35,17 @@
 #         # create an empty 'weights' folder if not exists
 #         path.parent.mkdir(parents=True, exist_ok=True)
 
 #     gdown.download(url, file, quiet=False)
 
 @dataclass(frozen=True, eq=True)
 class YoloV4ModelDesc:
-    class_names: List[str]
+    class_names: list[str]
     cfg_file_path: str
-    weights_file_path: Any
+    weights_file_path: str
 
 def _download_model_descriptor(model_id: str, top_dir: Path) -> YoloV4ModelDesc:
     class_names_file = (top_dir / 'coco.names').as_posix()
     gdown_file('https://drive.google.com/uc?id=1HY_sDInWvjhBq1s3nM6IIZL9T2thh0ro', class_names_file)
     class_names = load_class_names(class_names_file)
 
     if model_id == 'yolov4': # YoloV4 normal
@@ -72,19 +74,23 @@
     args = parse_query(query)
     tag = args.get('model', '')
     model_id = 'yolov4' if tag == '' else f'yolov4-{tag}'
 
     import os
     top_dir = Path(os.getcwd()) / 'models' / 'yolov4'
 
-    desc = _download_model_descriptor(model_id, top_dir)
+    desc:Yolov4TorchDetector = _download_model_descriptor(model_id, top_dir)
+    LOGGER.info((f'Loading Yolov4TorchDetector: cfg={desc.cfg_file_path}, weights={desc.weights_file_path}'))
+    detector = Yolov4TorchDetector(desc)
+
+    score = args.get('score')
+    if score is not None:
+        detector.conf_thres = float(score)
 
-    LOGGER.info((f'Loading Yolov4TorchDetector: cfg={desc.cfg_file_path}, '
-                f'weights={desc.weights_file_path}, class_names={desc.class_names}'))
-    return Yolov4TorchDetector(desc)
+    return detector
 
 class Yolov4TorchDetector(ObjectDetector):
     def __init__(self, desc: YoloV4ModelDesc,
                 conf_thres=0.4,     # confidence threshold
                 nms_thres=0.6,      # NMS IOU threshold
                 use_cuda = True
                 ) -> None:
@@ -96,22 +102,22 @@
         self.conf_thres = conf_thres
         self.nms_thres = nms_thres
 
         self.use_cuda = use_cuda
         if self.use_cuda:
             self.model.cuda()
 
-    def detect(self, frame: Frame) -> List[Detection]:
+    def detect(self, frame: Frame) -> list[Detection]:
         sized = cv2.resize(frame.image, (self.model.width, self.model.height))
         sized = cv2.cvtColor(sized, cv2.COLOR_BGR2RGB)
 
         h, w, _ = frame.image.shape
         batched_boxes = do_detect(self.model, sized, self.conf_thres, self.nms_thres, self.use_cuda)
 
         return [self.box_to_detection(box, w, h) for box in batched_boxes[0]]
 
     def box_to_detection(self, box, w, h):
-        coords = np.array([box[0] * w, box[1] * h, box[2] * w, box[3] * h])
-        bbox = Box.from_tlbr(coords)
+        coords = [box[0] * w, box[1] * h, box[2] * w, box[3] * h]
+        bbox = Box(coords)
         conf = box[5]
         label = self.class_names[box[6]]
         return Detection(bbox, label=label, score=conf)
```

## dna/detect/yolov5/yolov5_detector.py

```diff
@@ -1,54 +1,115 @@
-from typing import List, Optional
+from __future__ import annotations
+
+from typing import Optional, Union
 from pathlib import Path
 from urllib.parse import parse_qs
 
 import yaml
 import numpy as np
 import cv2
 import torch
 import torch.backends.cudnn as cudnn
 
-from dna import Box, Frame
+from dna import Box, Frame, Image
 from dna.utils import parse_query
 from dna.detect import ObjectDetector, Detection
 
+from pathlib import Path
 import logging
-LOGGER = logging.getLogger("dna.detector.yolov5")
+LOGGER = logging.getLogger(f"dna.detector.{Path(__file__).parent.stem}")
 
 
 def load(query: str):
     args = parse_query(query)
-    model_id = 'yolov5' + args.get('model', 's')
+    return Yolov5Detector(**args)
 
-    model = torch.hub.load('ultralytics/yolov5', model_id, pretrained=True, verbose=False)
+class Yolov5Detector(ObjectDetector):
+    def __init__(self, **kwargs) -> None:
+        model_id = 'yolov5' + kwargs.get('model', 's')
+        LOGGER.info(f'Loading {Yolov5Detector.__name__}: model={model_id}')
+
+        # self.model = torch.hub.load('ultralytics/yolov5', 'custom', f'models/yolov5/{model_id}', verbose=False)
+        self.model = torch.hub.load('ultralytics/yolov5', model_id, pretrained=True, verbose=False)
+        self.names = self.model.names
+
+        self.detect_args = dict()
+        # self.detect_args = {'imgsz':640}
+        if (v := kwargs.get('score')) is not None:
+            self.model.conf = float(v)
+        if (v := kwargs.get('iou')) is not None:
+            self.model.iou = float(v)
+        if (v := kwargs.get('max_det')) is not None:
+            self.model.max_det = int(v)
+        if (v := kwargs.get('classes')) is not None:
+            from dna import utils
+            class_names = self.names if utils.has_method(self.names, 'index') else list(self.names.values())
+            class_idxes = [class_names.index(cls) if isinstance(cls, str) else int(cls) for cls in v.split(',')]
+            self.model.classes = [idx for idx in class_idxes if idx < len(class_names)]
+        if (v := kwargs.get('agnostic')) is not None:
+            self.model.agnostic = bool(v)
+        if (v := kwargs.get('device')) is not None:
+            self.model.to(v)
+            
+    @property
+    def score(self) -> float:
+        return self.model.conf
+    @score.setter
+    def score(self, score:float) -> None:
+        self.model.conf = score
+            
+    @property
+    def classes(self) -> list[str]:
+        return [self.names[cls_idx] for cls_idx in self.model.classes]
+    @classes.setter
+    def classes(self, classes:list[str]) -> None:
+        class_idxes = [self.names.index(cls) if isinstance(cls, str) else int(cls) for cls in classes.split(',')]
+        self.model.classes = [idx for idx in class_idxes if idx >= 0 and idx < len(self.names)]
+            
+    @property
+    def iou(self) -> float:
+        return self.model.iou
+    @iou.setter
+    def iou(self, iou:float) -> None:
+        self.model.iou = iou
+            
+    @property
+    def max_det(self) -> int:
+        return self.model.max_det
+    @max_det.setter
+    def max_det(self, count:int) -> None:
+        self.model.max_det = count
+            
+    def device(self, device:Union[int,str]) -> None:
+        self.model.to(device)
 
-    score = args.get('score')
-    if score is not None:
-        model.conf = float(score)
+    @torch.no_grad()
+    def detect(self, frame: Frame) -> list[Detection]:
+        batch = [self._preprocess(frame.image)]
 
-    LOGGER.info(f'Loading Yolov5Detector: model={model_id}')
-    return Yolov5Detector(model)
+        # inference
+        result = self.model(batch, size=640)
 
+        return self._to_detections(result.xyxy[0])
 
-class Yolov5Detector(ObjectDetector):
-    def __init__(self, model) -> None:
-        self.model = model
-        self.names = model.names
+    # @torch.no_grad()
+    # def detect_images(self, frames:list[Frame]) -> list[list[Detection]]:
+    #     batch = [self._preprocess(frame.image) for frame in frames]
 
-    @torch.no_grad()
-    def detect(self, frame: Frame) -> List[Detection]:
-        # Convert
-        img = frame.image.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
-        img = np.ascontiguousarray(img)
+    #     # inference
+    #     result = self.model(batch)
 
-        # inference
-        preds = self.model(img).xyxy[0].cpu().numpy()
+    #     return [self._to_detections(xyxy) for xyxy in result.xyxy]
+
+    def _preprocess(self, image:Image) -> torch.Tensor:
+        return image[:,:,::-1]
+        # img = image.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
+        # return np.ascontiguousarray(img)
 
-        det_list = []
-        for i, pred in enumerate(preds):  # detections per image
-            bbox = Box.from_tlbr(pred[:4])
-            name = self.names[int(pred[5])]
-            confi = pred[4]
-            det_list.append(Detection(bbox, name, confi))
+    def _to_detections(self, xyxy) -> list[Detection]:
+        return [self._to_detection(pred) for pred in xyxy.cpu().numpy()]
 
-        return det_list
+    def _to_detection(self, pred) -> list[Detection]:
+        box = Box(pred[:4])
+        name = self.names[int(pred[5])]
+        confi = pred[4]
+        return Detection(box, name, confi)
```

## dna/node/__init__.py

```diff
@@ -1,8 +1 @@
-# from .kafka_event import KafkaEvent
-from .track_event import TrackEvent
-# from .event_processor import EventQueue, EventListener, EventProcessor, PrintTrackEvent
-# from .track_event_source import TrackEventSource
-# from .refine_track_event import RefineTrackEvent
-# from .drop_short_trail import DropShortTrail
-# from .kafka_event_publisher import KafkaEventPublisher
-# from .generate_local_path import GenerateLocalPath
+from .node_event import NodeEvent
```

## dna/node/drop_short_trail.py

```diff
@@ -1,53 +1,63 @@
 from __future__ import annotations
 
-from typing import List, Dict, Set
+from typing import Union, Optional
+import sys
+import logging
 from collections import defaultdict
 
-from dna.tracker import TrackState
-from .track_event import TrackEvent
-from .event_processor import EventProcessor
-
-import logging
-LOGGER = logging.getLogger('dna.node.pipeline')
+from dna.event import TimeElapsed, TrackEvent, TrackId, EventProcessor
+from dna.track import TrackState
 
 
 class DropShortTrail(EventProcessor):
-    __slots__ = 'min_trail_length', 'long_trails', 'pending_dict'
+    __slots__ = 'min_trail_length', 'long_trails', 'pending_dict', 'logger'
 
-    def __init__(self, min_trail_length:int) -> None:
+    def __init__(self, min_trail_length:int, *, logger:Optional[logging.Logger]=None) -> None:
         EventProcessor.__init__(self)
 
         self.min_trail_length = min_trail_length
-        self.long_trails: Set[str] = set()  # 'long trail' 여부
-        self.pending_dict: Dict[str, List[TrackEvent]] = defaultdict(list)
+        self.long_trails: set[TrackId] = set()  # 'long trail' 여부
+        self.pending_dict: dict[TrackId, list[TrackEvent]] = defaultdict(list)
+        self.logger = logger
 
     def close(self) -> None:
         super().close()
         self.pending_dict.clear()
         self.long_trails.clear()
+        
+    def min_frame_index(self) -> int:
+        return min(ev_list[0].frame_index for ev_list in self.pending_dict.values()) if self.pending_dict else None
+
+    def handle_event(self, ev:Union[TrackEvent,TimeElapsed]) -> None:
+        if isinstance(ev, TrackEvent):
+            self.handle_track_event(ev)
+        else:
+            self._publish_event(ev)
 
-    def handle_event(self, ev) -> None:
-        is_long_trail = ev.luid in self.long_trails
+    def handle_track_event(self, ev:TrackEvent) -> None:
+        is_long_trail = ev.track_id in self.long_trails
         if ev.state == TrackState.Deleted:   # tracking이 종료된 경우
             if is_long_trail:
-                self.long_trails.discard(ev.luid)
-                self.publish_event(ev)
+                self.long_trails.discard(ev.track_id)
+                self._publish_event(ev)
             else:
-                pendings = self.pending_dict.pop(ev.luid, [])
-                LOGGER.info(f"drop short track events: luid={ev.luid}, length={len(pendings)}")
+                pendings = self.pending_dict.pop(ev.track_id, [])
+                if pendings and self.logger and self.logger.isEnabledFor(logging.INFO):
+                    self.logger.info(f"drop short track events: track_id={ev.track_id}, length={len(pendings)}")
         elif is_long_trail:
-            self.publish_event(ev)
+            self._publish_event(ev)
         else:
-            pendings = self.pending_dict[ev.luid]
+            pendings = self.pending_dict[ev.track_id]
             pendings.append(ev)
 
             # pending된 event의 수가 threshold (min_trail_length) 이상이면 long-trail으로 설정하고,
             # 더 이상 pending하지 않고, 바로 publish 시킨다.
             if len(pendings) >= self.min_trail_length:
-                self.pending_dict.pop(ev.luid, None)
+                # 'pending_dict'에서 track을 제거하기 전에 pending event를 publish 해야 한다.
                 self.__publish_pendings(pendings)
-                self.long_trails.add(ev.luid)
+                self.long_trails.add(ev.track_id)
+                self.pending_dict.pop(ev.track_id, None)
 
-    def __publish_pendings(self, pendings:List[TrackEvent]) -> None:
+    def __publish_pendings(self, pendings:list[TrackEvent]) -> None:
         for pev in pendings:
-            self.publish_event(pev)
+            self._publish_event(pev)
```

## dna/node/node_processor.py

```diff
@@ -1,64 +1,44 @@
+from __future__ import annotations
+from typing import Optional
 
 from omegaconf import OmegaConf
 
-from dna.conf import exists_config
-from dna.camera import ImageProcessor, ImageCapture
-from dna.execution import Execution, ExecutionContext, NoOpExecutionContext
-from dna.pika_execution import PikaExecutionContext, PikaExecutionFactory
-from dna.tracker import TrackProcessor
-
-
-_DEFAULT_EXEC_CONTEXT = NoOpExecutionContext()
-
-def build_node_processor(capture: ImageCapture, conf: OmegaConf,
-                         context: ExecutionContext=_DEFAULT_EXEC_CONTEXT) -> ImageProcessor:
-    from dna.camera import create_camera_from_conf
-    from dna.node.utils import load_publishing_pipeline
-
-    img_proc = ImageProcessor(capture, conf, context=context)
-
-    publishing_conf = conf.get('publishing', OmegaConf.create())
-    publish_pipeline:TrackProcessor = load_publishing_pipeline(conf.id, publishing_conf)
-    
-    from dna.tracker.track_pipeline import TrackingPipeline
-    tracker_conf = conf.get('tracker', OmegaConf.create())
-    frame_proc = TrackingPipeline.load(img_proc, tracker_conf, [publish_pipeline])
-    img_proc.add_frame_processor(frame_proc)
+from dna import config
+from dna.camera import ImageProcessor
+from dna.track.track_pipeline import TrackingPipeline
+from .track_event_pipeline import TrackEventPipeline
+from .zone.zone_pipeline import ZonePipeline
+from .zone.zone_sequences_display import ZoneSequenceDisplay
+ 
+
+def build_node_processor(image_processor:ImageProcessor, conf: OmegaConf,
+                         *,
+                         tracking_pipeline:Optional[TrackingPipeline]=None) \
+    -> tuple[ImageProcessor, TrackingPipeline, TrackEventPipeline]:
+    # TrackingPipeline 생성하고 ImageProcessor에 등록함
+    if not tracking_pipeline:
+        tracker_conf = config.get_or_insert_empty(conf, 'tracker')
+        tracking_pipeline = TrackingPipeline.load(tracker_conf)
+    image_processor.add_frame_processor(tracking_pipeline)
+
+    # TrackEventPipeline 생성하고 TrackingPipeline에 등록함
+    publishing_conf = config.get_or_insert_empty(conf, 'publishing')
+    track_event_pipeline = TrackEventPipeline(conf.id, publishing_conf=publishing_conf,
+                                              image_processor=image_processor)
+    tracking_pipeline.add_track_processor(track_event_pipeline)
+
+    # ZonePipeline이 TrackEventPipeline에 등록되고, motion detection이 정의된 경우
+    # 이를 ZonePipeline에 등록시킨다
+    draw_motions = config.get(publishing_conf, "zone_pipeline.draw", default=True)
+    zone_pipeline:ZonePipeline = track_event_pipeline.plugins.get('zone_pipeline')
+    if zone_pipeline and image_processor.is_drawing and draw_motions:
+        motion_detector = zone_pipeline.services.get('motions')
+        motion_queue = zone_pipeline.event_queues.get('motions')
+        if motion_detector and motion_queue:
+            display = ZoneSequenceDisplay(motion_definitions=motion_detector.motion_definitions,
+                                          track_queue=track_event_pipeline,
+                                          motion_queue=motion_queue)
+            image_processor.add_frame_processor(display)
     
-    return img_proc
-    
-class PikaNodeExecutionFactory(PikaExecutionFactory):
-    def __init__(self, db_conf: OmegaConf, show: bool) -> None:
-        super().__init__()
-        self.db_conf = db_conf
-        self.show = show
-
-    def create(self, pika_ctx: PikaExecutionContext) -> Execution:
-        request = OmegaConf.create(pika_ctx.request)
-
-        if exists_config(request, 'node'):
-            from .utils import read_node_config
-            conf = read_node_config(self.db_conf, request.node)
-        elif exists_config(request, 'parameters'):
-            conf = request.parameters
-            conf.id = request.id
-        else:
-            raise ValueError(f'cannot get node configuration: request={request}')
-        conf.show = self.show
-
-        import json
-        rtsp_uri = request.get('rtsp_uri', None)
-        if rtsp_uri is None:
-            raise ValueError(f'RTSP stream is not specified')
-        rtsp_conf = OmegaConf.create({'uri': rtsp_uri})
-        
-        from dna.camera.utils import create_camera_from_conf
-        camera = create_camera_from_conf(rtsp_conf)
-        
-        import dna
-        img_proc = build_node_processor(camera.open(), conf, context=pika_ctx)
-        if dna.conf.exists_config(request, 'progress_report.interval_seconds'):
-            interval = int(request.progress_report.interval_seconds)
-            img_proc.report_interval = interval
-
-        return img_proc
+    return tracking_pipeline, track_event_pipeline
+
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## dna/node/publish_events_execution.py

```diff
@@ -1,23 +1,22 @@
-
-from typing import List
+from __future__ import annotations
 import heapq
 import time
 
 import pika
 from kafka import KafkaProducer
 
 import dna
 from dna.execution import AbstractExecution, Execution, ExecutionContext, ExecutionFactory
 from dna.pika_execution import PikaExecutionContext, PikaExecutionFactory, PikaExecutionContext
-from dna.node import TrackEvent
+from dna.event.track_event import TrackEvent
 
 
 class TrackEventPublishingExecution(AbstractExecution):
-    def __init__(self, context: ExecutionContext, topic:str, bootstrap_servers:List[str], sync:bool=True) -> None:
+    def __init__(self, context: ExecutionContext, topic:str, bootstrap_servers:list[str], sync:bool=True) -> None:
         super().__init__()
 
         self.ctx = context
         self.log_path = context.request.rtsp_uri
         self.topic = topic
         self.bootstrap_servers = bootstrap_servers
         self.sync = sync
@@ -62,15 +61,15 @@
                             next_report_time += interval
         finally:
             producer.close()
 
 
 from omegaconf import OmegaConf
 class PikaEventPublisherFactory(PikaExecutionFactory):
-    def __init__(self, topic:str, bootstrap_servers:List[str], sync:bool=True) -> None:
+    def __init__(self, topic:str, bootstrap_servers:list[str], sync:bool=True) -> None:
         super().__init__()
 
         self.topic = topic
         self.bootstrap_servers = bootstrap_servers
         self.sync = sync
 
     def create(self, pika_ctx: PikaExecutionContext) -> TrackEventPublishingExecution:
```

## dna/node/refine_track_event.py

```diff
@@ -1,88 +1,217 @@
 from __future__ import annotations
 
-from typing import List, Dict
+from typing import Union, Optional
+import sys
 from dataclasses import dataclass, field
 
-from dna.tracker import TrackState
-from .track_event import TrackEvent
-from .event_processor import EventProcessor
-
 import logging
-LOGGER = logging.getLogger("dna.node.pipeline")
+
+from dna.event import TrackId, TimeElapsed, TrackEvent, EventProcessor
+from dna.track.track_state import TrackState
 
 
-@dataclass(eq=True)    # slots=True
+@dataclass(eq=True) # slots=True
 class Session:
-    id: str = field(hash=True)
+    id: TrackId = field(hash=True)
+    '''본 세션에 해당하는 track id.'''
     state: TrackState = field(hash=False, compare=False)
-    pendings: List[TrackEvent] = field(hash=False, compare=False)
+    '''본 track session의 상태.'''
+    pendings: list[TrackEvent] = field(hash=False, compare=False)
+    '''TrackEvent refinement를 위해 track별로 보류되고 있는 TrackEvent 리스트.'''
+    
+    @property
+    def first_frame_index(self) -> int:
+        return self.pendings[0].frame_index if self.pendings else None
+        
+    def index_of(self, frame_index:int) -> int:
+        npendings = len(self.pendings)
+        if npendings == 0:
+            return -1
+        else:
+            index = frame_index - self.pendings[0].frame_index
+            if index < npendings:
+                return index
+            elif index == npendings:
+                return -1
+            else:
+                raise ValueError(f'invalid frame_index: {frame_index}, '
+                                 f'pendings=[{self.pendings[0].frame_index}-{self.pendings[-1].frame_index}]')
+
+    def trim_right_to(self, frame_index:int) -> None:
+        end_index = self.index_of(frame_index)
+        if end_index > 0 and end_index < len(self.pendings):
+            self.pendings = self.pendings[:end_index]
+            
+    def __repr__(self) -> str:
+        interval_str = ""
+        if self.pendings:
+            interval_str = f':{self.pendings[0].frame_index}-{self.pendings[-1].frame_index}'
+        return f'{self.id}({self.state.abbr})[{len(self.pendings)}{interval_str}]'
 
 
 class RefineTrackEvent(EventProcessor):
-    __slots__ = ('sessions', )
+    __slots__ = ('sessions', 'buffer_size', 'timeout', 'timeout_millis', 'logger', 'oldest_pending_session')
 
-    def __init__(self) -> None:
+    def __init__(self, buffer_size:int=30, buffer_timeout:float=1.0,
+                 *, logger:Optional[logging.Logger]=None) -> None:
         EventProcessor.__init__(self)
 
-        self.sessions: Dict[str, Session] = {}
-
-    def handle_event(self, ev) -> None:
-        session: Session = self.sessions.get(ev.luid, None)
-        if ev.state == TrackState.Deleted:   # tracking이 종료된 경우
-            self.sessions.pop(ev.luid, None)
-            if session.state != TrackState.Tentative:
-                if len(session.pendings) > 0 and LOGGER.isEnabledFor(logging.INFO):
-                    LOGGER.info(f"discard trailing Tentative track events: luid={ev.luid}, count={len(session.pendings)}")
-                self.publish_event(ev)
-        else:
-            if session is None: # TrackState.Null or TrackState.Deleted
-                self.__on_initial(ev)
-            elif session.state == TrackState.Confirmed:
-                self.__on_confirmed(session, ev)
-            elif session.state == TrackState.Tentative:
-                self.__on_tentative(session, ev)
-            elif session.state == TrackState.TemporarilyLost:
-                self.__on_temporarily_lost(session, ev)
-
-    def __on_initial(self, ev: TrackEvent) -> None:
-        # track과 관련된 session 정보가 없다는 것은 이 track event가 한 물체의 첫번째 track event라는
-        # 것을 의미하기 때문에 session을 새로 생성한다.
+        self.sessions: dict[str, Session] = {}
+        self.buffer_size = buffer_size
+        self.timeout = buffer_timeout
+        self.timeout_millis = round(buffer_timeout * 1000)
+        self.logger = logger
+        self.oldest_pending_session:Session = None
+
+    def close(self) -> None:
+        self.sessions.clear()
+        super().close()
+        
+    def min_frame_index(self) -> Optional[int]:
+        """Pending된 TravkEvent들 중에서 가장 작은 frame index를 반환한다.
+
+        Returns:
+            Optional[int]: Pending된 TravkEvent들 중에서 가장 작은 frame index.
+            만일 pending된 TrackEvent가 없는 경우에는 None.
+        """
+        if not self.oldest_pending_session:
+            pending_sessions = [session for session in self.sessions.values() if session.pendings]
+            self.oldest_pending_session = min(pending_sessions, key=lambda s: s.first_frame_index) if pending_sessions else None
+        return self.oldest_pending_session.first_frame_index if self.oldest_pending_session else None
+
+    def handle_event(self, ev:Union[TrackEvent,TimeElapsed]) -> None:
+        if isinstance(ev, TrackEvent):
+            self.handle_track_event(ev)
+            pass
+        elif isinstance(ev, TimeElapsed):
+            self.handle_time_elapsed(ev)
+
+    def handle_track_event(self, ev:TrackEvent) -> None:
+        session:Session = self.sessions.get(ev.track_id)
+        if session is None: # TrackState.Null or TrackState.Deleted
+            self.__on_initial(ev)
+        elif session.state == TrackState.Confirmed:
+            self.__on_confirmed(session, ev)
+        elif session.state == TrackState.Tentative:
+            self.__on_tentative(session, ev)
+        elif session.state == TrackState.TemporarilyLost:
+            self.__on_temporarily_lost(session, ev)
+
+    def handle_time_elapsed(self, ev:TimeElapsed) -> None:
+        for session in self.sessions.values():
+            self._publish_old_events(session, ev.ts)
+        self._publish_event(ev)
+        
+    def _remove_session(self, id:TrackId) -> None:
+        session = self.sessions.pop(id, None)
+        self._unset_oldest_pending_session(session)
+
+    def __on_initial(self, ev:TrackEvent) -> None:
+        # track과 관련된 session 정보가 없다는 것은 이 track event가 한 물체의 첫번째 track event라는 것을 
+        # 의미하기 때문에 session을 새로 생성한다.
+        self.sessions[ev.track_id] = session = Session(id=ev.track_id, state=ev.state, pendings=[])
         if ev.state == TrackState.Tentative:
-            self.sessions[ev.luid] = Session(id=ev.luid, state=TrackState.Tentative, pendings=[ev])
+            self._append_track_event(session, ev)
         elif ev.state == TrackState.Confirmed:
-            self.sessions[ev.luid] = Session(id=ev.luid, state=TrackState.Confirmed, pendings=[])
+            self._publish_event(ev)
+        elif ev.state == TrackState.Deleted:
+            self._remove_session(ev.track_id)
         else:
-            raise AssertionError(f"unexpected track event (invalid track state): {ev.track}")
+            raise AssertionError(f"unexpected track event (invalid track state): {ev}")
 
-    def __on_confirmed(self, session: Session, ev: TrackEvent) -> None:
+    def __on_confirmed(self, session:Session, ev:TrackEvent) -> None:
         if ev.state == TrackState.Confirmed:
-            self.publish_event(ev)
+            self._publish_event(ev)
         elif ev.state == TrackState.TemporarilyLost:
-            session.pendings.append(ev)
+            self._append_track_event(session, ev)
             session.state = TrackState.TemporarilyLost
+        elif ev.state == TrackState.Deleted:
+            self._publish_event(ev)
+            self._remove_session(ev.track_id)
+        else:
+            raise AssertionError(f"unexpected track event (invalid track state): "
+                                f"state={session.state}, event={ev.track}")
 
-    def __on_tentative(self, session: Session, ev: TrackEvent) -> None:
+    def __on_tentative(self, session:Session, ev:TrackEvent) -> None:
         if ev.state == TrackState.Confirmed:
             # 본 trail을 임시 상태에서 정식의 trail 상태로 변환시키고,
             # 지금까지 pending된 모든 tentative event를 trail에 포함시킨다
-            # self.logger.debug(f"accept tentative tracks: track={track.id}, count={len(session.pendings)}")
-            self.__publish_all_pended_events(session)
-            self.publish_event(ev)
+            self._publish_all_pended_events(session)
+            self._unset_oldest_pending_session(session)
+            self._publish_event(ev)
             session.state = TrackState.Confirmed
         elif ev.state == TrackState.Tentative:
-            session.pendings.append(ev)
+            self._append_track_event(session, ev)
+        elif ev.state == TrackState.Deleted:
+            if self.logger and self.logger.isEnabledFor(logging.DEBUG):
+                self.logger.debug(f"discard tentative track: "
+                                    f"track_id={ev.track_id}, count={len(session.pendings)}")
+            # track 전체를 제거하기 때문에, 'delete' event로 publish하지 않는다.
+            self._remove_session(ev.track_id)
+        else:
+            raise AssertionError(f"unexpected track event (invalid track state): "
+                                    f"state={session.state}, event={ev.track}")
 
-    def __on_temporarily_lost(self, session: Session, ev: TrackEvent) -> None:
+    def __on_temporarily_lost(self, session:Session, ev:TrackEvent) -> None:
         if ev.state == TrackState.Confirmed:
-            # self.logger.debug(f"accept 'temporarily-lost' tracks[{ev.luid}]: count={len(session.pendings)}")
-
-            self.__publish_all_pended_events(session)
-            self.publish_event(ev)
+            session.trim_right_to(ev.frame_index)
+            self._publish_all_pended_events(session)
+            self._unset_oldest_pending_session(session)
+            self._publish_event(ev)
             session.state = TrackState.Confirmed
         elif ev.state == TrackState.TemporarilyLost:
-            session.pendings.append(ev)
+            self._append_track_event(session, ev)
+            # event buffer가 overflow가 발생하면, overflow되는
+            # event 갯수만큼 oldest event를 publish시킨다.
+            n_overflows = len(session.pendings) - self.buffer_size
+            if n_overflows > 0:
+                if self.logger and self.logger.isEnabledFor(logging.INFO):
+                    self.logger.info(f'flush overflowed {n_overflows} TrackEvent: track_id={session.id}, '
+                                        f'range={session.pendings[0].frame_index}-{session.pendings[n_overflows-1].frame_index}')
+                for tev in session.pendings[:n_overflows]:
+                    self._publish_event(tev)
+                session.pendings = session.pendings[n_overflows:]
+                self._unset_oldest_pending_session(session)
+        elif ev.state == TrackState.Deleted:
+            if self.logger and self.logger.isEnabledFor(logging.DEBUG):
+                self.logger.debug(f"discard all pending lost track events: "
+                                f"track_id={ev.track_id}, count={len(session.pendings)}")
+            self._publish_event(ev)
+            self._remove_session(ev.track_id)
+        else:
+            raise AssertionError(f"unexpected track event (invalid track state): "
+                                    f"state={session.state}, event={ev.track}")
+        
+    def _unset_oldest_pending_session(self, session) -> None:
+        if self.oldest_pending_session == session:
+            self.oldest_pending_session = None
+        
+    def _append_track_event(self, session:Session, te:TrackEvent) -> None:
+        session.pendings.append(te)
+        if self.oldest_pending_session and self.oldest_pending_session != session:
+            if te.frame_index < self.oldest_pending_session.first_frame_index:
+                self.oldest_pending_session = None
 
-    def __publish_all_pended_events(self, session):
+    def _publish_all_pended_events(self, session:Session):
         for pended in session.pendings:
-            self.publish_event(pended)
-        session.pendings.clear()
+            self._publish_event(pended)
+        session.pendings.clear()
+
+    def _publish_old_events(self, session:Session, ts:int) -> int:
+        from dna.support import iterables
+        
+        end_idx = iterables.first((idx for idx, tev in enumerate(session.pendings) if (ts - tev.ts) < self.timeout_millis), default=-1)
+        if end_idx > 0:
+            if self.logger and self.logger.isEnabledFor(logging.INFO):
+                longest = (ts - session.pendings[0].ts) / 1000
+                self.logger.info(f'flush too old {end_idx} TrackEvents: track_id={session.id}, '
+                                 f'range={session.pendings[0].frame_index}-{session.pendings[end_idx-1].frame_index}, '
+                                 f'longest={longest:.3f}s, '
+                                 f'timeout={self.timeout:.3f}s')
+            self._unset_oldest_pending_session(session)
+            for pending in session.pendings[:end_idx]:
+                self._publish_event(pending)
+            session.pendings = session.pendings[end_idx:]
+            return end_idx
+        else:
+            return 0
```

## dna/node/utils.py

```diff
@@ -1,75 +1,24 @@
+from __future__ import annotations
 
-from omegaconf import OmegaConf
+from collections.abc import Generator
 
-from dna.tracker import TrackProcessor
+from dna.event import TrackEvent
+from dna.support.text_line_writer import TextLineWriter
+            
 
+def read_tracks_csv(track_file:str) -> Generator[TrackEvent, None, None]:
+    import csv
+    with open(track_file) as f:
+        reader = csv.reader(f)
+        for row in reader:
+            yield TrackEvent.from_csv(row)
 
-_DEFAULT_MIN_PATH_LENGTH=10
 
-def load_publishing_pipeline(node_id: str, publishing_conf: OmegaConf) -> TrackProcessor:
-    from .track_event import TrackEventSource
-    from .kafka_event_publisher import KafkaEventPublisher
-    from .event_processor import PrintTrackEvent
-
-    source = TrackEventSource(node_id)
-    queue = source
-    
-    # drop unnecessary tracks (eg. trailing 'TemporarilyLost' tracks)
-    from .refine_track_event import RefineTrackEvent
-    refine = RefineTrackEvent()
-    queue.add_listener(refine)
-    queue = refine
-
-    # drop too-short tracks of an object
-    min_path_length = publishing_conf.get('min_path_length', _DEFAULT_MIN_PATH_LENGTH)
-    if min_path_length > 0:
-        from .drop_short_trail import DropShortTrail
-        drop_short_path = DropShortTrail(min_path_length)
-        queue.add_listener(drop_short_path)
-        queue = drop_short_path
-
-    # attach world-coordinates to each track
-    if publishing_conf.get('attach_world_coordinates') is not None:
-        from .world_transform import WorldTransform
-        world_coords = WorldTransform(publishing_conf.attach_world_coordinates)
-        queue.add_listener(world_coords)
-        queue = world_coords
-
-    if publishing_conf.get('kafka', None) is not None:
-        queue.add_listener(KafkaEventPublisher(publishing_conf.kafka))
-    else:
-        import logging
-        logger = logging.getLogger('dna.node.kafka')
-        logger.warning(f'Kafka publishing is not specified')
-
-    if publishing_conf.get('output', None) is not None:
-        queue.add_listener(PrintTrackEvent(publishing_conf.output))
-        
-    return source
-
-
-def read_node_config(db_conf: OmegaConf, node_id:str) -> OmegaConf:
-    from contextlib import closing
-    import psycopg2
-
-    with closing(psycopg2.connect(host=db_conf.db_host, dbname=db_conf.db_name,
-                                  user=db_conf.db_user, password=db_conf.db_password)) as conn:
-        sql = f"select id, camera_conf, tracker_conf, publishing_conf from nodes where id='{node_id}'"
-        with closing(conn.cursor()) as cursor:
-            cursor.execute(sql)
-            row = cursor.fetchone()
-            if row is not None:
-                import json
-
-                conf = OmegaConf.create()
-                conf.id = node_id
-                if row[1] is not None:
-                    conf.camera = OmegaConf.create(json.loads(row[1]))
-                if row[2] is not None:
-                    conf.tracker = OmegaConf.create(json.loads(row[2]))
-                if row[3] is not None:
-                    conf.publishing = OmegaConf.create(json.loads(row[3]))
-
-                return conf
-            else:
-                return None
+class JsonTrackEventGroupWriter(TextLineWriter):
+    def __init__(self, file_path: str) -> None:
+        super().__init__(file_path)
+
+    def handle_event(self, group:list[TrackEvent]) -> None:
+        for track in group:
+            self.write(track.to_json() + '\n')
+
```

## scripts/__init__.py

```diff
@@ -0,0 +1,5 @@
+00000000: 6672 6f6d 202e 7574 696c 7320 696d 706f  from .utils impo
+00000010: 7274 2075 7064 6174 655f 6e61 6d65 7370  rt update_namesp
+00000020: 6163 655f 7769 7468 5f65 6e76 6972 6f6e  ace_with_environ
+00000030: 2c20 6c6f 6164 5f63 616d 6572 615f 636f  , load_camera_co
+00000040: 6e66                                     nf
```

## scripts/dna_node.py

```diff
@@ -1,60 +1,76 @@
+import os
 from contextlib import closing
-from threading import Thread
 from datetime import timedelta
 
 import yaml
 from omegaconf import OmegaConf
 
+import warnings
+from torch.serialization import SourceChangeWarning
+warnings.filterwarnings("ignore", category=SourceChangeWarning)
+
 import dna
-from dna.camera import ImageProcessor,  create_camera_from_conf
-from dna.execution import UserInterruptException
+from dna import config
+from scripts import load_camera_conf
+from dna.camera import ImageProcessor, create_opencv_camera_from_conf
 from dna.node.node_processor import build_node_processor
-from dna.node.utils import read_node_config
-
+from scripts import update_namespace_with_environ
 
 import argparse
 def parse_args():
-    parser = argparse.ArgumentParser(description="Track objects in a video file")
+    parser = argparse.ArgumentParser(description="Track objects and publish their locations")
     parser.add_argument("--conf", metavar="file path", help="configuration file path")
-    parser.add_argument("--node", metavar="id", help="DNA node id")
+    
+    parser.add_argument("--camera", metavar="uri", help="target camera uri")
+    parser.add_argument("--sync", action='store_true', help="sync to camera fps")
+    parser.add_argument("--begin_frame", type=int, metavar="number", default=argparse.SUPPRESS,
+                        help="the first frame number")
+    parser.add_argument("--end_frame", type=int, metavar="number", default=argparse.SUPPRESS,
+                        help="the last frame number")
+
     parser.add_argument("--output", metavar="json file", help="track event file.", default=None)
-    parser.add_argument("--show", "-s", nargs='?', const='0x0')
-    parser.add_argument("--loop", action='store_true')
+    parser.add_argument("--output_video", "-v", metavar="mp4 file", help="output video file.", default=None)
     parser.add_argument("--show_progress", help="display progress bar.", action='store_true')
-    parser.add_argument("--begin_frame", type=int, metavar="number", help="the first frame number", default=1)
-    parser.add_argument("--end_frame", type=int, metavar="number", help="the last frame number")
-
-    parser.add_argument("--db_host", metavar="postgresql host", help="PostgreSQL host", default='localhost')
-    parser.add_argument("--db_port", metavar="postgresql port", help="PostgreSQL port", default=5432)
-    parser.add_argument("--db_name", metavar="dbname", help="PostgreSQL database name", default='dna')
-    parser.add_argument("--db_user", metavar="user_name", help="PostgreSQL user name", default='dna')
-    parser.add_argument("--db_password", metavar="password", help="PostgreSQL user password", default="urc2004")
+    parser.add_argument("--show", "-s", nargs='?', const='0x0', default=None)
+    parser.add_argument("--loop", action='store_true')
+    
+    parser.add_argument("--kafka_brokers", nargs='+', metavar="hosts", help="Kafka broker hosts list", default=None)
 
     parser.add_argument("--logger", metavar="file path", help="logger configuration file path")
     return parser.parse_known_args()
+    
 
 def main():
     args, _ = parse_args()
-
     dna.initialize_logger(args.logger)
-    conf, _, args_conf = dna.load_node_conf(args, ['show', 'show_progress'])
+    args = update_namespace_with_environ(args)
+    
+    # argument에 기술된 conf를 사용하여 configuration 파일을 읽는다.
+    conf = config.load(args.conf) if args.conf else OmegaConf.create()
     
     # 카메라 설정 정보 추가
-    conf.camera.begin_frame = args.begin_frame
-    conf.camera.end_frame = args.end_frame
+    config.update(conf, 'camera', load_camera_conf(args))
+    camera = create_opencv_camera_from_conf(conf.camera)
 
-    if 'output' in args:
-        publishing_conf = conf.get('publishing', OmegaConf.create())
-        publishing_conf.output = args.output
-        conf.publishing = publishing_conf
+    # args에 포함된 ImageProcess 설정 정보를 추가한다.
+    config.update_values(conf, args, 'show', 'output_video', 'show_progress')
+    if args.kafka_brokers:
+        # 'kafka_brokers'가 설정된 경우 publishing 작업에서 이 broker로 접속하도록 설정한다.
+        config.update(conf, 'publishing.plugins.kafka_brokers', args.kafka_brokers)
+    if args.output:
+        # 'output'이 설정되어 있으면, track 결과를 frame 단위로 출력할 수 있도록 설정을 수정함.
+        config.update(conf, "publishing.plugins.output", args.output)
 
-    camera = create_camera_from_conf(conf.camera)
     while True:
-        img_proc = build_node_processor(camera.open(), conf)
+        options = config.to_dict(config.filter(conf, 'show', 'output_video', 'show_progress'))
+        img_proc = ImageProcessor(camera.open(), **options)
+
+        build_node_processor(img_proc, conf)
+        
         result: ImageProcessor.Result = img_proc.run()
         if not args.loop or result.failure_cause is not None:
             break
     print(result)
 
 if __name__ == '__main__':
 	main()
```

## scripts/dna_node_processor.py

```diff
@@ -1,43 +1,45 @@
 
+import logging
+import argparse
 from omegaconf import OmegaConf
 
-import dna
-from dna.camera.image_processor import ImageProcessor
-from dna.node.node_processor import PikaNodeExecutionFactory
+from dna import config, initialize_logger
+from dna.node.pika.pika_execution import PikaExecutionFactory, PikaConnector
+from dna.node.pika.pika_execution_server import PikaExecutionServer
+from scripts import update_namespace_with_environ
+
+LOGGER = logging.getLogger('dna.node.pika')
+
 
-import argparse
 def parse_args():
-    parser = argparse.ArgumentParser(description="Detect Objects in a video file")
-    parser.add_argument("--host", "-i", metavar="broker host", help="RabbitMQ broker host", default="localhost")
-    parser.add_argument("--port", "-p", metavar="broker port", help="RabbitMQ broker port", default=5672)
-    parser.add_argument("--user", "-u", metavar="broker user", help="RabbitMQ broker user id", default="dna")
-    parser.add_argument("--password", "-w", metavar="broker password", help="RabbitMQ broker password",
+    parser = argparse.ArgumentParser(description="Run a node processor.")
+    parser.add_argument("--conf_root", metavar="dir", help="Root directory for configurations", default="conf")
+    parser.add_argument("--kafka_brokers", nargs='+', metavar="hosts", help="Kafka broker hosts list", default=None)
+    parser.add_argument("--rabbitmq_host", metavar="broker host", help="RabbitMQ broker host", default="localhost:5672")
+    parser.add_argument("--rabbitmq_user", metavar="broker user", help="RabbitMQ broker user id", default="dna")
+    parser.add_argument("--rabbitmq_password", metavar="broker password", help="RabbitMQ broker password",
                         default="urc2004")
     parser.add_argument("--request_qname", "-q", metavar="json file", help="track event file.",
                         default="track_requests")
-    parser.add_argument("--show", "-s", nargs='?', const='0x0')
-
-    parser.add_argument("--db_host", metavar="postgresql host", help="PostgreSQL host", default='localhost')
-    parser.add_argument("--db_port", metavar="postgresql port", help="PostgreSQL port", default=5432)
-    parser.add_argument("--db_name", metavar="dbname", help="PostgreSQL database name", default='dna')
-    parser.add_argument("--db_user", metavar="user_name", help="PostgreSQL user name", default='dna')
-    parser.add_argument("--db_password", metavar="password", help="PostgreSQL user password", default="urc2004")
+    parser.add_argument("--show", "-s", nargs='?', const='0x0', default='0x0')
 
     parser.add_argument("--logger", metavar="file path", help="logger configuration file path")
     return parser.parse_known_args()
 
 def main():
     args, _ = parse_args()
-
-    dna.initialize_logger(args.logger)
-    conf, db_conf, args_conf = dna.load_node_conf(args)
-
-    conn_params = dna.PikaConnectionParameters(host=args.host, port=args.port,
-                                               user_id=args.user, password=args.password)
-    server = dna.PikaExecutionServer(conn_params=conn_params,
-                                     execution_factory=PikaNodeExecutionFactory(db_conf=db_conf, show=args.show),
-                                     request_qname=args.request_qname)
+    initialize_logger(args.logger)
+    args = update_namespace_with_environ(args)
+    
+    host, port = tuple(args.rabbitmq_host.split(':'))
+    connector = PikaConnector(host=host, port=int(port),
+                              user_id=args.rabbitmq_user, password=args.rabbitmq_password)
+    fact = PikaExecutionFactory(args=args)
+    server = PikaExecutionServer(connector=connector,
+                                 execution_factory=fact,
+                                 request_qname=args.request_qname,
+                                 logger=LOGGER)
     server.run()
 
 if __name__ == '__main__':
 	main()
```

## scripts/dna_node_processor_client.py

```diff
@@ -1,11 +1,14 @@
 import json
+
+from dna import config
 from dna.execution import ExecutionState
 
-from dna.pika_execution import PikaExecutionClient, PikaConnectionParameters
+from dna.node.pika.pika_execution import PikaConnector
+from dna.node.pika.pika_execution_client import PikaExecutionClient
 
 
 import argparse
 def parse_args():
     parser = argparse.ArgumentParser(description="Detect Objects in a video file")
     parser.add_argument("req_message", help="request file path")
     parser.add_argument("--host", "-i", metavar="broker host", help="RabbitMQ broker host", default="localhost")
@@ -21,16 +24,21 @@
 def main():
     args, unknown = parse_args()
     
     json_str = ''
     with open(args.req_message, 'r') as file:
         json_str = file.read()
         
-    conn_params = PikaConnectionParameters(host=args.host, port=args.port,
-                                            user_id=args.user, password=args.password)
-    client = PikaExecutionClient(conn_params=conn_params, request_qname=args.request_qname,
-                                progress_handler=lambda x: print(x))
-    result = client.call(json_str)
-    print("done:", result)
+    connector = PikaConnector(host=args.host, port=args.port, user_id=args.user, password=args.password)
+    client = PikaExecutionClient(connector=connector, request_qname=args.request_qname)
+    try:
+        client.start(json_str)
+        for resp in client.report_progress():
+            resp = config.to_conf(resp)
+            print(resp)
+            # if resp.state == 'RUNNING' and resp.progress.frame_index >= 40:
+            #     client.stop(resp.id, 'timeout')
+    finally:
+        client.close()
 
 if __name__ == '__main__':
 	main()
```

## Comparing `dna/func.py` & `dna/support/func.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,43 +1,44 @@
 from __future__ import annotations
 
-from typing import Any, Callable, List, Union
+from typing import Union
+from collections.abc import Callable
 from dataclasses import dataclass, field
 
 
 @dataclass(frozen=True, eq=True, repr=False)
 class Option:
-    value: Any
+    value: object
     president: bool = field(default=True)
 
-    @classmethod
-    def empty(cls) -> Option:
+    @staticmethod
+    def empty() -> Option:
         return _EMPTY
 
-    @classmethod
-    def of(cls, value: Any) -> None:
+    @staticmethod
+    def of(value: object) -> Option:
         return Option(value, True)
 
-    @classmethod
-    def ofNullable(cls, value: Any) -> None:
+    @staticmethod
+    def ofNullable(value: object) -> Option:
         return Option(value, True) if value is not None else Option.empty()
 
-    def get(self) -> Any:
+    def get(self) -> object:
         if self.president:
             return self.value
         else:
             raise ValueError("NoSuchValue")
 
-    def getOrNone(self) -> Any:
+    def getOrNone(self) -> object:
         return self.value if self.president else None
 
-    def getOrElse(self, else_value) -> Any:
+    def getOrElse(self, else_value) -> object:
         return self.value if self.president else else_value
 
-    def getOrCall(self, else_value) -> Any:
+    def getOrCall(self, else_value) -> object:
         return self.value if self.president else else_value()
 
     def is_present(self) -> bool:
         return self.president
 
     def is_absent(self) -> bool:
         return self.president
@@ -53,15 +54,15 @@
             call()
 
         return self
 
     def map(self, mapper) -> Option:
         return Option.of(mapper(self.value)) if self.president else Option.empty()
 
-    def transform(self, target:Any, mapper:Callable[[Any, Any], Any]) -> Option:
+    def transform(self, target:object, mapper:Callable[[object, object], object]) -> Option:
         if self.is_present:
             return mapper(target, self.value)
         else:
             return target
 
     def __repr__(self) -> str:
         return f'Option({self.value})' if self.president else 'Option(Empty)'
```

## Comparing `dna/pika_rpc.py` & `dna/node/pika/pika_rpc.py`

 * *Files 0% similar despite different names*

```diff
@@ -7,33 +7,36 @@
 class Serde(metaclass=ABCMeta):
     @abstractmethod
     def serialize(self, data:object) -> bytes: pass
 
     @abstractmethod
     def deserialize(self, body:bytes) -> object: pass
 
+
 class NoOpSerde(Serde):
     def serialize(self, data:object) -> bytes:
         return data
 
     def deserialize(self, body:bytes) -> object:
         return body
 
+
 class JsonSerde(Serde):
     def deserialize(self, body:bytes) -> object:
         json_str = body.decode('utf-8')
         return json.loads(json_str)
 
     def serialize(self, resp:object) -> bytes:
         if isinstance(resp, str):
             resp = resp.encode('utf-8')
         elif not isinstance(resp, bytes):
             resp = json.dumps(resp, default=lambda o: o.__dict__).encode('utf-8')
         return resp
 
+
 NO_OP_SERDE = NoOpSerde()
 JSON_SERDE = JsonSerde()
 
 _REQ_QUEUE = 'rpc_requests'
 
 class RpcCallError(Exception):
     def __init__(self, message:str) -> None:
```

## Comparing `dna/plot_utils.py` & `dna/support/plot_utils.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,34 +1,44 @@
-from typing import List, Optional
+from typing import Optional, Union
 
 import numpy as np
 import cv2
 
-from dna import Box, Point, BGR, WHITE, Image
+from dna import Box, Point, BGR, Image
+from dna.color import WHITE, RED
 
 
 def draw_line(convas:Image, from_pt:Point, to_pt:Point, color:BGR,
                 line_thickness: int=2) -> Image:
     return draw_line_raw(convas, from_pt.xy.astype(int), to_pt.xy.astype(int), color, line_thickness)
 
 def draw_line_raw(convas:Image, from_pt, to_pt, color:BGR, line_thickness: int=2) -> Image:
-    return cv2.line(convas, from_pt, to_pt, color, line_thickness)
+    return cv2.line(convas, from_pt, to_pt, color, line_thickness, lineType=cv2.LINE_AA)
 
-def draw_line_string_raw(convas:Image, pts:List[List[int]], color: BGR,
+def draw_line_string_raw(convas:Image, pts:list[list[int]], color: BGR,
                             line_thickness: int=2) -> Image:
     for pt1, pt2 in zip(pts, pts[1:]):
         convas = draw_line_raw(convas, pt1, pt2, color, line_thickness)
     return convas
 
-def draw_line_string(convas:Image, pts: List[Point], color:BGR, line_thickness: int=2) -> Image:
+def draw_line_string(convas:Image, pts: list[Point], color:BGR, line_thickness: int=2) -> Image:
     return draw_line_string_raw(convas, [pt.xy.astype(int) for pt in pts], color, line_thickness)
 
-def draw_label(convas:Image, label:str, tl, color: BGR=WHITE, fill_color: Optional[BGR]=None,
-                thickness: int=2) -> Image:
+def draw_label(convas:Image, label:str, tl:Point, color: BGR=WHITE, fill_color:BGR=RED,
+                thickness: int=2, font_scale=0.4) -> Image:
     txt_thickness = max(thickness - 1, 1)
-    scale = thickness / 4
+    # font_scale = thickness / 4
 
-    txt_size = cv2.getTextSize(label, 0, fontScale=scale, thickness=thickness)[0]
-    br = (tl[0] + txt_size[0], tl[1] - txt_size[1] - 3)
-    convas = cv2.rectangle(convas, tl, br, fill_color, -1, cv2.LINE_AA)  # filled
-    return cv2.putText(convas, label, (tl[0], tl[1] - 2), 0, scale, color, thickness=txt_thickness,
-                        lineType=cv2.LINE_AA)
+    txt_size = cv2.getTextSize(label, 0, fontScale=font_scale, thickness=thickness)[0]
+    br = (tl.x + txt_size[0], tl.y - txt_size[1] - 3)
+    convas = cv2.rectangle(convas, tuple(tl.xy), br, color=fill_color, thickness=-1, lineType=cv2.LINE_AA)  # filled
+    return cv2.putText(convas, label, (tl.x, tl.y - 2), 0, font_scale, color, thickness=txt_thickness,
+                        lineType=cv2.LINE_AA)
+    
+def draw_polygon(convas:Image, coords:list[Union[tuple[float,float],list[float]]], color, line_thickness) -> Image:
+    if len(coords) > 2:
+        coords = np.array(coords).astype(int)
+        return cv2.polylines(convas, [coords], True, color, line_thickness, lineType=cv2.LINE_AA)
+    elif len(coords) == 2:
+        return cv2.line(convas, coords[0], coords[1], color, line_thickness, lineType=cv2.LINE_AA)
+    else:
+        return convas
```

## Comparing `dna/node/generate_local_path.py` & `dna/node/local_path_generator.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,25 +1,26 @@
-from typing import List
+from __future__ import annotations
 
 from omegaconf import OmegaConf
 from shapely.geometry import LineString
+import cv2
 
 from dna import Point
-from dna.tracker.tracker import TrackState
-from .local_path_event import LocalPathEvent
-from .track_event import TrackEvent
-from .event_processor import EventProcessor
+from dna.color import BGR
+from dna.track.track_state import TrackState
+from ..event.local_path_event import LocalPathEvent
+from dna.event import TrackEvent, EventProcessor
 
 class Session:
     def __init__(self, node_id:str, luid:str) -> None:
         self.node_id = node_id
         self.luid = luid
 
-        self.points:List[Point] = []
-        self.world_coords:List[Point] = []
+        self.points:list[Point] = []
+        self.world_coords:list[Point] = []
         self.first_frame = -1
         self.last_frame = -1
 
     @property
     def length(self) -> int:
         return len(self.points)
 
@@ -27,57 +28,56 @@
         self.points.append(ev.location.center())
         self.world_coords.append(ev.world_coord)
         if self.first_frame < 0:
             self.first_frame = ev.frame_index
         self.last_frame = ev.frame_index
 
     def build_local_path(self, length: int, cont: bool) -> LocalPathEvent:
-        camera_path = LineString([pt.to_tuple() for pt in self.points[:length]]).wkb_hex
-        world_path = LineString([pt.to_tuple() for pt in self.world_coords[:length]]).wkb_hex
+        camera_path = LineString([tuple(pt.xy) for pt in self.points[:length]]).wkb_hex
+        world_path = LineString([tuple(pt.xy) for pt in self.world_coords[:length]]).wkb_hex
         self.points = self.points[length:]
         self.world_coords = self.world_coords[length:]
 
-        return LocalPathEvent(node_id=self.node_id, luid=self.luid,
-                              camera_path=camera_path, world_path = world_path,
+        return LocalPathEvent(node_id=self.node_id, track_id=self.luid,
+                              camera_path=camera_path, world_path=world_path,
                               first_frame=self.first_frame, last_frame=self.last_frame,
                               continuation=cont)
 
-
-class GenerateLocalPath(EventProcessor):
+class LocalPathGenerator(EventProcessor):
     MAX_PATH_LENGTH = 100
 
     def __init__(self, conf:OmegaConf) -> None:
         EventProcessor.__init__(self)
 
-        self.max_path_length = conf.get('max_path_length', GenerateLocalPath.MAX_PATH_LENGTH)
+        self.max_path_length = conf.get('max_path_length', LocalPathGenerator.MAX_PATH_LENGTH)
         self.sessions = dict()
 
     def close(self) -> None:
         super().close()
         
         # build local paths from the unfinished sessions and upload them
         for session in self.sessions.values():
             pev = session.build_local_path(cont=False)
-            self.publish_event(pev)
+            self._publish_event(pev)
         self.sessions.clear()
 
 
     def handle_event(self, ev: TrackEvent) -> None:
-        session = self.sessions.get(ev.luid, None)
+        session = self.sessions.get(ev.track_id, None)
         if session is None:
-            session = Session(ev.node_id, ev.luid)
-            self.sessions[ev.luid] = session
+            session = Session(ev.node_id, ev.track_id)
+            self.sessions[ev.track_id] = session
 
         if ev.state == TrackState.Deleted:
-            self.sessions.pop(ev.luid, None)
+            self.sessions.pop(ev.track_id, None)
             if session.length > 0:
                 pev = session.build_local_path(length=session.length, cont=False)
-                self.publish_event(pev)
+                self._publish_event(pev)
         else:
             if session.length >= self.max_path_length + 10:
                 pev = session.build_local_path(length=self.max_path_length, cont=True)
-                self.publish_event(pev)
+                self._publish_event(pev)
 
                 # refresh the current session
                 # session = Session(ev.node_id, ev.luid)
                 # self.sessions[ev.luid] = session
             session.append(ev)
```

## Comparing `dna/node/local_path_event.py` & `dna/event/local_path_event.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 from dataclasses import dataclass, field
 import json
 
-from .kafka_event import KafkaEvent
+from dna.event import KafkaEvent
 
 
 @dataclass(frozen=True, eq=True, order=True)    # slots=True
 class LocalPathEvent(KafkaEvent):
     node_id: str
-    luid: int
+    track_id: str
     camera_path:str = field(compare=False, repr=False, hash=False)
     world_path:str = field(compare=False, repr=False, hash=False)
     first_frame: int
     last_frame: int
     continuation:bool = field(compare=False)
 
     def key(self) -> str:
         return self.node_id.encode('utf-8')
     
     def serialize(self) -> str:
-        serialized = { 'node_id': self.node_id, 'luid': self.luid,
+        serialized = { 'node_id': self.node_id, 'track_id': self.track_id,
                         'camera_path': self.camera_path, 'world_path': self.world_path,
                         'first_frame': self.first_frame, 'last_frame': self.last_frame,
                         'continuation': self.continuation }
         return json.dumps(serialized, separators=(',', ':')).encode('utf-8')
```

## Comparing `dna/node/track_event.py` & `scripts/dna_show_mc_locations.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,146 +1,157 @@
 from __future__ import annotations
 
-from typing import Optional, List
-from dataclasses import dataclass, field, asdict
-import json
+from typing import Union, Optional, NamedTuple
+from contextlib import closing
+from collections import defaultdict
+from dataclasses import dataclass
 
 import numpy as np
+import cv2
+from omegaconf import OmegaConf
+import json
 
-from dna import Box, Point
-from dna.tracker import Track
-from dna.tracker.tracker import TrackState
-from .kafka_event import KafkaEvent
-
+from dna import Box, Image, BGR, color, Frame, Point
+from dna.camera import Camera
+from dna.event.track_event import TrackEvent
+from dna.node.world_coord_localizer import WorldCoordinateLocalizer, ContactPointType
+from dna.node import stabilizer
+from dna.support import plot_utils
+from dna.track.track_state import TrackState
+
+COLORS = {
+    'etri:04': color.RED,
+    'etri:05': color.BLUE,
+    'etri:06': color.GREEN,
+    'etri:07': color.YELLOW
+}
+MAX_DISTS = {'etri:04': 50, 'etri:05': 40, 'etri:06': 45, 'etri:07': 40 }
 
-@dataclass(frozen=True, eq=True, order=False, repr=False)    # slots=True
-class TrackEvent(KafkaEvent):
-    node_id: str
+@dataclass(frozen=True)
+class Location:
     luid: int
-    state: TrackState
-    location: Box = field(hash=False)
-    frame_index: int
-    ts: int = field(hash=False)
-    world_coord: Optional[Point] = field(default=None, repr=False, hash=False)
-    distance: Optional[float] = field(default=None, repr=False, hash=False)
-
-    def key(self) -> str:
-        return self.node_id.encode('utf-8')
-
-    def __lt__(self, other) -> bool:
-        if self.frame_index < other.frame_index:
-            return True
-        elif self.frame_index == other.frame_index:
-            return self.luid < other.luid
-        else:
-            return False
-
-    @staticmethod
-    def from_track(node_id:str, track:Track) -> TrackEvent:
-        return TrackEvent(node_id=node_id, luid=track.id, state=track.state, location=track.location,
-                        frame_index=track.frame_index, ts=int(track.ts * 1000))
-
-    @staticmethod
-    def from_json(json_str:str) -> TrackEvent:
-        json_obj = json.loads(json_str)
-
-        world_coord = json_obj.get('world_coord', None)
-        if world_coord is not None:
-            world_coord = Point.from_np(world_coord)
-        distance = json_obj.get('distance', None)
-
-        return TrackEvent(node_id=json_obj['node'],
-                            luid=json_obj['luid'],
-                            state=TrackState[json_obj['state']],
-                            location=Box.from_tlbr(np.array(json_obj['location'])),
-                            frame_index=json_obj['frame_index'],
-                            ts=json_obj['ts'],
-                            world_coord=world_coord,
-                            distance=distance)
-
-        print(type(json_obj))
-
-    def to_json(self) -> str:
-        tlbr_expr = [round(v, 2) for v in self.location.to_tlbr().tolist()]
-        serialized = {'node':self.node_id, 'luid':self.luid, 'state':self.state.name,
-                    'location':tlbr_expr, 'frame_index':self.frame_index, 'ts': self.ts}
-        if self.world_coord is not None:
-            serialized['world_coord'] = [round(v, 3) for v in self.world_coord.to_tuple()]
-        if self.distance is not None:
-            serialized['distance'] = round(self.distance,2)
-
-        return json.dumps(serialized, separators=(',', ':'))
-
-    def serialize(self) -> str:
-        tlbr_expr = [round(v, 2) for v in self.location.to_tlbr().tolist()]
-        serialized = {'node':self.node_id, 'luid':self.luid, 'state':self.state.name,
-                    'location':tlbr_expr, 'frame_index':self.frame_index, 'ts': self.ts}
-        if self.world_coord is not None:
-            serialized['world_coord'] = [round(v, 3) for v in self.world_coord.to_tuple()]
-        if self.distance is not None:
-            serialized['distance'] = round(self.distance,2)
-
-        return self.to_json().encode('utf-8')
-
-    def updated(self, **kwargs) -> TrackEvent:
-        fields = asdict(self)
-        for key, value in kwargs.items():
-            fields[key] = value
-        return TrackEvent(**fields)
-
-    def to_csv(self) -> str:
-        vlist = [self.node_id, self.luid, self.state.name] \
-                + self.location.to_tlbr().tolist() \
-                + [self.frame_index, self.ts]
-        if self.world_coord is not None:
-            vlist += np.round(self.world_coord.xy, 3).tolist() + [round(self.distance, 3)]
-        else:
-            vlist += ['', '']
-
-        return ','.join([str(v) for v in vlist])
-
-    @staticmethod
-    def from_csv(csv: str):
-        parts = csv.split(',')
-
-        node_id = parts[0]
-        luid = int(parts[1])
-        state = TrackState[parts[2]]
-        loc = Box.from_tlbr(np.array([float(s) for s in parts[3:7]]))
-        frame_idx = int(parts[7])
-        ts=int(parts[8])
-        xy_str = parts[9:11]
-        if len(xy_str[0]) > 0:
-            wcoord = Point.from_np(np.array([float(s) for s in xy_str]))
-            dist = float(parts[11])
-        else:
-            wcoord = None
-            dist = None
+    point: Point
+    distance: float
+
+import argparse
+def parse_args():
+    parser = argparse.ArgumentParser(description="show target locations")
+    parser.add_argument("track_files", nargs='+', help="track files to display")
+    parser.add_argument("--offsets", metavar="csv", help="camera frame offsets")
+    parser.add_argument("--interactive", "-i", action='store_true', help="show trajectories interactively")
+    return parser.parse_known_args()
+
+
+def load_json(track_file:str, localizer:WorldCoordinateLocalizer) -> tuple[str, dict[int, list[Location]]]:
+    def parse_line(line:str) -> tuple[str, str, int, TrackState, Location]:
+        ev = TrackEvent.from_json(line)
+
+        pt_m, dist = localizer.from_camera_box(ev.location.tlbr)
+        pt = Point(localizer.to_image_coord(pt_m))
+        loc = Location(luid=ev.track_id, point=pt, distance=dist)
+        return (ev.node_id, ev.track_id, ev.frame_index, ev.state, loc)
+
+    with open(track_file) as f:
+        node_id = None
+        indexed_locations = defaultdict(list)
+        state_accum = defaultdict(int)
+        for line in f.readlines():
+            node_id, track_id, index, state, loc = parse_line(line)
+            if state == TrackState.TemporarilyLost:
+                state_accum[track_id] += 1
+            if state != TrackState.Deleted and state_accum[track_id] < 3:
+                indexed_locations[index].append(loc)
+            if state == TrackState.Confirmed:
+                state_accum[track_id] = 0
+            elif state == TrackState.Deleted:
+                del state_accum[track_id]
             
-        return TrackEvent(node_id=node_id, luid=luid, state=state, location=loc,
-                            frame_index=frame_idx, ts=ts, world_coord=wcoord, distance=dist)
+    return node_id, dict(indexed_locations)
+
+
+class MCLocationDrawer:
+    def __init__(self, mc_locations: list[tuple[str,dict[int, list[Location]]]],
+                 world_image: Image, offsets:list[int]) -> None:
+        self.mc_locations = mc_locations
+        self.world_image = world_image
+        self.indexes = list(mc_locations[0][1].keys())
+        self.offsets = offsets
+
+    def draw_frame_index(self, convas: Image, frame_indexes:list[int]) -> Image:
+        index_str = ', '.join([str(i) for i in frame_indexes])
+        return cv2.putText(convas, f'frames={index_str}', (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color.RED, 2)
+    
+    def draw_frame(self, slot_no:int) -> Image:
+        index = self.indexes[slot_no]
+        frame_indexes = [index + offset for offset in self.offsets]
+        
+        convas = self.world_image.copy()
+        convas = self.draw_frame_index(convas, frame_indexes)
+        for index, (node_id, idxed_locations) in zip(frame_indexes, self.mc_locations):
+            color = COLORS[node_id]
+            for loc in idxed_locations.get(index, []):
+                if loc.distance < MAX_DISTS[node_id]:
+                    self._draw_circles(convas, loc, fill_color=color)
+                    # convas = cv2.circle(convas, tuple(loc.point.to_rint().xy), radius=7, color=color, thickness=-1, lineType=cv2.LINE_AA)
+        cv2.imshow("locations", convas)
+        return convas
+
+    def draw(self, title='locations', interactive:bool=True) -> Image:
+        slot_no = 0
+        self.draw_frame(slot_no)
+        
+        while True:
+            delay = 1 if interactive else 100
+            key = cv2.waitKey(delay) & 0xFF
+            if key == ord('q'):
+                break
+            elif  key == ord(' '):
+                interactive = not interactive
+            elif interactive:
+                if key == ord('n'):
+                    if slot_no < len(self.indexes)-1:
+                        slot_no += 1
+                        self.draw_frame(slot_no)
+                elif key == ord('p'):
+                    if slot_no > 0:
+                        slot_no -= 1
+                        self.draw_frame(slot_no)
+                elif key == ord('s'):
+                    image = self.draw_frame(slot_no)
+                    cv2.imwrite("output/output.png", image)
+            else:
+                if key == 0xFF:
+                    if slot_no < len(self.indexes)-1:
+                        slot_no += 1
+                        self.draw_frame(slot_no)
+        cv2.destroyWindow(title)
+
+    def _draw_circles(self, convas:Image, location:Location, fill_color:BGR) -> Image:
+        center = tuple(location.point.to_rint().xy)
+        # convas = cv2.circle(convas, center, radius=3, color=color.RED, thickness=-1, lineType=cv2.LINE_AA)
+        convas = plot_utils.draw_label(convas, f'{location.distance:.1f}', location.point.to_rint(),
+                                       color=color.BLACK, fill_color=fill_color, thickness=1)
+        return convas
+
+
+def main():
+    args, _ = parse_args()
+
+    if args.offsets is not None:
+        offsets = [max(0, int(vstr)) for vstr in args.offsets.split(',')]
+    else:
+        offsets = [0] * len(args.video_uris)
+
+    mc_locations:list[tuple[str,dict[int, list[Location]]]] = []
+    for i, track_file in enumerate(args.track_files):
+        localizer = WorldCoordinateLocalizer('regions/etri_testbed/etri_testbed.json',
+                                             camera_index=i,
+                                             contact_point=ContactPointType.Simulation)
+        mc_locations.append(load_json(track_file, localizer))
     
-    def __repr__(self) -> str:
-        return (f"TrackEvent[node={self.node_id}, id={self.luid}, loc={self.location}, "
-                f"frame={self.frame_index}, ts={self.ts}]")
-
-EOT:TrackEvent = TrackEvent(node_id=None, luid=None, state=None, location=None,
-                            world_coord=None, distance=None, frame_index=-1, ts=-1)
-
-
-from dna import Frame
-from dna.tracker import Track, TrackProcessor
-from .event_processor import EventQueue
-class TrackEventSource(TrackProcessor, EventQueue):
-    def __init__(self, node_id:str) -> None:
-        TrackProcessor.__init__(self)
-        EventQueue.__init__(self)
-
-        self.node_id = node_id
-
-    def track_started(self, tracker) -> None: pass
-    def track_stopped(self, tracker) -> None:
-        self.close()
-
-    def process_tracks(self, tracker, frame: Frame, tracks: List[Track]) -> None:
-        for track in tracks:
-            self.publish_event(TrackEvent.from_track(self.node_id, track))
+    world_image = cv2.imread("data/ETRI_221011.png", cv2.IMREAD_COLOR)
+
+    drawer = MCLocationDrawer(mc_locations, world_image=world_image, offsets=offsets)
+    drawer.draw()
+
+if __name__ == '__main__':
+    main()
```

## Comparing `dna/tracker/track_pipeline.py` & `dna/track/track_pipeline.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,165 +1,192 @@
 from __future__ import annotations
-from typing import List, Optional
+from typing import Optional
+
 import collections
+from pathlib import Path
 
 from omegaconf import OmegaConf
 import numpy as np
+import cv2
 
-from dna import plot_utils, color, Point, BGR, Image, Frame
-from .tracker import Track, TrackState, ObjectTracker, TrackProcessor, DetectionBasedObjectTracker
+from dna import color, Point, BGR, Image, Frame
+from dna.support import plot_utils
+from .track_state import TrackState
+from .types import ObjectTrack, ObjectTracker, TrackProcessor
+from . import utils
 
 
-class TrackWriter(TrackProcessor):
-    def __init__(self, track_file: str) -> None:
+class TrackCsvWriter(TrackProcessor):
+    def __init__(self, track_file:str) -> None:
         super().__init__()
 
         self.track_file = track_file
         self.out_handle = None
 
-    def track_started(self, tracker: ObjectTracker) -> None:
+    def track_started(self, tracker:ObjectTracker) -> None:
         super().track_started(tracker)
 
+        parent = Path(self.track_file).parent
+        if not parent.exists():
+            parent.mkdir(parents=True, exist_ok=True)
         self.out_handle = open(self.track_file, 'w')
     
-    def track_stopped(self, tracker: ObjectTracker) -> None:
+    def track_stopped(self, tracker:ObjectTracker) -> None:
         if self.out_handle:
             self.out_handle.close()
             self.out_handle = None
 
         super().track_stopped(tracker)
 
-    def process_tracks(self, tracker: ObjectTracker, frame: Frame, tracks: List[Track]) -> None:
+    def process_tracks(self, tracker:ObjectTracker, frame:Frame, tracks:list[ObjectTrack]) -> None:
         for track in tracks:
-            self.out_handle.write(track.to_string() + '\n')
+            self.out_handle.write(track.to_csv() + '\n')
 
 class Trail:
     __slots__ = ('__tracks', )
 
     def __init__(self) -> None:
         self.__tracks = []
 
     @property
-    def tracks(self) -> List[Track]:
+    def tracks(self) -> list[ObjectTrack]:
         return self.__tracks
 
-    def append(self, track: Track) -> None:
+    def append(self, track:ObjectTrack) -> None:
         self.__tracks.append(track)
 
-    def draw(self, convas: np.ndarray, color: color.BGR, line_thickness=2) -> np.ndarray:
+    def draw(self, convas:np.ndarray, color:color.BGR, line_thickness=2) -> np.ndarray:
         # track의 중점 값들을 선으로 이어서 출력함
-        track_centers: List[Point] = [t.location.center() for t in self.tracks[-11:]]
+        track_centers:list[Point] = [t.location.center() for t in self.tracks[-11:]]
         return plot_utils.draw_line_string(convas, track_centers, color, line_thickness)
     
 
 class TrailCollector(TrackProcessor):
     __slots__ = ('trails', )
 
     def __init__(self) -> None:
         super().__init__()
         self.trails = collections.defaultdict(lambda: Trail())
 
-    def get_trail(self, track_id: str) -> Trail:
+    def get_trail(self, track_id:str) -> Trail:
         return self.trails[track_id]
 
-    def track_started(self, tracker: ObjectTracker) -> None: pass
-    def track_stopped(self, tracker: ObjectTracker) -> None: pass
+    def track_started(self, tracker:ObjectTracker) -> None: pass
+    def track_stopped(self, tracker:ObjectTracker) -> None: pass
 
-    def process_tracks(self, tracker: ObjectTracker, frame: Frame, tracks: List[Track]) -> None:      
+    def process_tracks(self, tracker:ObjectTracker, frame:Frame, tracks:list[ObjectTrack]) -> None:      
         for track in tracks:
             if track.state == TrackState.Confirmed  \
                 or track.state == TrackState.TemporarilyLost    \
                 or track.state == TrackState.Tentative:
                 self.trails[track.id].append(track)
             elif track.state == TrackState.Deleted:
                 self.trails.pop(track.id, None)
 
 
-from dna.camera import ImageProcessor, FrameProcessor
+from dna.camera import FrameProcessor
 class TrackingPipeline(FrameProcessor):
-    __slots__ = ( 'tracker', 'is_detection_based', 'trail_collector', 'track_processors', 'draw_tracks', 'show_zones' )
-
-    @classmethod
-    def load(cls, img_proc: ImageProcessor, tracker_conf: OmegaConf,
-                            track_processors: List[TrackProcessor]=[]) -> TrackingPipeline:
-        tracker_uri = tracker_conf.get("uri", "dna.tracker.dna_deepsort")
-        parts = tracker_uri.split(':', 1)
-        id, query = tuple(parts) if len(parts) > 1 else (tracker_uri, "")
-
-        from dna import Box
-        domain = Box.from_size(img_proc.capture.size)
-        
-        import importlib
-        tracker_module = importlib.import_module(id)
-        tracker = tracker_module.load(domain, tracker_conf)
-
-        draw_tracks = img_proc.is_drawing() and tracker_conf.get("draw_tracks", True)
-        draw_zones = img_proc.is_drawing() and tracker_conf.get("draw_zones", False)
-
-        output = tracker_conf.get("output", None)
-        if output is not None:
-            track_processors = [TrackWriter(output)] + track_processors
-            
-        return cls(tracker=tracker, processors=track_processors, draw_tracks=draw_tracks, draw_zones=draw_zones)
+    __slots__ = ( 'tracker', '_trail_collector', '_track_processors', 'draw')
 
-    def __init__(self, tracker: ObjectTracker, processors: List[TrackProcessor]=[], draw_tracks: bool=False,
-                draw_zones=False) -> None:
+    def __init__(self, tracker:ObjectTracker, draw:list[str]=[]) -> None:
         super().__init__()
 
         self.tracker = tracker
-        self.is_detection_based = isinstance(self.tracker, DetectionBasedObjectTracker)
-        self.trail_collector = TrailCollector()
-        self.track_processors = processors + [self.trail_collector]
-        self.draw_tracks = draw_tracks
-        self.draw_zones = draw_zones
+        self._trail_collector = TrailCollector()
+        self._track_processors:list[TrackProcessor] = [self._trail_collector]
+        self.draw = draw
+
+    @staticmethod
+    def load(tracker_conf:OmegaConf) -> TrackingPipeline:
+        from .dna_tracker import DNATracker
+        tracker = DNATracker.load(tracker_conf)
+        
+        draw = tracker_conf.get("draw", [])
+        tracking_pipeline = TrackingPipeline(tracker=tracker, draw=draw)
+
+        if output := tracker_conf.get("output", None):
+            tracking_pipeline.add_track_processor(TrackCsvWriter(output))
+            
+        return tracking_pipeline
+        
+    def add_track_processor(self, proc:TrackProcessor) -> None:
+        self._track_processors.append(proc)
 
     def on_started(self, capture) -> None:
-        for processor in self.track_processors:
+        for processor in self._track_processors:
             processor.track_started(self.tracker)
 
     def on_stopped(self) -> None:
-        for processor in self.track_processors:
+        for processor in self._track_processors:
             processor.track_stopped(self.tracker)
 
-    def set_control(self, key: int) -> int:
-        if key == ord('r'):
-            self.draw_zones = not self.draw_zones
+    def set_control(self, key:int) -> int:
+        def toggle(tag:str):
+            if tag in self.draw:
+                self.draw.pop(tag)
+            else:
+                self.draw.append(tag)
+            
+        if key == ord('t'):
+            toggle('tracks')
+        if key == ord('b'):
+            toggle('blind_zones')
+        if key == ord('z'):
+            toggle('track_zones')
+        if key == ord('e'):
+            toggle('exit_zones')
+        if key == ord('s'):
+            toggle('stable_zones')
+        if key == ord('m'):
+            toggle('magnifying_zones')
         return key
 
-    def process_frame(self, frame: Frame) -> Frame:
+    def process_frame(self, frame:Frame) -> Frame:
         tracks = self.tracker.track(frame)
 
-        for processor in self.track_processors:
+        for processor in self._track_processors:
             processor.process_tracks(self.tracker, frame, tracks)
 
-        convas = frame.image
-        if self.draw_zones:
-            for region in self.tracker.params.blind_zones:
-                convas = region.draw(convas, color.MAGENTA, 2)
-            for region in self.tracker.params.dim_zones:
-                convas = region.draw(convas, color.RED, 2)
-
-        if self.draw_tracks:
-            if self.is_detection_based:
-                for det in self.tracker.last_frame_detections():
-                    convas = det.draw(convas, color.WHITE, line_thickness=2)
-
-            for track in tracks:
-                if track.is_tentative():
-                    convas = self.draw_track_trail(convas, track, color.RED, trail_color=color.BLUE)
-            for track in sorted(tracks, key=lambda t: t.id, reverse=True):
-                if not track.is_tentative():
+        if self.draw:
+            convas = frame.image
+            if 'track_zones' in self.draw:
+                for zone in self.tracker.params.track_zones:
+                    convas = zone.draw(convas, color.RED, 1)
+            if 'blind_zones' in self.draw:
+                for zone in self.tracker.params.blind_zones:
+                    convas = zone.draw(convas, color.YELLOW, 1)
+            if 'exit_zones' in self.draw:
+                for zone in self.tracker.params.exit_zones:
+                    convas = zone.draw(convas, color.RED, 1)
+            if 'stable_zones' in self.draw:
+                for zone in self.tracker.params.stable_zones:
+                    convas = zone.draw(convas, color.BLUE, 1)
+            if 'magnifying_zones' in self.draw:
+                for roi in self.tracker.params.magnifying_zones:
+                    roi.draw(convas, color.ORANGE, line_thickness=1)
+
+            if 'tracks' in self.draw:
+                tracks = self.tracker.tracks
+                for track in tracks:
+                    if hasattr(track, 'last_detection'):
+                        det = track.last_detection
+                        if det:
+                            convas = det.draw(convas, color.WHITE, line_thickness=1)
+                for track in tracks:
+                    if track.is_tentative():
+                        convas = self.draw_track_trail(convas, track, color.RED, trail_color=color.BLUE, line_thickness=1)
+                for track in sorted(tracks, key=lambda t:t.id, reverse=True):
                     if track.is_confirmed():
-                        convas = self.draw_track_trail(convas, track, color.BLUE, trail_color=color.RED)
-                    if track.is_temporarily_lost():
-                        convas = self.draw_track_trail(convas, track, color.BLUE, trail_color=color.LIGHT_GREY)
+                        convas = self.draw_track_trail(convas, track, color.BLUE, trail_color=color.RED, line_thickness=1)
+                    elif track.is_temporarily_lost():
+                        convas = self.draw_track_trail(convas, track, color.BLUE, trail_color=color.LIGHT_GREY, line_thickness=1)
             return Frame(convas, frame.index, frame.ts)
         else:
             return frame
     
-    def draw_track_trail(self, convas:Image, track: Track, color: color.BGR, label_color: BGR=color.WHITE,
-                        trail_color: Optional[BGR]=None) -> np.ndarray:
-        convas = track.draw(convas, color, label_color=label_color, line_thickness=2)
+    def draw_track_trail(self, convas:Image, track:ObjectTrack, color:color.BGR, label_color:BGR=color.WHITE,
+                        trail_color:Optional[BGR]=None, line_thickness=2) -> np.ndarray:
+        convas = track.draw(convas, color, label_color=label_color, line_thickness=line_thickness)
 
         if trail_color:
-            trail = self.trail_collector.get_trail(track.id)
-            return trail.draw(convas, trail_color)
+            trail = self._trail_collector.get_trail(track.id)
+            return trail.draw(convas, trail_color, line_thickness=line_thickness)
```

## Comparing `dna/tracker/dna_deepsort/deepsort/kalman_filter.py` & `dna/track/kalman_filter.py`

 * *Files 5% similar despite different names*

```diff
@@ -45,21 +45,16 @@
         for i in range(ndim):
             self._motion_mat[i, ndim + i] = dt
         self._update_mat = np.eye(ndim, 2 * ndim)
 
         # Motion and observation uncertainty are chosen relative to the current
         # state estimate. These weights control the amount of uncertainty in
         # the model. This is a bit hacky.
-        # self._std_weight_position = 1. / 50#20
-        # self._std_weight_velocity = 1. / 200#160
-        # kwlee
-        self._std_weight_position = 1. / 10
-        self._std_weight_velocity = 1. / 80
-        # self._std_weight_position = 1. / 100
-        # self._std_weight_velocity = 1. / 400
+        self._std_weight_position = 1. / 20
+        self._std_weight_velocity = 1. / 160
 
     def initiate(self, measurement):
         """Create track from unassociated measurement.
 
         Parameters
         ----------
         measurement : ndarray
@@ -118,15 +113,16 @@
             self._std_weight_velocity * mean[3],
             self._std_weight_velocity * mean[3],
             1e-5,
             self._std_weight_velocity * mean[3]]
         motion_cov = np.diag(np.square(np.r_[std_pos, std_vel]))
 
         mean = np.dot(self._motion_mat, mean)
-        covariance = np.linalg.multi_dot((self._motion_mat, covariance, self._motion_mat.T)) + motion_cov
+        covariance = np.linalg.multi_dot((
+            self._motion_mat, covariance, self._motion_mat.T)) + motion_cov
 
         return mean, covariance
 
     def project(self, mean, covariance):
         """Project state distribution to measurement space.
 
         Parameters
@@ -147,15 +143,16 @@
             self._std_weight_position * mean[3],
             self._std_weight_position * mean[3],
             1e-1,
             self._std_weight_position * mean[3]]
         innovation_cov = np.diag(np.square(std))
 
         mean = np.dot(self._update_mat, mean)
-        covariance = np.linalg.multi_dot((self._update_mat, covariance, self._update_mat.T))
+        covariance = np.linalg.multi_dot((
+            self._update_mat, covariance, self._update_mat.T))
         return mean, covariance + innovation_cov
 
     def update(self, mean, covariance, measurement):
         """Run Kalman filter correction step.
 
         Parameters
         ----------
@@ -172,28 +169,32 @@
         -------
         (ndarray, ndarray)
             Returns the measurement-corrected state distribution.
 
         """
         projected_mean, projected_cov = self.project(mean, covariance)
 
-        chol_factor, lower = scipy.linalg.cho_factor(projected_cov, lower=True, check_finite=False)
-        kalman_gain = scipy.linalg.cho_solve((chol_factor, lower), np.dot(covariance, self._update_mat.T).T,
-                                                check_finite=False).T
+        chol_factor, lower = scipy.linalg.cho_factor(
+            projected_cov, lower=True, check_finite=False)
+        kalman_gain = scipy.linalg.cho_solve(
+            (chol_factor, lower), np.dot(covariance, self._update_mat.T).T,
+            check_finite=False).T
         innovation = measurement - projected_mean
 
         new_mean = mean + np.dot(innovation, kalman_gain.T)
-        new_covariance = covariance - np.linalg.multi_dot((kalman_gain, projected_cov, kalman_gain.T))
+        new_covariance = covariance - np.linalg.multi_dot((
+            kalman_gain, projected_cov, kalman_gain.T))
         return new_mean, new_covariance
 
-    def gating_distance(self, mean, covariance, measurements, only_position=False):
+    def gating_distance(self, mean, covariance, measurements,
+                        only_position=False):
         """Compute gating distance between state distribution and measurements.
 
-        A suitable distance threshold can be obtained from `chi2inv95`.
-        If `only_position` is False, the chi-square distribution has 4 degrees of
+        A suitable distance threshold can be obtained from `chi2inv95`. If
+        `only_position` is False, the chi-square distribution has 4 degrees of
         freedom, otherwise 2.
 
         Parameters
         ----------
         mean : ndarray
             Mean vector over the state distribution (8 dimensional).
         covariance : ndarray
@@ -205,22 +206,24 @@
         only_position : Optional[bool]
             If True, distance computation is done with respect to the bounding
             box center position only.
 
         Returns
         -------
         ndarray
-            Returns an array of length N, where the i-th element contains the squared Mahalanobis distance
-            between (mean, covariance) and `measurements[i]`.
+            Returns an array of length N, where the i-th element contains the
+            squared Mahalanobis distance between (mean, covariance) and
+            `measurements[i]`.
 
         """
         mean, covariance = self.project(mean, covariance)
         if only_position:
             mean, covariance = mean[:2], covariance[:2, :2]
             measurements = measurements[:, :2]
 
         cholesky_factor = np.linalg.cholesky(covariance)
         d = measurements - mean
-        z = scipy.linalg.solve_triangular(cholesky_factor, d.T, lower=True, check_finite=False,
-                                            overwrite_b=True)
+        z = scipy.linalg.solve_triangular(
+            cholesky_factor, d.T, lower=True, check_finite=False,
+            overwrite_b=True)
         squared_maha = np.sum(z * z, axis=0)
         return squared_maha
```

## Comparing `dna/tracker/dna_deepsort/deepsort/siamese_net.py` & `dna/track/siamese_net.py`

 * *Files identical despite different names*

## Comparing `scripts/dna_node_detect.py` & `scripts/dna_track.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,63 +1,71 @@
+import warnings
+warnings.filterwarnings("ignore")
+
 from contextlib import closing
 from datetime import timedelta
 
 import argparse
 from omegaconf import OmegaConf
 
+import warnings
+from torch.serialization import SourceChangeWarning
+warnings.filterwarnings("ignore", category=SourceChangeWarning)
+
 import dna
-from dna.camera import Camera, ImageProcessor
-from dna.camera.utils import create_camera_from_conf
-from dna.detect.detecting_processor import DetectingProcessor
+from dna import config
+from dna.camera import ImageProcessor, create_opencv_camera_from_conf
+from dna.track import TrackingPipeline
+from scripts.utils import load_camera_conf
 
-__DEFAULT_DETECTOR_URI = 'dna.detect.yolov5:model=l&score=0.4'
 
 def parse_args():
-    parser = argparse.ArgumentParser(description="Detect objects in an video")
+    parser = argparse.ArgumentParser(description="Track objects from a camera")
     parser.add_argument("--conf", metavar="file path", help="configuration file path")
-    parser.add_argument("--node", metavar="id", help="DNA node id")
+    
+    parser.add_argument("--camera", metavar="uri", help="target camera uri")
+    parser.add_argument("--sync", action='store_true', help="sync to camera fps")
+    parser.add_argument("--begin_frame", type=int, metavar="number", default=1, help="the first frame number")
+    parser.add_argument("--end_frame", type=int, metavar="number", default=argparse.SUPPRESS,
+                        help="the last frame number")
 
-    parser.add_argument("--detector", help="Object detection algorithm.", default=__DEFAULT_DETECTOR_URI)
-    parser.add_argument("--output", "-o", metavar="csv file", help="output detection file.", default=None)
+    parser.add_argument("--output", "-o", metavar="csv file", default=argparse.SUPPRESS, help="output detection file.")
     parser.add_argument("--output_video", "-v", metavar="mp4 file", help="output video file.", default=None)
-    parser.add_argument("--show", "-s", nargs='?', const='0x0')
+    parser.add_argument("--show", "-s", nargs='?', const='0x0', default=None)
     parser.add_argument("--show_progress", "-p", help="display progress bar.", action='store_true')
-    parser.add_argument("--begin_frame", type=int, metavar="number", help="the first frame number", default=1)
-    parser.add_argument("--end_frame", type=int, metavar="number", help="the last frame number")
     parser.add_argument("--loop", action='store_true')
-    
-    parser.add_argument("--db_host", metavar="postgresql host", help="PostgreSQL host", default='localhost')
-    parser.add_argument("--db_port", metavar="postgresql port", help="PostgreSQL port", default=5432)
-    parser.add_argument("--db_name", metavar="dbname", help="PostgreSQL database name", default='dna')
-    parser.add_argument("--db_user", metavar="user_name", help="PostgreSQL user name", default='dna')
-    parser.add_argument("--db_password", metavar="password", help="PostgreSQL user password", default="urc2004")
 
     parser.add_argument("--logger", metavar="file path", help="logger configuration file path")
     return parser.parse_known_args()
 
 def main():
     args, _ = parse_args()
 
     dna.initialize_logger(args.logger)
-    conf, _, args_conf = dna.load_node_conf(args, ['show', 'show_progress'])
+    
+    # argument에 기술된 conf를 사용하여 configuration 파일을 읽는다.
+    conf = config.load(args.conf) if args.conf else OmegaConf.create()
     
     # 카메라 설정 정보 추가
-    conf.camera.begin_frame = args.begin_frame
-    conf.camera.end_frame = args.end_frame
-
-    camera:Camera = create_camera_from_conf(conf.camera)
+    config.update(conf, 'camera', load_camera_conf(args))
+    camera = create_opencv_camera_from_conf(conf.camera)
 
-    # ImageProcess 설정 정보 추가
-    conf.output = args.output
-    conf.output_video = args.output_video
+    # args에 포함된 ImageProcess 설정 정보를 추가한다.
+    config.update_values(conf, args, 'show', 'output_video', 'show_progress')
+    
     while True:
-        img_proc = ImageProcessor(camera.open(), conf)
-        detector = DetectingProcessor.load(detector_uri=args.detector, output=args.output,
-                                            draw_detections=img_proc.is_drawing())
-        img_proc.add_frame_processor(detector)
+        options = config.to_dict(config.filter(conf, 'show', 'output_video', 'show_progress'))
+        img_proc = ImageProcessor(camera.open(), **options)
+        
+        tracker_conf = config.get_or_insert_empty(conf, 'tracker')
+        config.update_values(tracker_conf, args, 'output')
+        
+        track_pipeline = TrackingPipeline.load(tracker_conf)
+        img_proc.add_frame_processor(track_pipeline)
+
         result: ImageProcessor.Result = img_proc.run()
         if not args.loop or result.failure_cause is not None:
             break
     print(result)
 
 if __name__ == '__main__':
 	main()
```

## Comparing `scripts/dna_node_show.py` & `scripts/dna_show.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,52 +1,55 @@
 
 from cv2 import merge
 from omegaconf import OmegaConf
 
-import dna
-from dna.camera import Camera, ImageProcessor
-from dna.camera.utils import create_camera_from_conf
+from dna import config, initialize_logger
+from dna.camera import ImageProcessor, create_opencv_camera_from_conf
+from scripts.utils import load_camera_conf
+from scripts import update_namespace_with_environ
 
 
 import argparse
 def parse_args():
     parser = argparse.ArgumentParser(description="Display a video")
     parser.add_argument("--conf", metavar="file path", help="configuration file path")
-    parser.add_argument("--node", metavar="id", help="DNA node id")
-    parser.add_argument("--uri", metavar="uri", help="target camera uri")
+    
+    parser.add_argument("--camera", metavar="uri", default=argparse.SUPPRESS, help="target camera uri")
+    parser.add_argument("--begin_frame", type=int, metavar="number", default=argparse.SUPPRESS,
+                        help="the first frame number")
+    parser.add_argument("--end_frame", type=int, metavar="number", default=argparse.SUPPRESS,
+                        help="the last frame number")
+    parser.add_argument("--nosync", action='store_true')
+
+    parser.add_argument("--output_video", "-v", metavar="mp4 file", default=argparse.SUPPRESS, help="output video file.")
     parser.add_argument("--show", "-s", nargs='?', const='0x0', default='0x0')
-    parser.add_argument("--show_progress", "-p", help="display progress bar.", action='store_true')
-    parser.add_argument("--begin_frame", type=int, metavar="number", help="the first frame number", default=1)
-    parser.add_argument("--end_frame", type=int, metavar="number", help="the last frame number")
     parser.add_argument("--loop", action='store_true')
 
-    parser.add_argument("--db_host", metavar="postgresql host", help="PostgreSQL host", default='localhost')
-    parser.add_argument("--db_port", metavar="postgresql port", help="PostgreSQL port", default=5432)
-    parser.add_argument("--db_name", metavar="dbname", help="PostgreSQL database name", default='dna')
-    parser.add_argument("--db_user", metavar="user_name", help="PostgreSQL user name", default='dna')
-    parser.add_argument("--db_password", metavar="password", help="PostgreSQL user password", default="urc2004")
-
     parser.add_argument("--logger", metavar="file path", help="logger configuration file path")
     return parser.parse_known_args()
 
 def main():
     args, _ = parse_args()
+    args = update_namespace_with_environ(args)
 
-    dna.initialize_logger(args.logger)
-    conf, _, args_conf = dna.load_node_conf(args, ['show', 'show_progress'])
+    initialize_logger(args.logger)
+    
+    # argument에 기술된 conf를 사용하여 configuration 파일을 읽는다.
+    conf = config.load(args.conf) if args.conf else OmegaConf.create()
     
     # 카메라 설정 정보 추가
-    conf.camera = dna.conf.get_config(conf, "camera", OmegaConf.create())
-    conf.camera.uri = dna.conf.get_config(conf.camera, "uri", args.uri)
-    conf.camera.begin_frame = args.begin_frame
-    conf.camera.end_frame = args.end_frame
-    camera:Camera = create_camera_from_conf(conf.camera)
+    config.update(conf, 'camera', load_camera_conf(args))
+    camera = create_opencv_camera_from_conf(conf.camera)
+
+    # args에 포함된 ImageProcess 설정 정보를 추가한다.
+    config.update_values(conf, args, 'show', 'output_video')
 
     while True:
-        img_proc = ImageProcessor(camera.open(), conf)
+        options = config.to_dict(config.filter(conf, 'show', 'output_video'))
+        img_proc = ImageProcessor(camera.open(), **options)
         result: ImageProcessor.Result = img_proc.run()
         if not args.loop or result.failure_cause is not None:
             break
     print(result)
 
 if __name__ == '__main__':
     main()
```

## Comparing `scripts/dna_node_track.py` & `scripts/dna_detect.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,63 +1,75 @@
 from contextlib import closing
+import sys
 from datetime import timedelta
-import warnings
-warnings.filterwarnings("ignore")
 
 import argparse
 from omegaconf import OmegaConf
 
 import dna
-from dna.camera import Camera, ImageProcessor, create_camera_from_conf
-from dna.tracker import TrackingPipeline
+from dna import config
+from dna.camera import ImageProcessor, create_opencv_camera_from_conf
+from dna.detect.detecting_processor import DetectingProcessor
+from scripts.utils import load_camera_conf
 
+__DEFAULT_DETECTOR_URI = 'dna.detect.yolov5:model=l&score=0.4'
+# __DEFAULT_DETECTOR_URI = 'dna.detect.yolov4'
 
 def parse_args():
-    parser = argparse.ArgumentParser(description="Track objects from a camera")
+    parser = argparse.ArgumentParser(description="Detect objects in an video")
     parser.add_argument("--conf", metavar="file path", help="configuration file path")
-    parser.add_argument("--node", metavar="id", help="DNA node id")
+    
+    parser.add_argument("--camera", metavar="uri", required=False, help="target camera uri")
+    parser.add_argument("--sync", action='store_true', help="sync to camera fps")
+    parser.add_argument("--begin_frame", type=int, metavar="number", help="the first frame number", default=1)
+    parser.add_argument("--end_frame", type=int, metavar="number", default=argparse.SUPPRESS,
+                        help="the last frame number")
 
-    parser.add_argument("--output", "-o", metavar="csv file", help="output detection file.", default=None)
-    parser.add_argument("--output_video", "-v", metavar="mp4 file", help="output video file.", default=None)
-    parser.add_argument("--show", "-s", nargs='?', const='0x0')
+    parser.add_argument("--detector", help="Object detection algorithm.", default=None)
+    parser.add_argument("--output", "-o", metavar="csv file", default=None, help="output detection file.")
+    parser.add_argument("--output_video", "-v", metavar="mp4 file", default=argparse.SUPPRESS, help="output video file.")
+    parser.add_argument("--show", "-s", nargs='?', const='0x0', default=None)
     parser.add_argument("--show_progress", "-p", help="display progress bar.", action='store_true')
-    parser.add_argument("--begin_frame", type=int, metavar="number", help="the first frame number", default=1)
-    parser.add_argument("--end_frame", type=int, metavar="number", help="the last frame number")
     parser.add_argument("--loop", action='store_true')
-    
-    parser.add_argument("--db_host", metavar="postgresql host", help="PostgreSQL host", default='localhost')
-    parser.add_argument("--db_port", metavar="postgresql port", help="PostgreSQL port", default=5432)
-    parser.add_argument("--db_name", metavar="dbname", help="PostgreSQL database name", default='dna')
-    parser.add_argument("--db_user", metavar="user_name", help="PostgreSQL user name", default='dna')
-    parser.add_argument("--db_password", metavar="password", help="PostgreSQL user password", default="urc2004")
 
     parser.add_argument("--logger", metavar="file path", help="logger configuration file path")
     return parser.parse_known_args()
 
 def main():
     args, _ = parse_args()
 
     dna.initialize_logger(args.logger)
-    conf, _, args_conf = dna.load_node_conf(args, ['show', 'show_progress'])
+    
+    # argument에 기술된 conf를 사용하여 configuration 파일을 읽는다.
+    conf = config.load(args.conf) if args.conf else OmegaConf.create()
     
     # 카메라 설정 정보 추가
-    conf.camera.begin_frame = args.begin_frame
-    conf.camera.end_frame = args.end_frame
-    camera:Camera = create_camera_from_conf(conf.camera)
-
-    # ImageProcess 설정 정보 추가
-    conf.output = args.output
-    conf.output_video = args.output_video
-    while True:
-        img_proc = ImageProcessor(camera.open(), conf)
-        tracker_conf = conf.get('tracker', OmegaConf.create())
-        tracker_conf = OmegaConf.merge(tracker_conf, dna.conf.filter(args_conf, ['output']))
-        track_pipeline = TrackingPipeline.load(img_proc, tracker_conf)
-        img_proc.add_frame_processor(track_pipeline)
+    config.update(conf, 'camera', load_camera_conf(args))
+    camera = create_opencv_camera_from_conf(conf.camera)
+    
+    # detector 설정 정보
+    detector_uri = args.detector
+    if detector_uri is None:
+        detector_uri = config.get(conf, "tracker.dna_deepsort.detector")
+    if detector_uri is None:
+        detector_uri = __DEFAULT_DETECTOR_URI
+        # print('detector is not specified', file=sys.stderr)
 
+    # args에 포함된 ImageProcess 설정 정보를 추가한다.
+    config.update_values(conf, args, 'show', 'output_video', 'show_progress')
+    
+    while True:
+        options = config.to_dict(config.filter(conf, 'show', 'output_video', 'show_progress'))
+        img_proc = ImageProcessor(camera.open(), **options)
+        
+        detector = DetectingProcessor.load(detector_uri=detector_uri,
+                                           output=args.output,
+                                           draw_detections=img_proc.is_drawing)
+        img_proc.add_frame_processor(detector)
+        
         result: ImageProcessor.Result = img_proc.run()
         if not args.loop or result.failure_cause is not None:
             break
     print(result)
 
 if __name__ == '__main__':
 	main()
```

## Comparing `scripts/dna_publish_event_server.py` & `scripts/dna_replay_node_events.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,43 +1,64 @@
 
-import heapq
-import time
+from typing import Union
+from collections.abc import Iterator, Callable
 
-import dna
-from dna import Box
-from dna.utils import initialize_logger
-from dna.node.publish_events_execution import PikaEventPublisherFactory
-from dna.pika_execution import PikaExecutionServer, PikaConnectionParameters
+import dataclasses
+import pickle
+from pathlib import Path
+
+from tqdm import tqdm
+from kafka import KafkaProducer
+from kafka.errors import NoBrokersAvailable
+from argparse import Namespace
+
+from dna import initialize_logger
+from dna.event import KafkaEvent, read_pickle_event_file, publish_kafka_events
+from dna.node import NodeEvent
+from scripts import *
 
 
 import argparse
 def parse_args():
-    parser = argparse.ArgumentParser(description="Detect Objects in a video file")
-    parser.add_argument("--host", "-i", metavar="broker host", help="RabbitMQ broker host", default="localhost")
-    parser.add_argument("--port", "-p", metavar="broker port", help="RabbitMQ broker port", default=5672)
-    parser.add_argument("--user", "-u", metavar="broker user", help="RabbitMQ broker user id", default="dna")
-    parser.add_argument("--password", "-w", metavar="broker password", help="RabbitMQ broker password",
-                        default="urc2004")
-    parser.add_argument("--request_qname", "-q", metavar="json file", help="track event file.",
-                        default="track_requests")
-    parser.add_argument("--servers", help="bootstrap-servers", default='localhost:9091,localhost:9092,localhost:9093')
-    parser.add_argument("--topic", help="topic name", default='node-tracks')
-    parser.add_argument("--sync", help="sync to publish events", action='store_true')
+    parser = argparse.ArgumentParser(argument_default=argparse.SUPPRESS, description="Tracklet and tracks commands")
+    
+    parser.add_argument("file", help="events file (pickle format)")
+    parser.add_argument("--kafka_brokers", default=['localhost:9092'], help="kafka broker hosts")
+    parser.add_argument("--sync", action='store_true', default=False)
+    parser.add_argument('--offsets', nargs='+', default=["0", "0", "0"], type=str, help='offsets')
+    parser.add_argument("--logger", metavar="file path", default=None, help="logger configuration file path")
 
-    parser.add_argument("--logger", metavar="file path", help="logger configuration file path")
     return parser.parse_known_args()
 
+
 def main():
     args, _ = parse_args()
 
-    dna.initialize_logger(args.logger)
-    conf, _, args_conf = dna.load_node_conf(args)
+    initialize_logger(args.logger)
+    
+    offsets = [int(offset) for offset in args.offsets]
+    def shift(ev:KafkaEvent) -> KafkaEvent:
+        return dataclasses.replace(ev,
+                                track_id=str(int(ev.track_id) + offsets[0]),
+                                frame_index=(ev.frame_index) + offsets[1],
+                                ts=(ev.ts) + offsets[2])
+    
+    print(f"loading events from the file '{args.file}'.")
+    events = read_pickle_event_file(args.file)
     
-    conn_params = PikaConnectionParameters(host=args.host, port=args.port,
-                                           user_id=args.user, password=args.password)
-    fact = PikaEventPublisherFactory(args.topic, args.servers.split(','), args.sync)
-    server = PikaExecutionServer(conn_params=conn_params, execution_factory=fact,
-                                 request_qname=args.request_qname)
-    server.run()
+    producer = None
+    try:
+        producer = KafkaProducer(bootstrap_servers=args.kafka_brokers)
+        
+        events = map(shift, tqdm(events))
+        publish_kafka_events(producer, events,
+                             topic_finder=lambda ev: NodeEvent.from_event_type(ev.__class__).topic,
+                             sync=args.sync)
+    except NoBrokersAvailable as e:
+        import sys
+        print(f'fails to connect to Kafka: server={args.kafka_brokers}', file=sys.stderr)
+    finally:
+        if producer:
+            producer.close()
 
 if __name__ == '__main__':
-	main()
+    main()
```

## Comparing `scripts/dna_publish_events.py` & `scripts/dna_restore_topics.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,60 +1,65 @@
-
-import heapq
+from __future__ import annotations
 
 import time
-import numpy as np
-from kafka import KafkaProducer, KafkaConsumer
+import pickle
+from tqdm import tqdm
+
+from kafka import KafkaProducer
+from kafka.errors import NoBrokersAvailable
 
-from dna import Box
-from dna.tracker import TrackState, Track
-from dna.node import TrackEvent
+from dna import initialize_logger
+from dna.event import TrackEvent, TrackFeature, TrackletMotion
+from scripts import update_namespace_with_environ
+
+TOPIC_TRACK_EVENTS = "track-events"
+TOPIC_MOTIONS = "track-motions"
+TOPIC_FEATURES = 'track-features'
 
 
 import argparse
 def parse_args():
-    parser = argparse.ArgumentParser(description="Detect Objects in a video file")
-    parser.add_argument("log_paths", nargs='+', help="configuration file path")
-    parser.add_argument("--servers", help="bootstrap-servers", default='kafka01:9092,kafka02:9092,kafka03:9092')
-    parser.add_argument("--topic", help="topic name", default='node-tracks')
-    parser.add_argument("--sync", help="sync to publish events", action='store_true')
-    parser.add_argument("--loop", action='store_true')
+    parser = argparse.ArgumentParser(argument_default=argparse.SUPPRESS, description="Tracklet and tracks commands")
+    
+    parser.add_argument("files", nargs='+', help="event pickle files")
+    parser.add_argument("--bootstrap_servers", default=['localhost:9092'], help="kafka server")
+    parser.add_argument("--logger", metavar="file path", default=None, help="logger configuration file path")
+
     return parser.parse_known_args()
+        
+    
+def topic_for(ev):
+    if isinstance(ev, TrackEvent):
+        return TOPIC_TRACK_EVENTS
+    elif isinstance(ev, TrackFeature):
+        return TOPIC_FEATURES
+    elif isinstance(ev, TrackletMotion):
+        return TOPIC_MOTIONS
+    else:
+        raise AssertionError()
+
 
 def main():
-    args, unknown = parse_args()
+    args, _ = parse_args()
+    args = update_namespace_with_environ(args)
 
-    producer = KafkaProducer(bootstrap_servers=args.servers.split(','))
-    while True:
-        for log_path in args.log_paths:
-            read_log_and_publish(producer, args.topic, log_path, args.sync)
-        if not args.loop:
-            break
-
-    producer.close()
-
-def read_log_and_publish(producer: KafkaProducer, topic:str, log_path:str, sync:bool):
-    heap = []
-    heapq.heapify(heap)
-
-    with open(log_path, 'r') as fp:
-        last_ts = 0
-        while True:
-            line = fp.readline().rstrip()
-            if len(line) > 0:
-                te = TrackEvent.from_json(line)
-                heapq.heappush(heap, te)
-            elif len(heap) == 0:
-                break
-            
-            if len(heap) >= 32 or len(line) == 0:
-                track: TrackEvent = heapq.heappop(heap)
-                if sync and last_ts > 0:
-                    remains = track.ts - last_ts
-                    if remains > 30:
-                        time.sleep(remains / 1000.0)
-                producer.send(topic, value=track.serialize(), key=track.key())
-                producer.flush()
-                last_ts = track.ts
+    initialize_logger(args.logger)
+    
+    try:
+        producer = KafkaProducer(bootstrap_servers=args.bootstrap_servers)
+        for file in args.files:
+            with open(file, 'rb') as fp:
+                try:
+                    while True:
+                        event = pickle.load(fp)
+                        topic = topic_for(event)
+                        producer.send(topic, value=event.serialize(), key=event.key().encode('utf-8'))
+                        # print(topic, event)
+                except EOFError:
+                    pass
+        producer.close()
+    except NoBrokersAvailable as e:
+        import sys
+        print(f'fails to connect to Kafka: server={args.bootstrap_servers}', file=sys.stderr)
 
 if __name__ == '__main__':
-	main()
+    main()
```

## Comparing `dna.node-1.0.0.dist-info/METADATA` & `dna.node-2.1.1.dist-info/METADATA`

 * *Files 8% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: dna.node
-Version: 1.0.0
+Version: 2.1.1
 Summary: DNA framework
 Home-page: https://github.com/kwlee0220/dna.node
 Author: Kang-Woo Lee
 Author-email: kwlee@etri.re.kr
 Requires-Python: >=3.8
 Requires-Dist: numpy (>=1.18.5)
 Requires-Dist: scipy
@@ -16,15 +16,18 @@
 Requires-Dist: omegaconf (>=2.1.2)
 Requires-Dist: tqdm (>=4.41.0)
 Requires-Dist: Shapely
 Requires-Dist: easydict
 Requires-Dist: pyyaml
 Requires-Dist: gdown
 Requires-Dist: pyproj
-Requires-Dist: psycopg2
 Requires-Dist: pika
 Requires-Dist: ipython
 Requires-Dist: psutil
-Requires-Dist: gluoncv
-Requires-Dist: mxnet
-Requires-Dist: imgaug
+Requires-Dist: ultralytics
+Requires-Dist: gitpython
+Requires-Dist: gitdb
+Requires-Dist: smmap
+Requires-Dist: protobuf
+Requires-Dist: scikit-learn
+Requires-Dist: networkx
```

